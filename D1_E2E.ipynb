{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "D1_E2E.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "nfyQfQLjyh9f"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfyQfQLjyh9f",
        "colab_type": "text"
      },
      "source": [
        "#### dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwTxt0lV8wls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/13578/588368/all.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1570368151&Signature=X4kCxegOxLlIL9yWxP6yokUvwifvIs9m1uotdBpOBzSrOscYBRTxPlGMgRJDrxI6U6UqP4Q%2BIX2v7W1%2B0cH%2FDlnsXK5NSySxPY41SGTKf%2BeoumVJwsxOFi5ixAjxjNkQ5wumoqLYS58H%2FP4FOAmPCRYY6K5fKghrjxB6cHFBCTHLD3dCAyq8eWFdTUp8YiKK1NoHZWD1Ml3Hs2I6oRzDGcEX7DrAwINX0dONBSFgnFZ%2F%2B6ZFQut8Xpo8zdT%2BFlKekYyjJ9t2%2FIeq5FCcd%2B0HMwLALulY8wI39XM9UIaTm63BIykj5VAx3N%2FZPTLEy0kuQtrj0gXY%2FVwi7R9k1CvYrw%3D%3D&response-content-disposition=attachment%3B+filename%3Dkuzushiji-recognition.zip\" -O \"kuzushiji-recognition.zip\" -c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KW-Bbjps8wed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q kuzushiji-recognition.zip\n",
        "!rm kuzushiji-recognition.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNKf49Ll9_Py",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir train_images\n",
        "!unzip -q train_images.zip -d train_images\n",
        "!rm train_images.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjdhHySoAxA9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir test_images\n",
        "!unzip -q test_images.zip -d test_images\n",
        "!rm test_images.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymwpZTAR98vg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZTfBAjbYn0X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%shell\n",
        "\n",
        "# Download TorchVision repo to use some files from\n",
        "# references/detection\n",
        "git clone https://github.com/pytorch/vision.git\n",
        "cd vision\n",
        "git checkout v0.3.0\n",
        "\n",
        "cp references/detection/utils.py ../\n",
        "cp references/detection/transforms.py ../\n",
        "cp references/detection/coco_eval.py ../\n",
        "cp references/detection/engine.py ../\n",
        "cp references/detection/coco_utils.py ../"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rdr7TSm8ykZ-",
        "colab_type": "text"
      },
      "source": [
        "#### sub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UDrfBt9Dq0ck",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d7d9e817-ef71-4950-b7f1-b67c6e710752"
      },
      "source": [
        "import pandas as pd\n",
        "df1 = pd.read_csv('train.csv')\n",
        "df1.head()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100241706_00004_2</td>\n",
              "      <td>U+306F 1231 3465 133 53 U+304C 275 1652 84 69 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100241706_00005_1</td>\n",
              "      <td>U+306F 1087 2018 103 65 U+304B 1456 1832 40 73...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100241706_00005_2</td>\n",
              "      <td>U+306F 572 1376 125 57 U+306E 1551 2080 69 68 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100241706_00006_1</td>\n",
              "      <td>U+3082 1455 3009 65 44 U+516B 1654 1528 141 75...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100241706_00007_2</td>\n",
              "      <td>U+309D 1201 2949 27 33 U+309D 1196 1539 27 36 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            image_id                                             labels\n",
              "0  100241706_00004_2  U+306F 1231 3465 133 53 U+304C 275 1652 84 69 ...\n",
              "1  100241706_00005_1  U+306F 1087 2018 103 65 U+304B 1456 1832 40 73...\n",
              "2  100241706_00005_2  U+306F 572 1376 125 57 U+306E 1551 2080 69 68 ...\n",
              "3  100241706_00006_1  U+3082 1455 3009 65 44 U+516B 1654 1528 141 75...\n",
              "4  100241706_00007_2  U+309D 1201 2949 27 33 U+309D 1196 1539 27 36 ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faS5g3nugf-j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5169b2f6-f81d-4b9d-aecc-1deabc98eed8"
      },
      "source": [
        "df1.labels[0]"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'U+306F 1231 3465 133 53 U+304C 275 1652 84 69 U+3044 1495 1218 143 69 U+3051 220 3331 53 91 U+306B 911 1452 61 92 U+306B 927 3445 71 92 U+306E 904 2879 95 92 U+5DE5 1168 1396 187 95 U+3053 289 3166 69 97 U+4E09 897 3034 121 107 U+306E 547 1912 141 108 U+3084 1489 2675 151 109 U+3068 1561 2979 55 116 U+5DF1 1513 2500 127 117 U+3082 1213 1523 72 119 U+3055 1219 3266 95 124 U+306E 259 2230 68 125 U+306E 1184 2423 169 125 U+4E16 849 2236 163 127 U+7D30 1144 1212 200 128 U+305D 316 3287 57 133 U+4EBA 217 2044 183 135 U+3051 277 2974 112 137 U+308C 201 3423 181 137 U+3060 243 2830 159 143 U+5F37 1479 2034 163 145 U+306E 1497 1567 123 152 U+305F 1164 952 145 153 U+3066 552 1199 97 155 U+4FF3 537 2095 176 155 U+6839 203 1439 184 156 U+304B 1188 2606 156 157 U+8AE7 549 2328 156 159 U+308C 1495 2784 168 159 U+5B50 891 1255 100 164 U+3092 584 2546 117 164 U+53CA 849 1588 151 164 U+8005 1192 2198 133 169 U+305A 889 1763 103 171 U+907F 513 945 181 171 U+6B63 539 1439 136 172 U+6587 192 2382 216 173 U+3075 1512 3371 147 176 U+6642 1465 1338 168 179 U+601D 1492 3175 159 180 U+306A 1191 2775 135 181 U+3081 593 3313 151 184 U+6D6E 868 1982 155 184 U+3092 873 2400 145 192 U+6C17 1504 1754 145 200 U+8077 208 1770 197 204 U+8001 1167 1687 152 208 U+6B66 1184 1942 171 208 U+697D 568 2762 133 209 U+3082 247 1159 116 212 U+76F2 253 2578 119 215 U+82E5 1465 951 172 216 U+81EA 1852 1736 104 219 U+3069 220 928 139 229 U+98A8 541 1619 147 236 U+306B 1521 2239 83 237 U+88CF 851 2608 169 237 U+7573 905 3189 103 244 U+606F 876 937 123 244 U+5E8F 1816 2096 152 296 U+3057 629 2985 27 300 U+3057 1243 2942 39 313'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gVpyLQlzq0ck",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0fe4ad20-57fd-49e2-da16-f69ac37cf61c"
      },
      "source": [
        "df1['image_id'] = df1.image_id + '.jpg'\n",
        "df1.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100241706_00004_2.jpg</td>\n",
              "      <td>U+306F 1231 3465 133 53 U+304C 275 1652 84 69 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100241706_00005_1.jpg</td>\n",
              "      <td>U+306F 1087 2018 103 65 U+304B 1456 1832 40 73...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100241706_00005_2.jpg</td>\n",
              "      <td>U+306F 572 1376 125 57 U+306E 1551 2080 69 68 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100241706_00006_1.jpg</td>\n",
              "      <td>U+3082 1455 3009 65 44 U+516B 1654 1528 141 75...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100241706_00007_2.jpg</td>\n",
              "      <td>U+309D 1201 2949 27 33 U+309D 1196 1539 27 36 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                image_id                                             labels\n",
              "0  100241706_00004_2.jpg  U+306F 1231 3465 133 53 U+304C 275 1652 84 69 ...\n",
              "1  100241706_00005_1.jpg  U+306F 1087 2018 103 65 U+304B 1456 1832 40 73...\n",
              "2  100241706_00005_2.jpg  U+306F 572 1376 125 57 U+306E 1551 2080 69 68 ...\n",
              "3  100241706_00006_1.jpg  U+3082 1455 3009 65 44 U+516B 1654 1528 141 75...\n",
              "4  100241706_00007_2.jpg  U+309D 1201 2949 27 33 U+309D 1196 1539 27 36 ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y5B94McAq0c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "6634afff-1690-40ef-830c-f2c2810dc035"
      },
      "source": [
        "df1['labels1'] = df1['labels'].str.split(' ')\n",
        "df1.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>labels</th>\n",
              "      <th>labels1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100241706_00004_2.jpg</td>\n",
              "      <td>U+306F 1231 3465 133 53 U+304C 275 1652 84 69 ...</td>\n",
              "      <td>[U+306F, 1231, 3465, 133, 53, U+304C, 275, 165...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100241706_00005_1.jpg</td>\n",
              "      <td>U+306F 1087 2018 103 65 U+304B 1456 1832 40 73...</td>\n",
              "      <td>[U+306F, 1087, 2018, 103, 65, U+304B, 1456, 18...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100241706_00005_2.jpg</td>\n",
              "      <td>U+306F 572 1376 125 57 U+306E 1551 2080 69 68 ...</td>\n",
              "      <td>[U+306F, 572, 1376, 125, 57, U+306E, 1551, 208...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100241706_00006_1.jpg</td>\n",
              "      <td>U+3082 1455 3009 65 44 U+516B 1654 1528 141 75...</td>\n",
              "      <td>[U+3082, 1455, 3009, 65, 44, U+516B, 1654, 152...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100241706_00007_2.jpg</td>\n",
              "      <td>U+309D 1201 2949 27 33 U+309D 1196 1539 27 36 ...</td>\n",
              "      <td>[U+309D, 1201, 2949, 27, 33, U+309D, 1196, 153...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                image_id  ...                                            labels1\n",
              "0  100241706_00004_2.jpg  ...  [U+306F, 1231, 3465, 133, 53, U+304C, 275, 165...\n",
              "1  100241706_00005_1.jpg  ...  [U+306F, 1087, 2018, 103, 65, U+304B, 1456, 18...\n",
              "2  100241706_00005_2.jpg  ...  [U+306F, 572, 1376, 125, 57, U+306E, 1551, 208...\n",
              "3  100241706_00006_1.jpg  ...  [U+3082, 1455, 3009, 65, 44, U+516B, 1654, 152...\n",
              "4  100241706_00007_2.jpg  ...  [U+309D, 1201, 2949, 27, 33, U+309D, 1196, 153...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wXUaJG94q0c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "816d9c92-a451-4a34-dc24-b7ff615bc2b8"
      },
      "source": [
        "df1 = df1.dropna()\n",
        "df1 = df1.reset_index(drop=True)\n",
        "df1.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3605 entries, 0 to 3604\n",
            "Data columns (total 3 columns):\n",
            "image_id    3605 non-null object\n",
            "labels      3605 non-null object\n",
            "labels1     3605 non-null object\n",
            "dtypes: object(3)\n",
            "memory usage: 84.6+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hOP6SFP3q0c4",
        "colab": {}
      },
      "source": [
        "unicode_trans = pd.read_csv('unicode_translation.csv')\n",
        "unicode_map = {codepoint: char for codepoint, char in unicode_trans.values}\n",
        "unicode2labels = dict(zip(unicode_map.keys(), range(len(unicode_map.keys()))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dwOVWbasq0c4",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "clz = []\n",
        "for idx, val in enumerate(df1.labels1):\n",
        "  elm = val[::5]\n",
        "  labels = np.zeros(len(elm))\n",
        "  for i, x in enumerate(elm):\n",
        "    labels[i] = unicode2labels[x]\n",
        "  \n",
        "  clz.append(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eyQR41f9q0dI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "af74a097-42cc-4f30-c354-9bbf8f8fe9ed"
      },
      "source": [
        "np.array(clz).shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3605,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rK6VwkwzXmb6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bb_hw_pandas(a):\n",
        "  a = np.array(a.split(' ')).reshape(-1, 5)\n",
        "  b = []\n",
        "  for codepoint, x, y, w, h in a:\n",
        "    x, y, w, h = int(x), int(y), int(w), int(h)\n",
        "    w = x+w\n",
        "    h = y+h\n",
        "    z = [x, y, w, h]\n",
        "    b.append(z)\n",
        "    \n",
        "  return b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HleBcjcLX-eL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "7b72c43b-a6fd-4dae-b259-92a7fd588199"
      },
      "source": [
        "df1.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>labels</th>\n",
              "      <th>labels1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100241706_00004_2.jpg</td>\n",
              "      <td>U+306F 1231 3465 133 53 U+304C 275 1652 84 69 ...</td>\n",
              "      <td>[U+306F, 1231, 3465, 133, 53, U+304C, 275, 165...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100241706_00005_1.jpg</td>\n",
              "      <td>U+306F 1087 2018 103 65 U+304B 1456 1832 40 73...</td>\n",
              "      <td>[U+306F, 1087, 2018, 103, 65, U+304B, 1456, 18...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100241706_00005_2.jpg</td>\n",
              "      <td>U+306F 572 1376 125 57 U+306E 1551 2080 69 68 ...</td>\n",
              "      <td>[U+306F, 572, 1376, 125, 57, U+306E, 1551, 208...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100241706_00006_1.jpg</td>\n",
              "      <td>U+3082 1455 3009 65 44 U+516B 1654 1528 141 75...</td>\n",
              "      <td>[U+3082, 1455, 3009, 65, 44, U+516B, 1654, 152...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100241706_00007_2.jpg</td>\n",
              "      <td>U+309D 1201 2949 27 33 U+309D 1196 1539 27 36 ...</td>\n",
              "      <td>[U+309D, 1201, 2949, 27, 33, U+309D, 1196, 153...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                image_id  ...                                            labels1\n",
              "0  100241706_00004_2.jpg  ...  [U+306F, 1231, 3465, 133, 53, U+304C, 275, 165...\n",
              "1  100241706_00005_1.jpg  ...  [U+306F, 1087, 2018, 103, 65, U+304B, 1456, 18...\n",
              "2  100241706_00005_2.jpg  ...  [U+306F, 572, 1376, 125, 57, U+306E, 1551, 208...\n",
              "3  100241706_00006_1.jpg  ...  [U+3082, 1455, 3009, 65, 44, U+516B, 1654, 152...\n",
              "4  100241706_00007_2.jpg  ...  [U+309D, 1201, 2949, 27, 33, U+309D, 1196, 153...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0WTAiMZWq0dn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "439ffc96-dcff-48d4-813d-72f64aa479b9"
      },
      "source": [
        "df1['bbox'] = df1['labels'].apply(lambda x : bb_hw_pandas(x))\n",
        "df1.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>labels</th>\n",
              "      <th>labels1</th>\n",
              "      <th>bbox</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100241706_00004_2.jpg</td>\n",
              "      <td>U+306F 1231 3465 133 53 U+304C 275 1652 84 69 ...</td>\n",
              "      <td>[U+306F, 1231, 3465, 133, 53, U+304C, 275, 165...</td>\n",
              "      <td>[[1231, 3465, 1364, 3518], [275, 1652, 359, 17...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100241706_00005_1.jpg</td>\n",
              "      <td>U+306F 1087 2018 103 65 U+304B 1456 1832 40 73...</td>\n",
              "      <td>[U+306F, 1087, 2018, 103, 65, U+304B, 1456, 18...</td>\n",
              "      <td>[[1087, 2018, 1190, 2083], [1456, 1832, 1496, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100241706_00005_2.jpg</td>\n",
              "      <td>U+306F 572 1376 125 57 U+306E 1551 2080 69 68 ...</td>\n",
              "      <td>[U+306F, 572, 1376, 125, 57, U+306E, 1551, 208...</td>\n",
              "      <td>[[572, 1376, 697, 1433], [1551, 2080, 1620, 21...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100241706_00006_1.jpg</td>\n",
              "      <td>U+3082 1455 3009 65 44 U+516B 1654 1528 141 75...</td>\n",
              "      <td>[U+3082, 1455, 3009, 65, 44, U+516B, 1654, 152...</td>\n",
              "      <td>[[1455, 3009, 1520, 3053], [1654, 1528, 1795, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100241706_00007_2.jpg</td>\n",
              "      <td>U+309D 1201 2949 27 33 U+309D 1196 1539 27 36 ...</td>\n",
              "      <td>[U+309D, 1201, 2949, 27, 33, U+309D, 1196, 153...</td>\n",
              "      <td>[[1201, 2949, 1228, 2982], [1196, 1539, 1223, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                image_id  ...                                               bbox\n",
              "0  100241706_00004_2.jpg  ...  [[1231, 3465, 1364, 3518], [275, 1652, 359, 17...\n",
              "1  100241706_00005_1.jpg  ...  [[1087, 2018, 1190, 2083], [1456, 1832, 1496, ...\n",
              "2  100241706_00005_2.jpg  ...  [[572, 1376, 697, 1433], [1551, 2080, 1620, 21...\n",
              "3  100241706_00006_1.jpg  ...  [[1455, 3009, 1520, 3053], [1654, 1528, 1795, ...\n",
              "4  100241706_00007_2.jpg  ...  [[1201, 2949, 1228, 2982], [1196, 1539, 1223, ...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6b06bxxNq0dn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dcb937a8-0767-439e-8e5e-158cc7f24683"
      },
      "source": [
        "df1.bbox[0][0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1231, 3465, 1364, 3518]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7bewbdxRq0dn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "5b3998c2-4841-448a-d141-0412cb3ffad5"
      },
      "source": [
        "import numpy as np\n",
        "df1['classes'] = np.array(clz)\n",
        "df1.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>labels</th>\n",
              "      <th>labels1</th>\n",
              "      <th>bbox</th>\n",
              "      <th>classes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100241706_00004_2.jpg</td>\n",
              "      <td>U+306F 1231 3465 133 53 U+304C 275 1652 84 69 ...</td>\n",
              "      <td>[U+306F, 1231, 3465, 133, 53, U+304C, 275, 165...</td>\n",
              "      <td>[[1231, 3465, 1364, 3518], [275, 1652, 359, 17...</td>\n",
              "      <td>[92.0, 57.0, 52.0, 62.0, 88.0, 88.0, 91.0, 125...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100241706_00005_1.jpg</td>\n",
              "      <td>U+306F 1087 2018 103 65 U+304B 1456 1832 40 73...</td>\n",
              "      <td>[U+306F, 1087, 2018, 103, 65, U+304B, 1456, 18...</td>\n",
              "      <td>[[1087, 2018, 1190, 2083], [1456, 1832, 1496, ...</td>\n",
              "      <td>[92.0, 56.0, 56.0, 52.0, 88.0, 88.0, 101.0, 57...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100241706_00005_2.jpg</td>\n",
              "      <td>U+306F 572 1376 125 57 U+306E 1551 2080 69 68 ...</td>\n",
              "      <td>[U+306F, 572, 1376, 125, 57, U+306E, 1551, 208...</td>\n",
              "      <td>[[572, 1376, 697, 1433], [1551, 2080, 1620, 21...</td>\n",
              "      <td>[92.0, 91.0, 101.0, 57.0, 88.0, 110.0, 56.0, 8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100241706_00006_1.jpg</td>\n",
              "      <td>U+3082 1455 3009 65 44 U+516B 1654 1528 141 75...</td>\n",
              "      <td>[U+3082, 1455, 3009, 65, 44, U+516B, 1654, 152...</td>\n",
              "      <td>[[1455, 3009, 1520, 3053], [1654, 1528, 1795, ...</td>\n",
              "      <td>[111.0, 502.0, 129.0, 88.0, 120.0, 56.0, 91.0,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100241706_00007_2.jpg</td>\n",
              "      <td>U+309D 1201 2949 27 33 U+309D 1196 1539 27 36 ...</td>\n",
              "      <td>[U+309D, 1201, 2949, 27, 33, U+309D, 1196, 153...</td>\n",
              "      <td>[[1201, 2949, 1228, 2982], [1196, 1539, 1223, ...</td>\n",
              "      <td>[128.0, 128.0, 128.0, 128.0, 101.0, 128.0, 26....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                image_id  ...                                            classes\n",
              "0  100241706_00004_2.jpg  ...  [92.0, 57.0, 52.0, 62.0, 88.0, 88.0, 91.0, 125...\n",
              "1  100241706_00005_1.jpg  ...  [92.0, 56.0, 56.0, 52.0, 88.0, 88.0, 101.0, 57...\n",
              "2  100241706_00005_2.jpg  ...  [92.0, 91.0, 101.0, 57.0, 88.0, 110.0, 56.0, 8...\n",
              "3  100241706_00006_1.jpg  ...  [111.0, 502.0, 129.0, 88.0, 120.0, 56.0, 91.0,...\n",
              "4  100241706_00007_2.jpg  ...  [128.0, 128.0, 128.0, 128.0, 101.0, 128.0, 26....\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OBxJ8hGAq0dn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "87af393f-d937-42f8-d88a-5d5a657ba67e"
      },
      "source": [
        "df1.classes[0][0]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "92.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WPo_khLEq0d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "a38a24ba-f159-4bde-acdf-f865154efc89"
      },
      "source": [
        "columns = ['labels', 'labels1']\n",
        "df1.drop(columns, inplace=True, axis=1)\n",
        "df1.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>bbox</th>\n",
              "      <th>classes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100241706_00004_2.jpg</td>\n",
              "      <td>[[1231, 3465, 1364, 3518], [275, 1652, 359, 17...</td>\n",
              "      <td>[92.0, 57.0, 52.0, 62.0, 88.0, 88.0, 91.0, 125...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100241706_00005_1.jpg</td>\n",
              "      <td>[[1087, 2018, 1190, 2083], [1456, 1832, 1496, ...</td>\n",
              "      <td>[92.0, 56.0, 56.0, 52.0, 88.0, 88.0, 101.0, 57...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100241706_00005_2.jpg</td>\n",
              "      <td>[[572, 1376, 697, 1433], [1551, 2080, 1620, 21...</td>\n",
              "      <td>[92.0, 91.0, 101.0, 57.0, 88.0, 110.0, 56.0, 8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100241706_00006_1.jpg</td>\n",
              "      <td>[[1455, 3009, 1520, 3053], [1654, 1528, 1795, ...</td>\n",
              "      <td>[111.0, 502.0, 129.0, 88.0, 120.0, 56.0, 91.0,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100241706_00007_2.jpg</td>\n",
              "      <td>[[1201, 2949, 1228, 2982], [1196, 1539, 1223, ...</td>\n",
              "      <td>[128.0, 128.0, 128.0, 128.0, 101.0, 128.0, 26....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                image_id  ...                                            classes\n",
              "0  100241706_00004_2.jpg  ...  [92.0, 57.0, 52.0, 62.0, 88.0, 88.0, 91.0, 125...\n",
              "1  100241706_00005_1.jpg  ...  [92.0, 56.0, 56.0, 52.0, 88.0, 88.0, 101.0, 57...\n",
              "2  100241706_00005_2.jpg  ...  [92.0, 91.0, 101.0, 57.0, 88.0, 110.0, 56.0, 8...\n",
              "3  100241706_00006_1.jpg  ...  [111.0, 502.0, 129.0, 88.0, 120.0, 56.0, 91.0,...\n",
              "4  100241706_00007_2.jpg  ...  [128.0, 128.0, 128.0, 128.0, 101.0, 128.0, 26....\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2piVFvZfq0d3",
        "colab": {}
      },
      "source": [
        "# Defining the dataset:\n",
        "'''\n",
        "https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html\n",
        "'''\n",
        "import os\n",
        "import numpy as np\n",
        "import torch.utils.data\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "\n",
        "class KuzushijiDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, df, root, mode='train', transforms=None):\n",
        "    self.records = df.to_records(index=False)\n",
        "    self.root = root\n",
        "    self.mode = mode\n",
        "    self.transforms = transforms\n",
        "    self.len = df.shape[0]    \n",
        "    \n",
        "  def __getitem__(self, index):\n",
        "    imgs, bbox, clas = self.records[index].image_id, self.records[index].bbox, self.records[index].classes\n",
        "    img = Image.open(os.path.join(root, imgs)).convert(\"RGB\")\n",
        "    \n",
        "    target = {}\n",
        "    target[\"boxes\"] = torch.as_tensor(bbox, dtype=torch.float32)\n",
        "    target[\"labels\"] = torch.as_tensor(clas, dtype=torch.int64)\n",
        "    target[\"image_id\"] = torch.tensor([index])\n",
        "    \n",
        "    if self.transforms is not None:\n",
        "      img = self.transforms(img)\n",
        "      #img, target = self.transforms(img, target)\n",
        "      \n",
        "    return img, target\n",
        "  \n",
        "    if self.mode == 'train':\n",
        "      return img, target\n",
        "    else:\n",
        "      return img, self.records[index].image_id\n",
        "    \n",
        "  def __len__(self):\n",
        "    return self.len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "29Si38VWq0d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1e34bc51-e119-4f05-9ce1-47c6f49b4bb5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "root = 'train_images'\n",
        "\n",
        "dataset = KuzushijiDataset(df1, root)\n",
        "\n",
        "for i in range(len(dataset)):\n",
        "  img, lbl = dataset[i]\n",
        "  \n",
        "  print(i, img.size, len(lbl))\n",
        "  \n",
        "  if i == 2:\n",
        "    break"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 (2404, 3874) 3\n",
            "1 (2392, 3874) 3\n",
            "2 (2416, 3874) 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yjoPI2mOq0d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "47eb782b-f806-49ef-bc61-c08efcdba3e7"
      },
      "source": [
        "dataset[0]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<PIL.Image.Image image mode=RGB size=2404x3874 at 0x7F443E413CF8>,\n",
              " {'boxes': tensor([[1231., 3465., 1364., 3518.],\n",
              "          [ 275., 1652.,  359., 1721.],\n",
              "          [1495., 1218., 1638., 1287.],\n",
              "          [ 220., 3331.,  273., 3422.],\n",
              "          [ 911., 1452.,  972., 1544.],\n",
              "          [ 927., 3445.,  998., 3537.],\n",
              "          [ 904., 2879.,  999., 2971.],\n",
              "          [1168., 1396., 1355., 1491.],\n",
              "          [ 289., 3166.,  358., 3263.],\n",
              "          [ 897., 3034., 1018., 3141.],\n",
              "          [ 547., 1912.,  688., 2020.],\n",
              "          [1489., 2675., 1640., 2784.],\n",
              "          [1561., 2979., 1616., 3095.],\n",
              "          [1513., 2500., 1640., 2617.],\n",
              "          [1213., 1523., 1285., 1642.],\n",
              "          [1219., 3266., 1314., 3390.],\n",
              "          [ 259., 2230.,  327., 2355.],\n",
              "          [1184., 2423., 1353., 2548.],\n",
              "          [ 849., 2236., 1012., 2363.],\n",
              "          [1144., 1212., 1344., 1340.],\n",
              "          [ 316., 3287.,  373., 3420.],\n",
              "          [ 217., 2044.,  400., 2179.],\n",
              "          [ 277., 2974.,  389., 3111.],\n",
              "          [ 201., 3423.,  382., 3560.],\n",
              "          [ 243., 2830.,  402., 2973.],\n",
              "          [1479., 2034., 1642., 2179.],\n",
              "          [1497., 1567., 1620., 1719.],\n",
              "          [1164.,  952., 1309., 1105.],\n",
              "          [ 552., 1199.,  649., 1354.],\n",
              "          [ 537., 2095.,  713., 2250.],\n",
              "          [ 203., 1439.,  387., 1595.],\n",
              "          [1188., 2606., 1344., 2763.],\n",
              "          [ 549., 2328.,  705., 2487.],\n",
              "          [1495., 2784., 1663., 2943.],\n",
              "          [ 891., 1255.,  991., 1419.],\n",
              "          [ 584., 2546.,  701., 2710.],\n",
              "          [ 849., 1588., 1000., 1752.],\n",
              "          [1192., 2198., 1325., 2367.],\n",
              "          [ 889., 1763.,  992., 1934.],\n",
              "          [ 513.,  945.,  694., 1116.],\n",
              "          [ 539., 1439.,  675., 1611.],\n",
              "          [ 192., 2382.,  408., 2555.],\n",
              "          [1512., 3371., 1659., 3547.],\n",
              "          [1465., 1338., 1633., 1517.],\n",
              "          [1492., 3175., 1651., 3355.],\n",
              "          [1191., 2775., 1326., 2956.],\n",
              "          [ 593., 3313.,  744., 3497.],\n",
              "          [ 868., 1982., 1023., 2166.],\n",
              "          [ 873., 2400., 1018., 2592.],\n",
              "          [1504., 1754., 1649., 1954.],\n",
              "          [ 208., 1770.,  405., 1974.],\n",
              "          [1167., 1687., 1319., 1895.],\n",
              "          [1184., 1942., 1355., 2150.],\n",
              "          [ 568., 2762.,  701., 2971.],\n",
              "          [ 247., 1159.,  363., 1371.],\n",
              "          [ 253., 2578.,  372., 2793.],\n",
              "          [1465.,  951., 1637., 1167.],\n",
              "          [1852., 1736., 1956., 1955.],\n",
              "          [ 220.,  928.,  359., 1157.],\n",
              "          [ 541., 1619.,  688., 1855.],\n",
              "          [1521., 2239., 1604., 2476.],\n",
              "          [ 851., 2608., 1020., 2845.],\n",
              "          [ 905., 3189., 1008., 3433.],\n",
              "          [ 876.,  937.,  999., 1181.],\n",
              "          [1816., 2096., 1968., 2392.],\n",
              "          [ 629., 2985.,  656., 3285.],\n",
              "          [1243., 2942., 1282., 3255.]]),\n",
              "  'image_id': tensor([0]),\n",
              "  'labels': tensor([  92,   57,   52,   62,   88,   88,   91, 1258,   64,  251,   91,  113,\n",
              "            85, 1264,  111,   66,   91,   91,  259, 3047,   74,  316,   62,  121,\n",
              "            77, 1369,   91,   76,   83,  407, 1981,   56, 3830,  121, 1086,  126,\n",
              "           688, 3181,   71, 4108, 2154, 1786,   98, 1838, 1439,   87,  110, 2268,\n",
              "           126, 2195, 3205, 3178, 2156, 2065,  111, 2712, 3359, 3289,   86, 4446,\n",
              "            88, 3704, 2626, 1464, 1314,   68,   68])})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAtNeCNnYLvI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "79e0a805-5527-446c-f42a-68702fb5cfd6"
      },
      "source": [
        "%%writefile utils.py\n",
        "from __future__ import print_function\n",
        "\n",
        "from collections import defaultdict, deque\n",
        "import datetime\n",
        "import pickle\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.distributed as dist\n",
        "\n",
        "import errno\n",
        "import os\n",
        "\n",
        "\n",
        "class SmoothedValue(object):\n",
        "    \"\"\"Track a series of values and provide access to smoothed values over a\n",
        "    window or the global series average.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, window_size=20, fmt=None):\n",
        "        if fmt is None:\n",
        "            fmt = \"{median:.4f} ({global_avg:.4f})\"\n",
        "        self.deque = deque(maxlen=window_size)\n",
        "        self.total = 0.0\n",
        "        self.count = 0\n",
        "        self.fmt = fmt\n",
        "\n",
        "    def update(self, value, n=1):\n",
        "        self.deque.append(value)\n",
        "        self.count += n\n",
        "        self.total += value * n\n",
        "\n",
        "    def synchronize_between_processes(self):\n",
        "        \"\"\"\n",
        "        Warning: does not synchronize the deque!\n",
        "        \"\"\"\n",
        "        if not is_dist_avail_and_initialized():\n",
        "            return\n",
        "        t = torch.tensor([self.count, self.total], dtype=torch.float64, device='cuda')\n",
        "        dist.barrier()\n",
        "        dist.all_reduce(t)\n",
        "        t = t.tolist()\n",
        "        self.count = int(t[0])\n",
        "        self.total = t[1]\n",
        "\n",
        "    @property\n",
        "    def median(self):\n",
        "        d = torch.tensor(list(self.deque))\n",
        "        return d.median().item()\n",
        "\n",
        "    @property\n",
        "    def avg(self):\n",
        "        d = torch.tensor(list(self.deque), dtype=torch.float32)\n",
        "        return d.mean().item()\n",
        "\n",
        "    @property\n",
        "    def global_avg(self):\n",
        "        return self.total / self.count\n",
        "\n",
        "    @property\n",
        "    def max(self):\n",
        "        return max(self.deque)\n",
        "\n",
        "    @property\n",
        "    def value(self):\n",
        "        return self.deque[-1]\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.fmt.format(\n",
        "            median=self.median,\n",
        "            avg=self.avg,\n",
        "            global_avg=self.global_avg,\n",
        "            max=self.max,\n",
        "            value=self.value)\n",
        "\n",
        "\n",
        "def all_gather(data):\n",
        "    \"\"\"\n",
        "    Run all_gather on arbitrary picklable data (not necessarily tensors)\n",
        "    Args:\n",
        "        data: any picklable object\n",
        "    Returns:\n",
        "        list[data]: list of data gathered from each rank\n",
        "    \"\"\"\n",
        "    world_size = get_world_size()\n",
        "    if world_size == 1:\n",
        "        return [data]\n",
        "\n",
        "    # serialized to a Tensor\n",
        "    buffer = pickle.dumps(data)\n",
        "    storage = torch.ByteStorage.from_buffer(buffer)\n",
        "    tensor = torch.ByteTensor(storage).to(\"cuda\")\n",
        "\n",
        "    # obtain Tensor size of each rank\n",
        "    local_size = torch.tensor([tensor.numel()], device=\"cuda\")\n",
        "    size_list = [torch.tensor([0], device=\"cuda\") for _ in range(world_size)]\n",
        "    dist.all_gather(size_list, local_size)\n",
        "    size_list = [int(size.item()) for size in size_list]\n",
        "    max_size = max(size_list)\n",
        "\n",
        "    # receiving Tensor from all ranks\n",
        "    # we pad the tensor because torch all_gather does not support\n",
        "    # gathering tensors of different shapes\n",
        "    tensor_list = []\n",
        "    for _ in size_list:\n",
        "        tensor_list.append(torch.empty((max_size,), dtype=torch.uint8, device=\"cuda\"))\n",
        "    if local_size != max_size:\n",
        "        padding = torch.empty(size=(max_size - local_size,), dtype=torch.uint8, device=\"cuda\")\n",
        "        tensor = torch.cat((tensor, padding), dim=0)\n",
        "    dist.all_gather(tensor_list, tensor)\n",
        "\n",
        "    data_list = []\n",
        "    for size, tensor in zip(size_list, tensor_list):\n",
        "        buffer = tensor.cpu().numpy().tobytes()[:size]\n",
        "        data_list.append(pickle.loads(buffer))\n",
        "\n",
        "    return data_list\n",
        "\n",
        "\n",
        "def reduce_dict(input_dict, average=True):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        input_dict (dict): all the values will be reduced\n",
        "        average (bool): whether to do average or sum\n",
        "    Reduce the values in the dictionary from all processes so that all processes\n",
        "    have the averaged results. Returns a dict with the same fields as\n",
        "    input_dict, after reduction.\n",
        "    \"\"\"\n",
        "    world_size = get_world_size()\n",
        "    if world_size < 2:\n",
        "        return input_dict\n",
        "    with torch.no_grad():\n",
        "        names = []\n",
        "        values = []\n",
        "        # sort the keys so that they are consistent across processes\n",
        "        for k in sorted(input_dict.keys()):\n",
        "            names.append(k)\n",
        "            values.append(input_dict[k])\n",
        "        values = torch.stack(values, dim=0)\n",
        "        dist.all_reduce(values)\n",
        "        if average:\n",
        "            values /= world_size\n",
        "        reduced_dict = {k: v for k, v in zip(names, values)}\n",
        "    return reduced_dict\n",
        "\n",
        "\n",
        "class MetricLogger(object):\n",
        "    def __init__(self, delimiter=\"\\t\"):\n",
        "        self.meters = defaultdict(SmoothedValue)\n",
        "        self.delimiter = delimiter\n",
        "\n",
        "    def update(self, **kwargs):\n",
        "        for k, v in kwargs.items():\n",
        "            if isinstance(v, torch.Tensor):\n",
        "                v = v.item()\n",
        "            assert isinstance(v, (float, int))\n",
        "            self.meters[k].update(v)\n",
        "\n",
        "    def __getattr__(self, attr):\n",
        "        if attr in self.meters:\n",
        "            return self.meters[attr]\n",
        "        if attr in self.__dict__:\n",
        "            return self.__dict__[attr]\n",
        "        raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n",
        "            type(self).__name__, attr))\n",
        "\n",
        "    def __str__(self):\n",
        "        loss_str = []\n",
        "        for name, meter in self.meters.items():\n",
        "            loss_str.append(\n",
        "                \"{}: {}\".format(name, str(meter))\n",
        "            )\n",
        "        return self.delimiter.join(loss_str)\n",
        "\n",
        "    def synchronize_between_processes(self):\n",
        "        for meter in self.meters.values():\n",
        "            meter.synchronize_between_processes()\n",
        "\n",
        "    def add_meter(self, name, meter):\n",
        "        self.meters[name] = meter\n",
        "\n",
        "    def log_every(self, iterable, print_freq, header=None):\n",
        "        i = 0\n",
        "        if not header:\n",
        "            header = ''\n",
        "        start_time = time.time()\n",
        "        end = time.time()\n",
        "        iter_time = SmoothedValue(fmt='{avg:.4f}')\n",
        "        data_time = SmoothedValue(fmt='{avg:.4f}')\n",
        "        space_fmt = ':' + str(len(str(len(iterable)))) + 'd'\n",
        "        log_msg = self.delimiter.join([\n",
        "            header,\n",
        "            '[{0' + space_fmt + '}/{1}]',\n",
        "            'eta: {eta}',\n",
        "            '{meters}',\n",
        "            'time: {time}',\n",
        "            'data: {data}',\n",
        "            'max mem: {memory:.0f}'\n",
        "        ])\n",
        "        MB = 1024.0 * 1024.0\n",
        "        for obj in iterable:\n",
        "            data_time.update(time.time() - end)\n",
        "            yield obj\n",
        "            iter_time.update(time.time() - end)\n",
        "            if i % print_freq == 0 or i == len(iterable) - 1:\n",
        "                eta_seconds = iter_time.global_avg * (len(iterable) - i)\n",
        "                eta_string = str(datetime.timedelta(seconds=int(eta_seconds)))\n",
        "                print(log_msg.format(\n",
        "                    i, len(iterable), eta=eta_string,\n",
        "                    meters=str(self),\n",
        "                    time=str(iter_time), data=str(data_time),\n",
        "                    memory=torch.cuda.max_memory_allocated() / MB))\n",
        "            i += 1\n",
        "            end = time.time()\n",
        "        total_time = time.time() - start_time\n",
        "        total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "        print('{} Total time: {} ({:.4f} s / it)'.format(\n",
        "            header, total_time_str, total_time / len(iterable)))\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "\n",
        "def warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor):\n",
        "\n",
        "    def f(x):\n",
        "        if x >= warmup_iters:\n",
        "            return 1\n",
        "        alpha = float(x) / warmup_iters\n",
        "        return warmup_factor * (1 - alpha) + alpha\n",
        "\n",
        "    return torch.optim.lr_scheduler.LambdaLR(optimizer, f)\n",
        "\n",
        "\n",
        "def mkdir(path):\n",
        "    try:\n",
        "        os.makedirs(path)\n",
        "    except OSError as e:\n",
        "        if e.errno != errno.EEXIST:\n",
        "            raise\n",
        "\n",
        "\n",
        "def setup_for_distributed(is_master):\n",
        "    \"\"\"\n",
        "    This function disables printing when not in master process\n",
        "    \"\"\"\n",
        "    import builtins as __builtin__\n",
        "    builtin_print = __builtin__.print\n",
        "\n",
        "    def print(*args, **kwargs):\n",
        "        force = kwargs.pop('force', False)\n",
        "        if is_master or force:\n",
        "            builtin_print(*args, **kwargs)\n",
        "\n",
        "    __builtin__.print = print\n",
        "\n",
        "\n",
        "def is_dist_avail_and_initialized():\n",
        "    if not dist.is_available():\n",
        "        return False\n",
        "    if not dist.is_initialized():\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def get_world_size():\n",
        "    if not is_dist_avail_and_initialized():\n",
        "        return 1\n",
        "    return dist.get_world_size()\n",
        "\n",
        "\n",
        "def get_rank():\n",
        "    if not is_dist_avail_and_initialized():\n",
        "        return 0\n",
        "    return dist.get_rank()\n",
        "\n",
        "\n",
        "def is_main_process():\n",
        "    return get_rank() == 0\n",
        "\n",
        "\n",
        "def save_on_master(*args, **kwargs):\n",
        "    if is_main_process():\n",
        "        torch.save(*args, **kwargs)\n",
        "\n",
        "\n",
        "def init_distributed_mode(args):\n",
        "    if 'RANK' in os.environ and 'WORLD_SIZE' in os.environ:\n",
        "        args.rank = int(os.environ[\"RANK\"])\n",
        "        args.world_size = int(os.environ['WORLD_SIZE'])\n",
        "        args.gpu = int(os.environ['LOCAL_RANK'])\n",
        "    elif 'SLURM_PROCID' in os.environ:\n",
        "        args.rank = int(os.environ['SLURM_PROCID'])\n",
        "        args.gpu = args.rank % torch.cuda.device_count()\n",
        "    else:\n",
        "        print('Not using distributed mode')\n",
        "        args.distributed = False\n",
        "        return\n",
        "\n",
        "    args.distributed = True\n",
        "\n",
        "    torch.cuda.set_device(args.gpu)\n",
        "    args.dist_backend = 'nccl'\n",
        "    print('| distributed init (rank {}): {}'.format(\n",
        "        args.rank, args.dist_url), flush=True)\n",
        "    torch.distributed.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n",
        "                                         world_size=args.world_size, rank=args.rank)\n",
        "    torch.distributed.barrier()\n",
        "    setup_for_distributed(args.rank == 0)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h7LXVaYNq0eG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ffcc2535-9ec5-41af-dc79-1a06a670e47f"
      },
      "source": [
        "import torchvision.transforms as T\n",
        "\n",
        "root = 'train_images'\n",
        "\n",
        "dataset = KuzushijiDataset(df1, root, transforms = T.ToTensor())\n",
        "#dataset_test = KuzushijiDataset(df1, root, transforms = T.ToTensor())\n",
        "\n",
        "# split the dataset in train and test set\n",
        "torch.manual_seed(1)\n",
        "#indices = torch.randperm(len(dataset)).tolist()\n",
        "#dataset = torch.utils.data.Subset(dataset, indices[:-50])\n",
        "#dataset_test = torch.utils.data.Subset(dataset_test, indices[-50:])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f43dcece6d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XCMChP3IbIP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "cba22ce1-197f-481e-df43-d11964000881"
      },
      "source": [
        "for i in range(len(dataset)):\n",
        "  img, lbl = dataset[i]\n",
        "  \n",
        "  print(i, img.shape, len(lbl))\n",
        "  \n",
        "  if i == 2:\n",
        "    break"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 torch.Size([3, 3874, 2404]) 3\n",
            "1 torch.Size([3, 3874, 2392]) 3\n",
            "2 torch.Size([3, 3874, 2416]) 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8hV97p3I0OT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define training and validation data loaders\n",
        "\n",
        "#from engine import train_one_epoch, evaluate\n",
        "import utils\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(dataset,\n",
        "                                          batch_size=1,\n",
        "                                          shuffle=True,\n",
        "                                          #num_workers=4,\n",
        "                                          collate_fn=utils.collate_fn)\n",
        "\n",
        "#data_loader_test = torch.utils.data.DataLoader(dataset_test,\n",
        " #                                              batch_size=1,\n",
        "  #                                             shuffle=False,\n",
        "                                               #num_workers=4,\n",
        "   #                                            collate_fn=utils.collate_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYyepoZMI3UV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(data_loader)\n",
        "images, labels = dataiter.next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHEX2IiYI6Sn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bb8a6be0-3bcc-4a43-ec22-19358c8f446a"
      },
      "source": [
        "len(images)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caFj34xrI74N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "da11f92c-5546-42c1-e048-4097a4bb26f3"
      },
      "source": [
        "len(labels)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9HCSt26JFBp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "95ff65e6-ec11-4238-f9d9-039165727532"
      },
      "source": [
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "\n",
        "# load a model pre-trained pre-trained on COCO\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "\n",
        "# replace the classifier with a new one, that has\n",
        "# num_classes which is user-defined\n",
        "num_classes = 4788  # 4212 class (person) + background\n",
        "# get number of input features for the classifier\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "# replace the pre-trained head with a new one\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n",
            "100%|| 160M/160M [00:01<00:00, 93.7MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXyfDCf3JI8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "# move model to the right device\n",
        "model.to(device)\n",
        "\n",
        "# construct an optimizer\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005,\n",
        "                            momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "# and a learning rate scheduler which decreases the learning rate by\n",
        "# 10x every 3 epochs\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
        "                                               step_size=3,\n",
        "                                               gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAxnKcFHJIW3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "d705c4cf-5a2a-4fef-d60b-d0bae0905390"
      },
      "source": [
        "images = list(image.to(device) for image in images)\n",
        "labels = [{k: v.to(device) for k, v in t.items()} for t in labels]\n",
        "output = model(images, labels)\n",
        "output"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss_box_reg': tensor(0.2220, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " 'loss_classifier': tensor(8.3762, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " 'loss_objectness': tensor(4.2284, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>),\n",
              " 'loss_rpn_box_reg': tensor(0.4006, device='cuda:0', grad_fn=<DivBackward0>)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glc2PqD5Ml57",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "83d8bb9e-7989-4677-f2cd-af6d79208747"
      },
      "source": [
        "from engine import train_one_epoch, evaluate\n",
        "\n",
        "'''\n",
        "ERROR\n",
        "'''\n",
        "# let's train it for 10 epochs\n",
        "num_epochs = 1\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # train for one epoch, printing every 10 iterations\n",
        "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
        "    # update the learning rate\n",
        "    lr_scheduler.step()\n",
        "    # evaluate on the test dataset\n",
        "    #evaluate(model, data_loader_test, device=device)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: [0]  [   0/3605]  eta: 1:19:35  lr: 0.000010  loss: 13.5540 (13.5540)  loss_classifier: 8.3091 (8.3091)  loss_box_reg: 0.3930 (0.3930)  loss_objectness: 4.5431 (4.5431)  loss_rpn_box_reg: 0.3089 (0.3089)  time: 1.3246  data: 0.3370  max mem: 2963\n",
            "Epoch: [0]  [  10/3605]  eta: 1:07:46  lr: 0.000060  loss: 11.9608 (11.5051)  loss_classifier: 8.1953 (8.1991)  loss_box_reg: 0.3930 (0.3544)  loss_objectness: 2.9997 (2.6629)  loss_rpn_box_reg: 0.2988 (0.2888)  time: 1.1313  data: 0.2200  max mem: 4413\n",
            "Epoch: [0]  [  20/3605]  eta: 1:06:16  lr: 0.000110  loss: 9.1524 (10.0768)  loss_classifier: 8.0683 (7.8679)  loss_box_reg: 0.3760 (0.3681)  loss_objectness: 0.4545 (1.5555)  loss_rpn_box_reg: 0.2725 (0.2853)  time: 1.0983  data: 0.2068  max mem: 5580\n",
            "Epoch: [0]  [  30/3605]  eta: 1:08:00  lr: 0.000160  loss: 7.3433 (8.6173)  loss_classifier: 6.4991 (6.8083)  loss_box_reg: 0.3855 (0.3828)  loss_objectness: 0.2669 (1.1316)  loss_rpn_box_reg: 0.2636 (0.2946)  time: 1.1472  data: 0.2122  max mem: 5838\n",
            "Epoch: [0]  [  40/3605]  eta: 1:07:27  lr: 0.000210  loss: 4.2879 (7.4669)  loss_classifier: 3.2351 (5.8761)  loss_box_reg: 0.4070 (0.3986)  loss_objectness: 0.2108 (0.9095)  loss_rpn_box_reg: 0.2517 (0.2827)  time: 1.1627  data: 0.2104  max mem: 5838\n",
            "Epoch: [0]  [  50/3605]  eta: 1:06:44  lr: 0.000260  loss: 3.5357 (6.6514)  loss_classifier: 2.6408 (5.2118)  loss_box_reg: 0.4185 (0.4027)  loss_objectness: 0.1779 (0.7620)  loss_rpn_box_reg: 0.2333 (0.2749)  time: 1.1032  data: 0.1965  max mem: 5838\n",
            "Epoch: [0]  [  60/3605]  eta: 1:06:55  lr: 0.000310  loss: 3.3040 (6.0987)  loss_classifier: 2.4925 (4.7625)  loss_box_reg: 0.3873 (0.3938)  loss_objectness: 0.1579 (0.6706)  loss_rpn_box_reg: 0.2345 (0.2717)  time: 1.1277  data: 0.2129  max mem: 5838\n",
            "Epoch: [0]  [  70/3605]  eta: 1:06:48  lr: 0.000360  loss: 3.2321 (5.6973)  loss_classifier: 2.4848 (4.4417)  loss_box_reg: 0.3656 (0.3913)  loss_objectness: 0.1579 (0.5987)  loss_rpn_box_reg: 0.2345 (0.2657)  time: 1.1534  data: 0.2128  max mem: 5838\n",
            "Epoch: [0]  [  80/3605]  eta: 1:06:25  lr: 0.000410  loss: 3.1657 (5.3629)  loss_classifier: 2.4081 (4.1734)  loss_box_reg: 0.3676 (0.3867)  loss_objectness: 0.1403 (0.5423)  loss_rpn_box_reg: 0.2287 (0.2606)  time: 1.1239  data: 0.2093  max mem: 5838\n",
            "Epoch: [0]  [  90/3605]  eta: 1:06:30  lr: 0.000460  loss: 3.1587 (5.1006)  loss_classifier: 2.4005 (3.9603)  loss_box_reg: 0.3560 (0.3807)  loss_objectness: 0.1432 (0.5020)  loss_rpn_box_reg: 0.2299 (0.2576)  time: 1.1392  data: 0.2079  max mem: 6909\n",
            "Epoch: [0]  [ 100/3605]  eta: 1:06:21  lr: 0.000509  loss: 3.1025 (4.9011)  loss_classifier: 2.3756 (3.8027)  loss_box_reg: 0.3575 (0.3793)  loss_objectness: 0.1318 (0.4647)  loss_rpn_box_reg: 0.2151 (0.2544)  time: 1.1576  data: 0.1945  max mem: 6909\n",
            "Epoch: [0]  [ 110/3605]  eta: 1:06:13  lr: 0.000559  loss: 3.0620 (4.7370)  loss_classifier: 2.3399 (3.6719)  loss_box_reg: 0.3632 (0.3784)  loss_objectness: 0.1142 (0.4350)  loss_rpn_box_reg: 0.2074 (0.2518)  time: 1.1451  data: 0.2093  max mem: 6909\n",
            "Epoch: [0]  [ 120/3605]  eta: 1:05:51  lr: 0.000609  loss: 2.9866 (4.6007)  loss_classifier: 2.3303 (3.5629)  loss_box_reg: 0.3632 (0.3787)  loss_objectness: 0.1142 (0.4099)  loss_rpn_box_reg: 0.2041 (0.2493)  time: 1.1241  data: 0.2022  max mem: 6909\n",
            "Epoch: [0]  [ 130/3605]  eta: 1:05:47  lr: 0.000659  loss: 2.9866 (4.4805)  loss_classifier: 2.3032 (3.4674)  loss_box_reg: 0.3715 (0.3776)  loss_objectness: 0.1070 (0.3866)  loss_rpn_box_reg: 0.2233 (0.2488)  time: 1.1300  data: 0.2142  max mem: 6909\n",
            "Epoch: [0]  [ 140/3605]  eta: 1:05:23  lr: 0.000709  loss: 2.9775 (4.3762)  loss_classifier: 2.2923 (3.3859)  loss_box_reg: 0.3612 (0.3773)  loss_objectness: 0.1021 (0.3672)  loss_rpn_box_reg: 0.2212 (0.2458)  time: 1.1227  data: 0.2115  max mem: 6909\n",
            "Epoch: [0]  [ 150/3605]  eta: 1:05:12  lr: 0.000759  loss: 2.9087 (4.2785)  loss_classifier: 2.2517 (3.3094)  loss_box_reg: 0.3504 (0.3751)  loss_objectness: 0.0855 (0.3496)  loss_rpn_box_reg: 0.2141 (0.2444)  time: 1.1098  data: 0.2093  max mem: 6909\n",
            "Epoch: [0]  [ 160/3605]  eta: 1:05:13  lr: 0.000809  loss: 2.8869 (4.1963)  loss_classifier: 2.2300 (3.2440)  loss_box_reg: 0.3486 (0.3758)  loss_objectness: 0.1029 (0.3349)  loss_rpn_box_reg: 0.2141 (0.2416)  time: 1.1619  data: 0.2452  max mem: 6909\n",
            "Epoch: [0]  [ 170/3605]  eta: 1:05:03  lr: 0.000859  loss: 2.8756 (4.1166)  loss_classifier: 2.1845 (3.1814)  loss_box_reg: 0.3578 (0.3739)  loss_objectness: 0.1029 (0.3210)  loss_rpn_box_reg: 0.2009 (0.2402)  time: 1.1670  data: 0.2399  max mem: 6909\n",
            "Epoch: [0]  [ 180/3605]  eta: 1:04:45  lr: 0.000909  loss: 2.8155 (4.0448)  loss_classifier: 2.1421 (3.1230)  loss_box_reg: 0.3355 (0.3719)  loss_objectness: 0.0945 (0.3104)  loss_rpn_box_reg: 0.2038 (0.2395)  time: 1.1209  data: 0.2173  max mem: 6909\n",
            "Epoch: [0]  [ 190/3605]  eta: 1:04:24  lr: 0.000959  loss: 2.7711 (3.9769)  loss_classifier: 2.0877 (3.0687)  loss_box_reg: 0.3249 (0.3707)  loss_objectness: 0.0964 (0.2997)  loss_rpn_box_reg: 0.2020 (0.2378)  time: 1.0889  data: 0.1898  max mem: 6909\n",
            "Epoch: [0]  [ 200/3605]  eta: 1:04:06  lr: 0.001009  loss: 2.7092 (3.9144)  loss_classifier: 2.0518 (3.0178)  loss_box_reg: 0.3408 (0.3704)  loss_objectness: 0.0959 (0.2895)  loss_rpn_box_reg: 0.1999 (0.2367)  time: 1.0865  data: 0.1813  max mem: 6909\n",
            "Epoch: [0]  [ 210/3605]  eta: 1:03:51  lr: 0.001059  loss: 2.6994 (3.8578)  loss_classifier: 2.0169 (2.9707)  loss_box_reg: 0.3429 (0.3708)  loss_objectness: 0.0890 (0.2803)  loss_rpn_box_reg: 0.2055 (0.2359)  time: 1.1007  data: 0.1903  max mem: 6909\n",
            "Epoch: [0]  [ 220/3605]  eta: 1:03:38  lr: 0.001109  loss: 2.5968 (3.8046)  loss_classifier: 1.9652 (2.9279)  loss_box_reg: 0.3646 (0.3707)  loss_objectness: 0.0890 (0.2718)  loss_rpn_box_reg: 0.1968 (0.2342)  time: 1.1123  data: 0.1876  max mem: 6909\n",
            "Epoch: [0]  [ 230/3605]  eta: 1:03:25  lr: 0.001159  loss: 2.5865 (3.7513)  loss_classifier: 1.9054 (2.8832)  loss_box_reg: 0.3467 (0.3693)  loss_objectness: 0.1070 (0.2651)  loss_rpn_box_reg: 0.1957 (0.2337)  time: 1.1160  data: 0.1944  max mem: 6909\n",
            "Epoch: [0]  [ 240/3605]  eta: 1:03:17  lr: 0.001209  loss: 2.5284 (3.7038)  loss_classifier: 1.8777 (2.8433)  loss_box_reg: 0.3446 (0.3698)  loss_objectness: 0.1070 (0.2583)  loss_rpn_box_reg: 0.1878 (0.2323)  time: 1.1334  data: 0.2064  max mem: 6909\n",
            "Epoch: [0]  [ 250/3605]  eta: 1:03:11  lr: 0.001259  loss: 2.5031 (3.6548)  loss_classifier: 1.8321 (2.8023)  loss_box_reg: 0.3458 (0.3694)  loss_objectness: 0.0950 (0.2511)  loss_rpn_box_reg: 0.2141 (0.2320)  time: 1.1589  data: 0.2232  max mem: 6909\n",
            "Epoch: [0]  [ 260/3605]  eta: 1:02:52  lr: 0.001309  loss: 2.4458 (3.6097)  loss_classifier: 1.7857 (2.7631)  loss_box_reg: 0.3640 (0.3702)  loss_objectness: 0.0950 (0.2455)  loss_rpn_box_reg: 0.2155 (0.2309)  time: 1.1191  data: 0.2162  max mem: 6909\n",
            "Epoch: [0]  [ 270/3605]  eta: 1:02:33  lr: 0.001359  loss: 2.4213 (3.5655)  loss_classifier: 1.7376 (2.7258)  loss_box_reg: 0.3640 (0.3707)  loss_objectness: 0.0768 (0.2396)  loss_rpn_box_reg: 0.1950 (0.2294)  time: 1.0702  data: 0.1747  max mem: 6909\n",
            "Epoch: [0]  [ 280/3605]  eta: 1:02:18  lr: 0.001409  loss: 2.3261 (3.5224)  loss_classifier: 1.7188 (2.6899)  loss_box_reg: 0.3247 (0.3695)  loss_objectness: 0.0692 (0.2346)  loss_rpn_box_reg: 0.1950 (0.2284)  time: 1.0782  data: 0.1611  max mem: 6909\n",
            "Epoch: [0]  [ 290/3605]  eta: 1:02:09  lr: 0.001459  loss: 2.3244 (3.4804)  loss_classifier: 1.7084 (2.6564)  loss_box_reg: 0.3114 (0.3673)  loss_objectness: 0.0865 (0.2296)  loss_rpn_box_reg: 0.2010 (0.2271)  time: 1.1197  data: 0.1937  max mem: 6909\n",
            "Epoch: [0]  [ 300/3605]  eta: 1:01:59  lr: 0.001508  loss: 2.3047 (3.4444)  loss_classifier: 1.7409 (2.6295)  loss_box_reg: 0.2994 (0.3660)  loss_objectness: 0.0683 (0.2240)  loss_rpn_box_reg: 0.1658 (0.2249)  time: 1.1402  data: 0.2080  max mem: 6909\n",
            "Epoch: [0]  [ 310/3605]  eta: 1:01:44  lr: 0.001558  loss: 2.2635 (3.4069)  loss_classifier: 1.7497 (2.5988)  loss_box_reg: 0.3040 (0.3651)  loss_objectness: 0.0570 (0.2192)  loss_rpn_box_reg: 0.1658 (0.2238)  time: 1.1096  data: 0.2000  max mem: 6909\n",
            "Epoch: [0]  [ 320/3605]  eta: 1:01:35  lr: 0.001608  loss: 2.3034 (3.3735)  loss_classifier: 1.7026 (2.5703)  loss_box_reg: 0.3184 (0.3635)  loss_objectness: 0.0570 (0.2154)  loss_rpn_box_reg: 0.2049 (0.2243)  time: 1.1219  data: 0.2151  max mem: 6909\n",
            "Epoch: [0]  [ 330/3605]  eta: 1:01:25  lr: 0.001658  loss: 2.3204 (3.3409)  loss_classifier: 1.7131 (2.5435)  loss_box_reg: 0.3165 (0.3626)  loss_objectness: 0.0644 (0.2111)  loss_rpn_box_reg: 0.2327 (0.2237)  time: 1.1448  data: 0.2270  max mem: 6909\n",
            "Epoch: [0]  [ 340/3605]  eta: 1:01:11  lr: 0.001708  loss: 2.3111 (3.3085)  loss_classifier: 1.7131 (2.5169)  loss_box_reg: 0.3243 (0.3620)  loss_objectness: 0.0611 (0.2070)  loss_rpn_box_reg: 0.2101 (0.2227)  time: 1.1158  data: 0.2146  max mem: 6909\n",
            "Epoch: [0]  [ 350/3605]  eta: 1:00:58  lr: 0.001758  loss: 2.2945 (3.2772)  loss_classifier: 1.6622 (2.4916)  loss_box_reg: 0.3315 (0.3608)  loss_objectness: 0.0611 (0.2036)  loss_rpn_box_reg: 0.1869 (0.2213)  time: 1.0972  data: 0.1916  max mem: 6909\n",
            "Epoch: [0]  [ 360/3605]  eta: 1:00:46  lr: 0.001808  loss: 2.2284 (3.2530)  loss_classifier: 1.6207 (2.4707)  loss_box_reg: 0.3315 (0.3609)  loss_objectness: 0.0845 (0.2001)  loss_rpn_box_reg: 0.1869 (0.2212)  time: 1.1118  data: 0.1970  max mem: 6909\n",
            "Epoch: [0]  [ 370/3605]  eta: 1:00:33  lr: 0.001858  loss: 2.2868 (3.2280)  loss_classifier: 1.6509 (2.4509)  loss_box_reg: 0.3407 (0.3609)  loss_objectness: 0.0582 (0.1963)  loss_rpn_box_reg: 0.1815 (0.2200)  time: 1.1101  data: 0.1979  max mem: 6909\n",
            "Epoch: [0]  [ 380/3605]  eta: 1:00:22  lr: 0.001908  loss: 2.1823 (3.1941)  loss_classifier: 1.6051 (2.4236)  loss_box_reg: 0.3297 (0.3586)  loss_objectness: 0.0534 (0.1933)  loss_rpn_box_reg: 0.1810 (0.2186)  time: 1.1118  data: 0.1944  max mem: 6909\n",
            "Epoch: [0]  [ 390/3605]  eta: 1:00:13  lr: 0.001958  loss: 2.1602 (3.1702)  loss_classifier: 1.5978 (2.4036)  loss_box_reg: 0.2793 (0.3571)  loss_objectness: 0.0808 (0.1908)  loss_rpn_box_reg: 0.1968 (0.2187)  time: 1.1377  data: 0.2004  max mem: 6909\n",
            "Epoch: [0]  [ 400/3605]  eta: 1:00:03  lr: 0.002008  loss: 2.1602 (3.1446)  loss_classifier: 1.6152 (2.3832)  loss_box_reg: 0.2885 (0.3559)  loss_objectness: 0.0705 (0.1879)  loss_rpn_box_reg: 0.1991 (0.2177)  time: 1.1443  data: 0.1986  max mem: 6909\n",
            "Epoch: [0]  [ 410/3605]  eta: 0:59:51  lr: 0.002058  loss: 2.0866 (3.1235)  loss_classifier: 1.5616 (2.3661)  loss_box_reg: 0.3045 (0.3560)  loss_objectness: 0.0540 (0.1845)  loss_rpn_box_reg: 0.1809 (0.2168)  time: 1.1305  data: 0.2086  max mem: 6909\n",
            "Epoch: [0]  [ 420/3605]  eta: 0:59:41  lr: 0.002108  loss: 2.0834 (3.0996)  loss_classifier: 1.5615 (2.3465)  loss_box_reg: 0.3178 (0.3552)  loss_objectness: 0.0506 (0.1817)  loss_rpn_box_reg: 0.1793 (0.2162)  time: 1.1307  data: 0.2242  max mem: 6909\n",
            "Epoch: [0]  [ 430/3605]  eta: 0:59:31  lr: 0.002158  loss: 2.0834 (3.0814)  loss_classifier: 1.5286 (2.3312)  loss_box_reg: 0.3178 (0.3550)  loss_objectness: 0.0726 (0.1794)  loss_rpn_box_reg: 0.1934 (0.2158)  time: 1.1423  data: 0.2285  max mem: 6909\n",
            "Epoch: [0]  [ 440/3605]  eta: 0:59:20  lr: 0.002208  loss: 2.0444 (3.0598)  loss_classifier: 1.5239 (2.3132)  loss_box_reg: 0.2748 (0.3541)  loss_objectness: 0.0650 (0.1770)  loss_rpn_box_reg: 0.1900 (0.2154)  time: 1.1307  data: 0.2224  max mem: 6909\n",
            "Epoch: [0]  [ 450/3605]  eta: 0:59:08  lr: 0.002258  loss: 1.9523 (3.0324)  loss_classifier: 1.3990 (2.2910)  loss_box_reg: 0.2637 (0.3522)  loss_objectness: 0.0560 (0.1745)  loss_rpn_box_reg: 0.1804 (0.2147)  time: 1.1210  data: 0.2207  max mem: 6909\n",
            "Epoch: [0]  [ 460/3605]  eta: 0:58:59  lr: 0.002308  loss: 1.9897 (3.0160)  loss_classifier: 1.4172 (2.2770)  loss_box_reg: 0.2637 (0.3511)  loss_objectness: 0.0709 (0.1730)  loss_rpn_box_reg: 0.2007 (0.2149)  time: 1.1350  data: 0.2255  max mem: 6909\n",
            "Epoch: [0]  [ 470/3605]  eta: 0:58:46  lr: 0.002358  loss: 2.0555 (2.9952)  loss_classifier: 1.4734 (2.2592)  loss_box_reg: 0.2671 (0.3498)  loss_objectness: 0.0795 (0.1714)  loss_rpn_box_reg: 0.2124 (0.2147)  time: 1.1287  data: 0.2108  max mem: 6909\n",
            "Epoch: [0]  [ 480/3605]  eta: 0:58:33  lr: 0.002408  loss: 2.0317 (2.9768)  loss_classifier: 1.4688 (2.2447)  loss_box_reg: 0.2812 (0.3490)  loss_objectness: 0.0601 (0.1693)  loss_rpn_box_reg: 0.1800 (0.2137)  time: 1.1042  data: 0.1829  max mem: 6909\n",
            "Epoch: [0]  [ 490/3605]  eta: 0:58:23  lr: 0.002458  loss: 2.1369 (2.9597)  loss_classifier: 1.5137 (2.2296)  loss_box_reg: 0.2879 (0.3480)  loss_objectness: 0.0579 (0.1681)  loss_rpn_box_reg: 0.1837 (0.2140)  time: 1.1150  data: 0.1874  max mem: 6909\n",
            "Epoch: [0]  [ 500/3605]  eta: 0:58:11  lr: 0.002507  loss: 2.0739 (2.9416)  loss_classifier: 1.4682 (2.2157)  loss_box_reg: 0.2665 (0.3461)  loss_objectness: 0.0696 (0.1666)  loss_rpn_box_reg: 0.1726 (0.2131)  time: 1.1236  data: 0.2013  max mem: 6909\n",
            "Epoch: [0]  [ 510/3605]  eta: 0:57:58  lr: 0.002557  loss: 1.9909 (2.9269)  loss_classifier: 1.4724 (2.2031)  loss_box_reg: 0.2665 (0.3459)  loss_objectness: 0.0744 (0.1652)  loss_rpn_box_reg: 0.1595 (0.2128)  time: 1.1083  data: 0.1934  max mem: 6909\n",
            "Epoch: [0]  [ 520/3605]  eta: 0:57:46  lr: 0.002607  loss: 2.0323 (2.9110)  loss_classifier: 1.4831 (2.1896)  loss_box_reg: 0.3170 (0.3454)  loss_objectness: 0.0650 (0.1634)  loss_rpn_box_reg: 0.1757 (0.2126)  time: 1.1038  data: 0.1876  max mem: 6909\n",
            "Epoch: [0]  [ 530/3605]  eta: 0:57:36  lr: 0.002657  loss: 2.0225 (2.8941)  loss_classifier: 1.4610 (2.1753)  loss_box_reg: 0.3111 (0.3447)  loss_objectness: 0.0511 (0.1616)  loss_rpn_box_reg: 0.1918 (0.2125)  time: 1.1237  data: 0.2064  max mem: 6909\n",
            "Epoch: [0]  [ 540/3605]  eta: 0:57:28  lr: 0.002707  loss: 2.0155 (2.8792)  loss_classifier: 1.4619 (2.1633)  loss_box_reg: 0.2668 (0.3431)  loss_objectness: 0.0726 (0.1602)  loss_rpn_box_reg: 0.1948 (0.2125)  time: 1.1676  data: 0.2213  max mem: 6909\n",
            "Epoch: [0]  [ 550/3605]  eta: 0:57:19  lr: 0.002757  loss: 2.0155 (2.8626)  loss_classifier: 1.4619 (2.1505)  loss_box_reg: 0.2628 (0.3420)  loss_objectness: 0.0726 (0.1585)  loss_rpn_box_reg: 0.1829 (0.2117)  time: 1.1761  data: 0.2160  max mem: 6909\n",
            "Epoch: [0]  [ 560/3605]  eta: 0:57:06  lr: 0.002807  loss: 1.9718 (2.8493)  loss_classifier: 1.4460 (2.1403)  loss_box_reg: 0.2854 (0.3413)  loss_objectness: 0.0492 (0.1567)  loss_rpn_box_reg: 0.1596 (0.2111)  time: 1.1318  data: 0.2066  max mem: 6909\n",
            "Epoch: [0]  [ 570/3605]  eta: 0:56:55  lr: 0.002857  loss: 2.0839 (2.8362)  loss_classifier: 1.5048 (2.1301)  loss_box_reg: 0.2979 (0.3408)  loss_objectness: 0.0621 (0.1549)  loss_rpn_box_reg: 0.1559 (0.2105)  time: 1.1111  data: 0.1966  max mem: 6909\n",
            "Epoch: [0]  [ 580/3605]  eta: 0:56:44  lr: 0.002907  loss: 1.9439 (2.8218)  loss_classifier: 1.4245 (2.1183)  loss_box_reg: 0.2916 (0.3400)  loss_objectness: 0.0621 (0.1532)  loss_rpn_box_reg: 0.1681 (0.2103)  time: 1.1274  data: 0.2031  max mem: 6909\n",
            "Epoch: [0]  [ 590/3605]  eta: 0:56:33  lr: 0.002957  loss: 1.9216 (2.8077)  loss_classifier: 1.3636 (2.1066)  loss_box_reg: 0.2944 (0.3394)  loss_objectness: 0.0550 (0.1518)  loss_rpn_box_reg: 0.1837 (0.2099)  time: 1.1314  data: 0.2090  max mem: 6909\n",
            "Epoch: [0]  [ 600/3605]  eta: 0:56:21  lr: 0.003007  loss: 1.9369 (2.7970)  loss_classifier: 1.4038 (2.0975)  loss_box_reg: 0.2984 (0.3392)  loss_objectness: 0.0424 (0.1511)  loss_rpn_box_reg: 0.1710 (0.2093)  time: 1.1189  data: 0.1985  max mem: 6909\n",
            "Epoch: [0]  [ 610/3605]  eta: 0:56:11  lr: 0.003057  loss: 1.9724 (2.7857)  loss_classifier: 1.5041 (2.0873)  loss_box_reg: 0.2914 (0.3388)  loss_objectness: 0.0724 (0.1503)  loss_rpn_box_reg: 0.1758 (0.2093)  time: 1.1331  data: 0.2089  max mem: 6909\n",
            "Epoch: [0]  [ 620/3605]  eta: 0:56:00  lr: 0.003107  loss: 1.8959 (2.7728)  loss_classifier: 1.3281 (2.0760)  loss_box_reg: 0.2879 (0.3384)  loss_objectness: 0.0793 (0.1489)  loss_rpn_box_reg: 0.1844 (0.2094)  time: 1.1456  data: 0.2172  max mem: 6909\n",
            "Epoch: [0]  [ 630/3605]  eta: 0:55:50  lr: 0.003157  loss: 1.8543 (2.7586)  loss_classifier: 1.3074 (2.0644)  loss_box_reg: 0.2733 (0.3375)  loss_objectness: 0.0653 (0.1478)  loss_rpn_box_reg: 0.1794 (0.2090)  time: 1.1437  data: 0.2082  max mem: 6909\n",
            "Epoch: [0]  [ 640/3605]  eta: 0:55:37  lr: 0.003207  loss: 1.8437 (2.7448)  loss_classifier: 1.3249 (2.0532)  loss_box_reg: 0.2733 (0.3370)  loss_objectness: 0.0498 (0.1462)  loss_rpn_box_reg: 0.1629 (0.2084)  time: 1.1149  data: 0.1871  max mem: 6909\n",
            "Epoch: [0]  [ 650/3605]  eta: 0:55:27  lr: 0.003257  loss: 1.9005 (2.7333)  loss_classifier: 1.3815 (2.0439)  loss_box_reg: 0.2767 (0.3362)  loss_objectness: 0.0464 (0.1450)  loss_rpn_box_reg: 0.1743 (0.2081)  time: 1.1151  data: 0.2017  max mem: 6909\n",
            "Epoch: [0]  [ 660/3605]  eta: 0:55:17  lr: 0.003307  loss: 1.8847 (2.7204)  loss_classifier: 1.3775 (2.0334)  loss_box_reg: 0.2767 (0.3354)  loss_objectness: 0.0464 (0.1435)  loss_rpn_box_reg: 0.1921 (0.2080)  time: 1.1519  data: 0.2361  max mem: 6909\n",
            "Epoch: [0]  [ 670/3605]  eta: 0:55:05  lr: 0.003357  loss: 1.8363 (2.7122)  loss_classifier: 1.3520 (2.0268)  loss_box_reg: 0.2761 (0.3353)  loss_objectness: 0.0511 (0.1425)  loss_rpn_box_reg: 0.1734 (0.2076)  time: 1.1342  data: 0.2191  max mem: 6909\n",
            "Epoch: [0]  [ 680/3605]  eta: 0:54:54  lr: 0.003407  loss: 1.8693 (2.7007)  loss_classifier: 1.3580 (2.0179)  loss_box_reg: 0.2749 (0.3346)  loss_objectness: 0.0548 (0.1413)  loss_rpn_box_reg: 0.1597 (0.2069)  time: 1.1183  data: 0.2020  max mem: 6909\n",
            "Epoch: [0]  [ 690/3605]  eta: 0:54:40  lr: 0.003457  loss: 1.8682 (2.6890)  loss_classifier: 1.3236 (2.0078)  loss_box_reg: 0.2938 (0.3342)  loss_objectness: 0.0548 (0.1403)  loss_rpn_box_reg: 0.1744 (0.2068)  time: 1.1016  data: 0.1943  max mem: 6909\n",
            "Epoch: [0]  [ 700/3605]  eta: 0:54:29  lr: 0.003506  loss: 1.8252 (2.6761)  loss_classifier: 1.2943 (1.9974)  loss_box_reg: 0.2862 (0.3332)  loss_objectness: 0.0541 (0.1390)  loss_rpn_box_reg: 0.1948 (0.2065)  time: 1.1001  data: 0.1953  max mem: 6909\n",
            "Epoch: [0]  [ 710/3605]  eta: 0:54:19  lr: 0.003556  loss: 1.8938 (2.6688)  loss_classifier: 1.3476 (1.9916)  loss_box_reg: 0.2708 (0.3331)  loss_objectness: 0.0510 (0.1380)  loss_rpn_box_reg: 0.1823 (0.2061)  time: 1.1443  data: 0.2239  max mem: 6909\n",
            "Epoch: [0]  [ 720/3605]  eta: 0:54:07  lr: 0.003606  loss: 1.9809 (2.6546)  loss_classifier: 1.4048 (1.9802)  loss_box_reg: 0.2823 (0.3320)  loss_objectness: 0.0516 (0.1369)  loss_rpn_box_reg: 0.1735 (0.2056)  time: 1.1308  data: 0.2236  max mem: 6909\n",
            "Epoch: [0]  [ 730/3605]  eta: 0:53:55  lr: 0.003656  loss: 1.8438 (2.6437)  loss_classifier: 1.3584 (1.9712)  loss_box_reg: 0.2669 (0.3311)  loss_objectness: 0.0524 (0.1360)  loss_rpn_box_reg: 0.1749 (0.2054)  time: 1.1036  data: 0.2088  max mem: 6909\n",
            "Epoch: [0]  [ 740/3605]  eta: 0:53:43  lr: 0.003706  loss: 1.8180 (2.6333)  loss_classifier: 1.3624 (1.9631)  loss_box_reg: 0.2555 (0.3302)  loss_objectness: 0.0524 (0.1350)  loss_rpn_box_reg: 0.1766 (0.2050)  time: 1.1146  data: 0.1947  max mem: 6909\n",
            "Epoch: [0]  [ 750/3605]  eta: 0:53:32  lr: 0.003756  loss: 1.7235 (2.6219)  loss_classifier: 1.2811 (1.9539)  loss_box_reg: 0.2532 (0.3296)  loss_objectness: 0.0463 (0.1339)  loss_rpn_box_reg: 0.1707 (0.2045)  time: 1.1239  data: 0.1969  max mem: 6909\n",
            "Epoch: [0]  [ 760/3605]  eta: 0:53:21  lr: 0.003806  loss: 1.7726 (2.6126)  loss_classifier: 1.2717 (1.9455)  loss_box_reg: 0.2769 (0.3294)  loss_objectness: 0.0540 (0.1332)  loss_rpn_box_reg: 0.1823 (0.2045)  time: 1.1238  data: 0.2076  max mem: 6909\n",
            "Epoch: [0]  [ 770/3605]  eta: 0:53:10  lr: 0.003856  loss: 1.8915 (2.6036)  loss_classifier: 1.3963 (1.9378)  loss_box_reg: 0.2941 (0.3292)  loss_objectness: 0.0598 (0.1325)  loss_rpn_box_reg: 0.1689 (0.2042)  time: 1.1229  data: 0.1956  max mem: 6909\n",
            "Epoch: [0]  [ 780/3605]  eta: 0:52:58  lr: 0.003906  loss: 1.9021 (2.5955)  loss_classifier: 1.2693 (1.9307)  loss_box_reg: 0.2913 (0.3290)  loss_objectness: 0.0559 (0.1315)  loss_rpn_box_reg: 0.1629 (0.2042)  time: 1.1173  data: 0.2053  max mem: 6909\n",
            "Epoch: [0]  [ 790/3605]  eta: 0:52:48  lr: 0.003956  loss: 1.9304 (2.5878)  loss_classifier: 1.2857 (1.9241)  loss_box_reg: 0.2934 (0.3288)  loss_objectness: 0.0554 (0.1308)  loss_rpn_box_reg: 0.1913 (0.2041)  time: 1.1328  data: 0.2334  max mem: 6909\n",
            "Epoch: [0]  [ 800/3605]  eta: 0:52:37  lr: 0.004006  loss: 2.0596 (2.5807)  loss_classifier: 1.3692 (1.9178)  loss_box_reg: 0.2919 (0.3285)  loss_objectness: 0.0554 (0.1301)  loss_rpn_box_reg: 0.2100 (0.2043)  time: 1.1480  data: 0.2253  max mem: 6909\n",
            "Epoch: [0]  [ 810/3605]  eta: 0:52:25  lr: 0.004056  loss: 1.8584 (2.5719)  loss_classifier: 1.3399 (1.9105)  loss_box_reg: 0.2812 (0.3277)  loss_objectness: 0.0565 (0.1295)  loss_rpn_box_reg: 0.2088 (0.2042)  time: 1.1268  data: 0.2051  max mem: 6909\n",
            "Epoch: [0]  [ 820/3605]  eta: 0:52:16  lr: 0.004106  loss: 1.7924 (2.5630)  loss_classifier: 1.3110 (1.9031)  loss_box_reg: 0.2428 (0.3269)  loss_objectness: 0.0603 (0.1288)  loss_rpn_box_reg: 0.1903 (0.2042)  time: 1.1523  data: 0.2219  max mem: 6909\n",
            "Epoch: [0]  [ 830/3605]  eta: 0:52:04  lr: 0.004156  loss: 1.8172 (2.5554)  loss_classifier: 1.3203 (1.8965)  loss_box_reg: 0.2595 (0.3265)  loss_objectness: 0.0621 (0.1281)  loss_rpn_box_reg: 0.2121 (0.2044)  time: 1.1477  data: 0.2205  max mem: 6909\n",
            "Epoch: [0]  [ 840/3605]  eta: 0:51:52  lr: 0.004206  loss: 2.0049 (2.5506)  loss_classifier: 1.3909 (1.8921)  loss_box_reg: 0.2906 (0.3264)  loss_objectness: 0.0729 (0.1277)  loss_rpn_box_reg: 0.2032 (0.2045)  time: 1.1056  data: 0.1933  max mem: 6909\n",
            "Epoch: [0]  [ 850/3605]  eta: 0:51:39  lr: 0.004256  loss: 2.0809 (2.5458)  loss_classifier: 1.4520 (1.8880)  loss_box_reg: 0.3095 (0.3264)  loss_objectness: 0.0814 (0.1271)  loss_rpn_box_reg: 0.1901 (0.2043)  time: 1.0875  data: 0.1832  max mem: 6909\n",
            "Epoch: [0]  [ 860/3605]  eta: 0:51:28  lr: 0.004306  loss: 1.8896 (2.5369)  loss_classifier: 1.3396 (1.8809)  loss_box_reg: 0.2793 (0.3257)  loss_objectness: 0.0605 (0.1263)  loss_rpn_box_reg: 0.1666 (0.2040)  time: 1.1062  data: 0.1978  max mem: 6909\n",
            "Epoch: [0]  [ 870/3605]  eta: 0:51:16  lr: 0.004356  loss: 1.7063 (2.5285)  loss_classifier: 1.2127 (1.8742)  loss_box_reg: 0.2599 (0.3253)  loss_objectness: 0.0487 (0.1254)  loss_rpn_box_reg: 0.1658 (0.2036)  time: 1.1188  data: 0.1959  max mem: 6909\n",
            "Epoch: [0]  [ 880/3605]  eta: 0:51:06  lr: 0.004406  loss: 1.7998 (2.5212)  loss_classifier: 1.2862 (1.8678)  loss_box_reg: 0.2638 (0.3247)  loss_objectness: 0.0551 (0.1250)  loss_rpn_box_reg: 0.1808 (0.2036)  time: 1.1201  data: 0.2051  max mem: 6909\n",
            "Epoch: [0]  [ 890/3605]  eta: 0:50:54  lr: 0.004456  loss: 1.8681 (2.5145)  loss_classifier: 1.2862 (1.8614)  loss_box_reg: 0.2730 (0.3243)  loss_objectness: 0.0960 (0.1249)  loss_rpn_box_reg: 0.2082 (0.2039)  time: 1.1292  data: 0.2238  max mem: 6909\n",
            "Epoch: [0]  [ 900/3605]  eta: 0:50:43  lr: 0.004505  loss: 1.8002 (2.5074)  loss_classifier: 1.2407 (1.8551)  loss_box_reg: 0.2924 (0.3240)  loss_objectness: 0.0732 (0.1243)  loss_rpn_box_reg: 0.2082 (0.2040)  time: 1.1285  data: 0.2153  max mem: 6909\n",
            "Epoch: [0]  [ 910/3605]  eta: 0:50:32  lr: 0.004555  loss: 1.7772 (2.4998)  loss_classifier: 1.2966 (1.8491)  loss_box_reg: 0.2814 (0.3234)  loss_objectness: 0.0639 (0.1236)  loss_rpn_box_reg: 0.1932 (0.2037)  time: 1.1309  data: 0.2003  max mem: 6909\n",
            "Epoch: [0]  [ 920/3605]  eta: 0:50:20  lr: 0.004605  loss: 1.8030 (2.4922)  loss_classifier: 1.3373 (1.8431)  loss_box_reg: 0.2652 (0.3229)  loss_objectness: 0.0537 (0.1229)  loss_rpn_box_reg: 0.1610 (0.2033)  time: 1.1137  data: 0.1938  max mem: 6909\n",
            "Epoch: [0]  [ 930/3605]  eta: 0:50:09  lr: 0.004655  loss: 1.8397 (2.4848)  loss_classifier: 1.3409 (1.8372)  loss_box_reg: 0.2604 (0.3221)  loss_objectness: 0.0497 (0.1223)  loss_rpn_box_reg: 0.1691 (0.2033)  time: 1.1119  data: 0.1992  max mem: 6909\n",
            "Epoch: [0]  [ 940/3605]  eta: 0:49:58  lr: 0.004705  loss: 1.7868 (2.4775)  loss_classifier: 1.2725 (1.8312)  loss_box_reg: 0.2535 (0.3215)  loss_objectness: 0.0551 (0.1217)  loss_rpn_box_reg: 0.1812 (0.2031)  time: 1.1262  data: 0.1950  max mem: 6909\n",
            "Epoch: [0]  [ 950/3605]  eta: 0:49:47  lr: 0.004755  loss: 1.8291 (2.4710)  loss_classifier: 1.2725 (1.8256)  loss_box_reg: 0.2541 (0.3210)  loss_objectness: 0.0670 (0.1215)  loss_rpn_box_reg: 0.1769 (0.2029)  time: 1.1370  data: 0.2119  max mem: 6909\n",
            "Epoch: [0]  [ 960/3605]  eta: 0:49:36  lr: 0.004805  loss: 1.8371 (2.4641)  loss_classifier: 1.2530 (1.8195)  loss_box_reg: 0.2665 (0.3206)  loss_objectness: 0.0804 (0.1211)  loss_rpn_box_reg: 0.1932 (0.2030)  time: 1.1399  data: 0.2225  max mem: 6909\n",
            "Epoch: [0]  [ 970/3605]  eta: 0:49:24  lr: 0.004855  loss: 1.7035 (2.4574)  loss_classifier: 1.1567 (1.8138)  loss_box_reg: 0.2648 (0.3202)  loss_objectness: 0.0697 (0.1206)  loss_rpn_box_reg: 0.1933 (0.2028)  time: 1.1151  data: 0.1955  max mem: 6909\n",
            "Epoch: [0]  [ 980/3605]  eta: 0:49:11  lr: 0.004905  loss: 1.6414 (2.4498)  loss_classifier: 1.1418 (1.8077)  loss_box_reg: 0.2599 (0.3198)  loss_objectness: 0.0438 (0.1198)  loss_rpn_box_reg: 0.1769 (0.2025)  time: 1.0815  data: 0.1772  max mem: 6909\n",
            "Epoch: [0]  [ 990/3605]  eta: 0:48:59  lr: 0.004955  loss: 1.6156 (2.4426)  loss_classifier: 1.1418 (1.8021)  loss_box_reg: 0.2449 (0.3193)  loss_objectness: 0.0381 (0.1191)  loss_rpn_box_reg: 0.1769 (0.2021)  time: 1.0872  data: 0.1902  max mem: 6909\n",
            "Epoch: [0]  [1000/3605]  eta: 0:48:48  lr: 0.005000  loss: 1.7512 (2.4381)  loss_classifier: 1.2457 (1.7985)  loss_box_reg: 0.2657 (0.3193)  loss_objectness: 0.0444 (0.1183)  loss_rpn_box_reg: 0.1734 (0.2019)  time: 1.1138  data: 0.2024  max mem: 6909\n",
            "Epoch: [0]  [1010/3605]  eta: 0:48:37  lr: 0.005000  loss: 1.9127 (2.4325)  loss_classifier: 1.3463 (1.7942)  loss_box_reg: 0.2685 (0.3189)  loss_objectness: 0.0511 (0.1177)  loss_rpn_box_reg: 0.1712 (0.2017)  time: 1.1203  data: 0.1987  max mem: 6909\n",
            "Epoch: [0]  [1020/3605]  eta: 0:48:26  lr: 0.005000  loss: 1.6938 (2.4262)  loss_classifier: 1.1991 (1.7891)  loss_box_reg: 0.2547 (0.3183)  loss_objectness: 0.0511 (0.1172)  loss_rpn_box_reg: 0.1766 (0.2016)  time: 1.1291  data: 0.2174  max mem: 6909\n",
            "Epoch: [0]  [1030/3605]  eta: 0:48:14  lr: 0.005000  loss: 1.7050 (2.4205)  loss_classifier: 1.2422 (1.7844)  loss_box_reg: 0.2420 (0.3181)  loss_objectness: 0.0460 (0.1166)  loss_rpn_box_reg: 0.1994 (0.2015)  time: 1.1226  data: 0.2140  max mem: 6909\n",
            "Epoch: [0]  [1040/3605]  eta: 0:48:03  lr: 0.005000  loss: 1.7348 (2.4153)  loss_classifier: 1.2257 (1.7800)  loss_box_reg: 0.2420 (0.3177)  loss_objectness: 0.0403 (0.1161)  loss_rpn_box_reg: 0.1994 (0.2015)  time: 1.1222  data: 0.2015  max mem: 6909\n",
            "Epoch: [0]  [1050/3605]  eta: 0:47:51  lr: 0.005000  loss: 1.8030 (2.4101)  loss_classifier: 1.2257 (1.7762)  loss_box_reg: 0.2505 (0.3176)  loss_objectness: 0.0386 (0.1153)  loss_rpn_box_reg: 0.1586 (0.2010)  time: 1.1185  data: 0.2036  max mem: 6909\n",
            "Epoch: [0]  [1060/3605]  eta: 0:47:41  lr: 0.005000  loss: 1.7811 (2.4037)  loss_classifier: 1.2564 (1.7710)  loss_box_reg: 0.2717 (0.3171)  loss_objectness: 0.0343 (0.1147)  loss_rpn_box_reg: 0.1783 (0.2009)  time: 1.1278  data: 0.2059  max mem: 6909\n",
            "Epoch: [0]  [1070/3605]  eta: 0:47:30  lr: 0.005000  loss: 1.6206 (2.3954)  loss_classifier: 1.1499 (1.7645)  loss_box_reg: 0.2462 (0.3163)  loss_objectness: 0.0354 (0.1140)  loss_rpn_box_reg: 0.1646 (0.2006)  time: 1.1549  data: 0.2100  max mem: 6909\n",
            "Epoch: [0]  [1080/3605]  eta: 0:47:19  lr: 0.005000  loss: 1.4872 (2.3875)  loss_classifier: 1.0203 (1.7579)  loss_box_reg: 0.2281 (0.3154)  loss_objectness: 0.0308 (0.1136)  loss_rpn_box_reg: 0.1644 (0.2006)  time: 1.1393  data: 0.1999  max mem: 6909\n",
            "Epoch: [0]  [1090/3605]  eta: 0:47:08  lr: 0.005000  loss: 1.4075 (2.3782)  loss_classifier: 0.9860 (1.7505)  loss_box_reg: 0.2281 (0.3146)  loss_objectness: 0.0371 (0.1129)  loss_rpn_box_reg: 0.1677 (0.2001)  time: 1.1202  data: 0.1989  max mem: 6909\n",
            "Epoch: [0]  [1100/3605]  eta: 0:46:56  lr: 0.005000  loss: 1.4435 (2.3719)  loss_classifier: 1.0183 (1.7448)  loss_box_reg: 0.2322 (0.3143)  loss_objectness: 0.0577 (0.1127)  loss_rpn_box_reg: 0.1850 (0.2002)  time: 1.1194  data: 0.2065  max mem: 6909\n",
            "Epoch: [0]  [1110/3605]  eta: 0:46:46  lr: 0.005000  loss: 1.6770 (2.3670)  loss_classifier: 1.1121 (1.7407)  loss_box_reg: 0.2567 (0.3139)  loss_objectness: 0.0630 (0.1122)  loss_rpn_box_reg: 0.1850 (0.2001)  time: 1.1355  data: 0.2178  max mem: 6909\n",
            "Epoch: [0]  [1120/3605]  eta: 0:46:33  lr: 0.005000  loss: 1.6666 (2.3602)  loss_classifier: 1.1553 (1.7353)  loss_box_reg: 0.2511 (0.3134)  loss_objectness: 0.0491 (0.1116)  loss_rpn_box_reg: 0.1728 (0.1999)  time: 1.1066  data: 0.1951  max mem: 6909\n",
            "Epoch: [0]  [1130/3605]  eta: 0:46:22  lr: 0.005000  loss: 1.6155 (2.3532)  loss_classifier: 1.1470 (1.7294)  loss_box_reg: 0.2472 (0.3127)  loss_objectness: 0.0548 (0.1111)  loss_rpn_box_reg: 0.1751 (0.1998)  time: 1.0959  data: 0.1866  max mem: 6909\n",
            "Epoch: [0]  [1140/3605]  eta: 0:46:11  lr: 0.005000  loss: 1.6711 (2.3482)  loss_classifier: 1.1470 (1.7251)  loss_box_reg: 0.2603 (0.3126)  loss_objectness: 0.0508 (0.1107)  loss_rpn_box_reg: 0.1907 (0.1999)  time: 1.1297  data: 0.2152  max mem: 6909\n",
            "Epoch: [0]  [1150/3605]  eta: 0:46:00  lr: 0.005000  loss: 1.7640 (2.3437)  loss_classifier: 1.2188 (1.7212)  loss_box_reg: 0.2603 (0.3122)  loss_objectness: 0.0500 (0.1104)  loss_rpn_box_reg: 0.1746 (0.1999)  time: 1.1373  data: 0.2120  max mem: 6909\n",
            "Epoch: [0]  [1160/3605]  eta: 0:45:50  lr: 0.005000  loss: 1.6927 (2.3396)  loss_classifier: 1.1853 (1.7179)  loss_box_reg: 0.2275 (0.3117)  loss_objectness: 0.0621 (0.1101)  loss_rpn_box_reg: 0.1731 (0.1999)  time: 1.1520  data: 0.2193  max mem: 6909\n",
            "Epoch: [0]  [1170/3605]  eta: 0:45:38  lr: 0.005000  loss: 1.6779 (2.3338)  loss_classifier: 1.1412 (1.7133)  loss_box_reg: 0.2419 (0.3113)  loss_objectness: 0.0503 (0.1095)  loss_rpn_box_reg: 0.1748 (0.1997)  time: 1.1445  data: 0.2073  max mem: 6909\n",
            "Epoch: [0]  [1180/3605]  eta: 0:45:27  lr: 0.005000  loss: 1.5511 (2.3273)  loss_classifier: 1.0940 (1.7081)  loss_box_reg: 0.2352 (0.3106)  loss_objectness: 0.0439 (0.1091)  loss_rpn_box_reg: 0.1877 (0.1996)  time: 1.1176  data: 0.1822  max mem: 6909\n",
            "Epoch: [0]  [1190/3605]  eta: 0:45:17  lr: 0.005000  loss: 1.5128 (2.3213)  loss_classifier: 1.0568 (1.7033)  loss_box_reg: 0.2227 (0.3101)  loss_objectness: 0.0452 (0.1086)  loss_rpn_box_reg: 0.1814 (0.1993)  time: 1.1422  data: 0.2127  max mem: 6909\n",
            "Epoch: [0]  [1200/3605]  eta: 0:45:05  lr: 0.005000  loss: 1.5342 (2.3153)  loss_classifier: 1.0735 (1.6985)  loss_box_reg: 0.2370 (0.3097)  loss_objectness: 0.0277 (0.1079)  loss_rpn_box_reg: 0.1633 (0.1991)  time: 1.1348  data: 0.2176  max mem: 6909\n",
            "Epoch: [0]  [1210/3605]  eta: 0:44:54  lr: 0.005000  loss: 1.5233 (2.3098)  loss_classifier: 1.1238 (1.6942)  loss_box_reg: 0.2370 (0.3093)  loss_objectness: 0.0217 (0.1072)  loss_rpn_box_reg: 0.1633 (0.1990)  time: 1.1232  data: 0.2180  max mem: 6909\n",
            "Epoch: [0]  [1220/3605]  eta: 0:44:43  lr: 0.005000  loss: 1.4505 (2.3020)  loss_classifier: 1.0018 (1.6880)  loss_box_reg: 0.2129 (0.3085)  loss_objectness: 0.0306 (0.1068)  loss_rpn_box_reg: 0.1593 (0.1987)  time: 1.1381  data: 0.2229  max mem: 6909\n",
            "Epoch: [0]  [1230/3605]  eta: 0:44:31  lr: 0.005000  loss: 1.5310 (2.2965)  loss_classifier: 1.0875 (1.6838)  loss_box_reg: 0.2240 (0.3079)  loss_objectness: 0.0414 (0.1063)  loss_rpn_box_reg: 0.1515 (0.1985)  time: 1.1082  data: 0.2009  max mem: 6909\n",
            "Epoch: [0]  [1240/3605]  eta: 0:44:20  lr: 0.005000  loss: 1.5310 (2.2906)  loss_classifier: 1.0875 (1.6790)  loss_box_reg: 0.2321 (0.3075)  loss_objectness: 0.0329 (0.1058)  loss_rpn_box_reg: 0.1674 (0.1983)  time: 1.1172  data: 0.2071  max mem: 6909\n",
            "Epoch: [0]  [1250/3605]  eta: 0:44:08  lr: 0.005000  loss: 1.5688 (2.2856)  loss_classifier: 1.0631 (1.6748)  loss_box_reg: 0.2258 (0.3070)  loss_objectness: 0.0392 (0.1054)  loss_rpn_box_reg: 0.1760 (0.1985)  time: 1.1175  data: 0.2043  max mem: 6909\n",
            "Epoch: [0]  [1260/3605]  eta: 0:43:56  lr: 0.005000  loss: 1.5609 (2.2793)  loss_classifier: 1.0488 (1.6699)  loss_box_reg: 0.2144 (0.3064)  loss_objectness: 0.0338 (0.1048)  loss_rpn_box_reg: 0.1662 (0.1982)  time: 1.0820  data: 0.1803  max mem: 6909\n",
            "Epoch: [0]  [1270/3605]  eta: 0:43:45  lr: 0.005000  loss: 1.4677 (2.2755)  loss_classifier: 1.0655 (1.6667)  loss_box_reg: 0.2079 (0.3062)  loss_objectness: 0.0383 (0.1045)  loss_rpn_box_reg: 0.1638 (0.1982)  time: 1.1086  data: 0.2039  max mem: 6909\n",
            "Epoch: [0]  [1280/3605]  eta: 0:43:34  lr: 0.005000  loss: 1.6826 (2.2712)  loss_classifier: 1.1053 (1.6632)  loss_box_reg: 0.2154 (0.3057)  loss_objectness: 0.0542 (0.1043)  loss_rpn_box_reg: 0.1691 (0.1980)  time: 1.1403  data: 0.2237  max mem: 6909\n",
            "Epoch: [0]  [1290/3605]  eta: 0:43:23  lr: 0.005000  loss: 1.5847 (2.2675)  loss_classifier: 1.1037 (1.6601)  loss_box_reg: 0.2403 (0.3054)  loss_objectness: 0.0594 (0.1041)  loss_rpn_box_reg: 0.1618 (0.1979)  time: 1.1281  data: 0.2018  max mem: 6909\n",
            "Epoch: [0]  [1300/3605]  eta: 0:43:12  lr: 0.005000  loss: 1.6662 (2.2635)  loss_classifier: 1.1373 (1.6565)  loss_box_reg: 0.2408 (0.3051)  loss_objectness: 0.0594 (0.1037)  loss_rpn_box_reg: 0.2089 (0.1981)  time: 1.1270  data: 0.2131  max mem: 6909\n",
            "Epoch: [0]  [1310/3605]  eta: 0:43:00  lr: 0.005000  loss: 1.6662 (2.2592)  loss_classifier: 1.1720 (1.6532)  loss_box_reg: 0.2382 (0.3049)  loss_objectness: 0.0466 (0.1033)  loss_rpn_box_reg: 0.1893 (0.1978)  time: 1.1249  data: 0.2119  max mem: 6909\n",
            "Epoch: [0]  [1320/3605]  eta: 0:42:48  lr: 0.005000  loss: 1.6102 (2.2544)  loss_classifier: 1.0855 (1.6493)  loss_box_reg: 0.2354 (0.3045)  loss_objectness: 0.0370 (0.1028)  loss_rpn_box_reg: 0.1734 (0.1978)  time: 1.1027  data: 0.1911  max mem: 6909\n",
            "Epoch: [0]  [1330/3605]  eta: 0:42:37  lr: 0.005000  loss: 1.6716 (2.2504)  loss_classifier: 1.0855 (1.6458)  loss_box_reg: 0.2416 (0.3043)  loss_objectness: 0.0370 (0.1026)  loss_rpn_box_reg: 0.1931 (0.1978)  time: 1.1189  data: 0.2077  max mem: 6909\n",
            "Epoch: [0]  [1340/3605]  eta: 0:42:26  lr: 0.005000  loss: 1.5891 (2.2447)  loss_classifier: 1.0145 (1.6409)  loss_box_reg: 0.2246 (0.3036)  loss_objectness: 0.0566 (0.1024)  loss_rpn_box_reg: 0.2032 (0.1978)  time: 1.1256  data: 0.2123  max mem: 6909\n",
            "Epoch: [0]  [1350/3605]  eta: 0:42:14  lr: 0.005000  loss: 1.4163 (2.2398)  loss_classifier: 0.9936 (1.6371)  loss_box_reg: 0.2115 (0.3031)  loss_objectness: 0.0635 (0.1021)  loss_rpn_box_reg: 0.1676 (0.1976)  time: 1.1069  data: 0.1889  max mem: 6909\n",
            "Epoch: [0]  [1360/3605]  eta: 0:42:03  lr: 0.005000  loss: 1.5116 (2.2350)  loss_classifier: 1.0594 (1.6332)  loss_box_reg: 0.2167 (0.3026)  loss_objectness: 0.0546 (0.1017)  loss_rpn_box_reg: 0.1693 (0.1975)  time: 1.1155  data: 0.1863  max mem: 6909\n",
            "Epoch: [0]  [1370/3605]  eta: 0:41:52  lr: 0.005000  loss: 1.4249 (2.2283)  loss_classifier: 0.9670 (1.6279)  loss_box_reg: 0.2069 (0.3020)  loss_objectness: 0.0449 (0.1013)  loss_rpn_box_reg: 0.1792 (0.1972)  time: 1.1131  data: 0.1888  max mem: 6909\n",
            "Epoch: [0]  [1380/3605]  eta: 0:41:41  lr: 0.005000  loss: 1.2967 (2.2235)  loss_classifier: 0.9080 (1.6238)  loss_box_reg: 0.2022 (0.3014)  loss_objectness: 0.0394 (0.1010)  loss_rpn_box_reg: 0.1689 (0.1973)  time: 1.1432  data: 0.2034  max mem: 6909\n",
            "Epoch: [0]  [1390/3605]  eta: 0:41:30  lr: 0.005000  loss: 1.4162 (2.2178)  loss_classifier: 1.0092 (1.6195)  loss_box_reg: 0.2054 (0.3008)  loss_objectness: 0.0354 (0.1006)  loss_rpn_box_reg: 0.1689 (0.1970)  time: 1.1589  data: 0.2135  max mem: 6909\n",
            "Epoch: [0]  [1400/3605]  eta: 0:41:19  lr: 0.005000  loss: 1.5206 (2.2146)  loss_classifier: 1.0523 (1.6170)  loss_box_reg: 0.2147 (0.3006)  loss_objectness: 0.0354 (0.1002)  loss_rpn_box_reg: 0.1480 (0.1967)  time: 1.1279  data: 0.2088  max mem: 6909\n",
            "Epoch: [0]  [1410/3605]  eta: 0:41:08  lr: 0.005000  loss: 1.5369 (2.2098)  loss_classifier: 1.0407 (1.6134)  loss_box_reg: 0.2269 (0.3002)  loss_objectness: 0.0388 (0.0998)  loss_rpn_box_reg: 0.1435 (0.1965)  time: 1.1305  data: 0.2146  max mem: 6909\n",
            "Epoch: [0]  [1420/3605]  eta: 0:40:58  lr: 0.005000  loss: 1.5656 (2.2052)  loss_classifier: 1.0010 (1.6095)  loss_box_reg: 0.2131 (0.2996)  loss_objectness: 0.0403 (0.0995)  loss_rpn_box_reg: 0.1687 (0.1966)  time: 1.1647  data: 0.2392  max mem: 6909\n",
            "Epoch: [0]  [1430/3605]  eta: 0:40:46  lr: 0.005000  loss: 1.4859 (2.1998)  loss_classifier: 1.0010 (1.6051)  loss_box_reg: 0.2076 (0.2991)  loss_objectness: 0.0401 (0.0991)  loss_rpn_box_reg: 0.1865 (0.1965)  time: 1.1450  data: 0.2306  max mem: 6909\n",
            "Epoch: [0]  [1440/3605]  eta: 0:40:35  lr: 0.005000  loss: 1.3398 (2.1943)  loss_classifier: 0.9947 (1.6008)  loss_box_reg: 0.1923 (0.2985)  loss_objectness: 0.0324 (0.0986)  loss_rpn_box_reg: 0.1682 (0.1963)  time: 1.1177  data: 0.2162  max mem: 6909\n",
            "Epoch: [0]  [1450/3605]  eta: 0:40:23  lr: 0.005000  loss: 1.3238 (2.1881)  loss_classifier: 0.9498 (1.5961)  loss_box_reg: 0.1923 (0.2978)  loss_objectness: 0.0301 (0.0983)  loss_rpn_box_reg: 0.1450 (0.1959)  time: 1.1191  data: 0.2206  max mem: 6909\n",
            "Epoch: [0]  [1460/3605]  eta: 0:40:12  lr: 0.005000  loss: 1.4409 (2.1838)  loss_classifier: 1.0076 (1.5928)  loss_box_reg: 0.1986 (0.2973)  loss_objectness: 0.0471 (0.0980)  loss_rpn_box_reg: 0.1454 (0.1957)  time: 1.1098  data: 0.2043  max mem: 6909\n",
            "Epoch: [0]  [1470/3605]  eta: 0:40:01  lr: 0.005000  loss: 1.5258 (2.1793)  loss_classifier: 1.0350 (1.5891)  loss_box_reg: 0.2100 (0.2969)  loss_objectness: 0.0471 (0.0977)  loss_rpn_box_reg: 0.1747 (0.1956)  time: 1.1139  data: 0.2047  max mem: 6909\n",
            "Epoch: [0]  [1480/3605]  eta: 0:39:50  lr: 0.005000  loss: 1.4363 (2.1745)  loss_classifier: 0.9905 (1.5853)  loss_box_reg: 0.2100 (0.2963)  loss_objectness: 0.0455 (0.0974)  loss_rpn_box_reg: 0.1668 (0.1955)  time: 1.1286  data: 0.2269  max mem: 6909\n",
            "Epoch: [0]  [1490/3605]  eta: 0:39:39  lr: 0.005000  loss: 1.4225 (2.1696)  loss_classifier: 0.9819 (1.5813)  loss_box_reg: 0.1973 (0.2957)  loss_objectness: 0.0537 (0.0972)  loss_rpn_box_reg: 0.1667 (0.1954)  time: 1.1420  data: 0.2221  max mem: 6909\n",
            "Epoch: [0]  [1500/3605]  eta: 0:39:28  lr: 0.005000  loss: 1.4230 (2.1669)  loss_classifier: 0.9908 (1.5790)  loss_box_reg: 0.2091 (0.2955)  loss_objectness: 0.0564 (0.0969)  loss_rpn_box_reg: 0.1622 (0.1954)  time: 1.1725  data: 0.2146  max mem: 7403\n",
            "Epoch: [0]  [1510/3605]  eta: 0:39:18  lr: 0.005000  loss: 1.5838 (2.1630)  loss_classifier: 1.1160 (1.5760)  loss_box_reg: 0.2118 (0.2950)  loss_objectness: 0.0605 (0.0967)  loss_rpn_box_reg: 0.1794 (0.1953)  time: 1.1922  data: 0.2408  max mem: 7403\n",
            "Epoch: [0]  [1520/3605]  eta: 0:39:07  lr: 0.005000  loss: 1.5944 (2.1596)  loss_classifier: 1.1272 (1.5732)  loss_box_reg: 0.1965 (0.2947)  loss_objectness: 0.0560 (0.0964)  loss_rpn_box_reg: 0.1794 (0.1953)  time: 1.1513  data: 0.2240  max mem: 7403\n",
            "Epoch: [0]  [1530/3605]  eta: 0:38:55  lr: 0.005000  loss: 1.4242 (2.1548)  loss_classifier: 0.9445 (1.5694)  loss_box_reg: 0.2176 (0.2942)  loss_objectness: 0.0369 (0.0961)  loss_rpn_box_reg: 0.1719 (0.1952)  time: 1.1220  data: 0.2060  max mem: 7403\n",
            "Epoch: [0]  [1540/3605]  eta: 0:38:43  lr: 0.005000  loss: 1.4016 (2.1529)  loss_classifier: 0.9418 (1.5678)  loss_box_reg: 0.2100 (0.2939)  loss_objectness: 0.0414 (0.0963)  loss_rpn_box_reg: 0.1558 (0.1950)  time: 1.1020  data: 0.1972  max mem: 7403\n",
            "Epoch: [0]  [1550/3605]  eta: 0:38:32  lr: 0.005000  loss: 1.4656 (2.1502)  loss_classifier: 1.0413 (1.5649)  loss_box_reg: 0.2205 (0.2936)  loss_objectness: 0.0850 (0.0965)  loss_rpn_box_reg: 0.1600 (0.1951)  time: 1.1040  data: 0.2008  max mem: 7403\n",
            "Epoch: [0]  [1560/3605]  eta: 0:38:20  lr: 0.005000  loss: 1.6375 (2.1476)  loss_classifier: 1.0813 (1.5623)  loss_box_reg: 0.2387 (0.2934)  loss_objectness: 0.0909 (0.0966)  loss_rpn_box_reg: 0.2098 (0.1954)  time: 1.1072  data: 0.1956  max mem: 7403\n",
            "Epoch: [0]  [1570/3605]  eta: 0:38:09  lr: 0.005000  loss: 1.6375 (2.1442)  loss_classifier: 1.0813 (1.5591)  loss_box_reg: 0.2438 (0.2930)  loss_objectness: 0.0794 (0.0965)  loss_rpn_box_reg: 0.2098 (0.1955)  time: 1.1135  data: 0.1800  max mem: 7403\n",
            "Epoch: [0]  [1580/3605]  eta: 0:37:58  lr: 0.005000  loss: 1.4641 (2.1390)  loss_classifier: 0.9862 (1.5548)  loss_box_reg: 0.2192 (0.2924)  loss_objectness: 0.0649 (0.0963)  loss_rpn_box_reg: 0.1900 (0.1955)  time: 1.1300  data: 0.1945  max mem: 7403\n",
            "Epoch: [0]  [1590/3605]  eta: 0:37:47  lr: 0.005000  loss: 1.3418 (2.1351)  loss_classifier: 0.8617 (1.5515)  loss_box_reg: 0.1998 (0.2921)  loss_objectness: 0.0570 (0.0962)  loss_rpn_box_reg: 0.1863 (0.1954)  time: 1.1147  data: 0.1975  max mem: 7403\n",
            "Epoch: [0]  [1600/3605]  eta: 0:37:36  lr: 0.005000  loss: 1.4140 (2.1319)  loss_classifier: 0.9271 (1.5486)  loss_box_reg: 0.2194 (0.2918)  loss_objectness: 0.0638 (0.0960)  loss_rpn_box_reg: 0.1915 (0.1955)  time: 1.1216  data: 0.2009  max mem: 7403\n",
            "Epoch: [0]  [1610/3605]  eta: 0:37:24  lr: 0.005000  loss: 1.4483 (2.1280)  loss_classifier: 0.9286 (1.5452)  loss_box_reg: 0.2202 (0.2915)  loss_objectness: 0.0638 (0.0958)  loss_rpn_box_reg: 0.1939 (0.1955)  time: 1.1291  data: 0.1965  max mem: 7403\n",
            "Epoch: [0]  [1620/3605]  eta: 0:37:13  lr: 0.005000  loss: 1.3570 (2.1230)  loss_classifier: 0.9222 (1.5411)  loss_box_reg: 0.2166 (0.2909)  loss_objectness: 0.0528 (0.0956)  loss_rpn_box_reg: 0.1878 (0.1953)  time: 1.1410  data: 0.2007  max mem: 7403\n",
            "Epoch: [0]  [1630/3605]  eta: 0:37:02  lr: 0.005000  loss: 1.2906 (2.1185)  loss_classifier: 0.9008 (1.5374)  loss_box_reg: 0.2080 (0.2904)  loss_objectness: 0.0484 (0.0955)  loss_rpn_box_reg: 0.1718 (0.1953)  time: 1.1377  data: 0.2074  max mem: 7403\n",
            "Epoch: [0]  [1640/3605]  eta: 0:36:51  lr: 0.005000  loss: 1.4439 (2.1151)  loss_classifier: 0.9848 (1.5344)  loss_box_reg: 0.2047 (0.2900)  loss_objectness: 0.0538 (0.0953)  loss_rpn_box_reg: 0.1884 (0.1954)  time: 1.1362  data: 0.2205  max mem: 7403\n",
            "Epoch: [0]  [1650/3605]  eta: 0:36:39  lr: 0.005000  loss: 1.4498 (2.1114)  loss_classifier: 0.9934 (1.5313)  loss_box_reg: 0.2259 (0.2897)  loss_objectness: 0.0523 (0.0951)  loss_rpn_box_reg: 0.1884 (0.1954)  time: 1.1025  data: 0.2078  max mem: 7403\n",
            "Epoch: [0]  [1660/3605]  eta: 0:36:28  lr: 0.005000  loss: 1.4498 (2.1079)  loss_classifier: 1.0016 (1.5285)  loss_box_reg: 0.2124 (0.2892)  loss_objectness: 0.0462 (0.0948)  loss_rpn_box_reg: 0.1837 (0.1953)  time: 1.0827  data: 0.1938  max mem: 7403\n",
            "Epoch: [0]  [1670/3605]  eta: 0:36:16  lr: 0.005000  loss: 1.5166 (2.1053)  loss_classifier: 1.0572 (1.5262)  loss_box_reg: 0.2358 (0.2891)  loss_objectness: 0.0700 (0.0947)  loss_rpn_box_reg: 0.1887 (0.1953)  time: 1.1187  data: 0.2085  max mem: 7403\n",
            "Epoch: [0]  [1680/3605]  eta: 0:36:05  lr: 0.005000  loss: 1.3728 (2.1002)  loss_classifier: 0.8901 (1.5219)  loss_box_reg: 0.2102 (0.2885)  loss_objectness: 0.0501 (0.0944)  loss_rpn_box_reg: 0.1861 (0.1954)  time: 1.1296  data: 0.2109  max mem: 7403\n",
            "Epoch: [0]  [1690/3605]  eta: 0:35:54  lr: 0.005000  loss: 1.3776 (2.0965)  loss_classifier: 0.8676 (1.5185)  loss_box_reg: 0.2077 (0.2881)  loss_objectness: 0.0565 (0.0943)  loss_rpn_box_reg: 0.2046 (0.1955)  time: 1.1506  data: 0.2241  max mem: 7403\n",
            "Epoch: [0]  [1700/3605]  eta: 0:35:43  lr: 0.005000  loss: 1.3776 (2.0908)  loss_classifier: 0.8676 (1.5140)  loss_box_reg: 0.2155 (0.2876)  loss_objectness: 0.0370 (0.0940)  loss_rpn_box_reg: 0.1973 (0.1953)  time: 1.1423  data: 0.2085  max mem: 7403\n",
            "Epoch: [0]  [1710/3605]  eta: 0:35:32  lr: 0.005000  loss: 1.3252 (2.0868)  loss_classifier: 0.9078 (1.5106)  loss_box_reg: 0.1987 (0.2871)  loss_objectness: 0.0340 (0.0937)  loss_rpn_box_reg: 0.1695 (0.1953)  time: 1.1103  data: 0.1925  max mem: 7403\n",
            "Epoch: [0]  [1720/3605]  eta: 0:35:20  lr: 0.005000  loss: 1.3991 (2.0829)  loss_classifier: 0.9586 (1.5075)  loss_box_reg: 0.2069 (0.2867)  loss_objectness: 0.0463 (0.0935)  loss_rpn_box_reg: 0.1694 (0.1952)  time: 1.1039  data: 0.1977  max mem: 7403\n",
            "Epoch: [0]  [1730/3605]  eta: 0:35:08  lr: 0.005000  loss: 1.3545 (2.0790)  loss_classifier: 0.9119 (1.5044)  loss_box_reg: 0.2076 (0.2863)  loss_objectness: 0.0420 (0.0931)  loss_rpn_box_reg: 0.1600 (0.1950)  time: 1.0977  data: 0.1945  max mem: 7403\n",
            "Epoch: [0]  [1740/3605]  eta: 0:34:57  lr: 0.005000  loss: 1.3491 (2.0744)  loss_classifier: 0.8841 (1.5007)  loss_box_reg: 0.1975 (0.2858)  loss_objectness: 0.0341 (0.0929)  loss_rpn_box_reg: 0.1851 (0.1950)  time: 1.0866  data: 0.1912  max mem: 7403\n",
            "Epoch: [0]  [1750/3605]  eta: 0:34:46  lr: 0.005000  loss: 1.4726 (2.0722)  loss_classifier: 0.9175 (1.4986)  loss_box_reg: 0.2139 (0.2857)  loss_objectness: 0.0467 (0.0929)  loss_rpn_box_reg: 0.1957 (0.1951)  time: 1.1089  data: 0.2050  max mem: 7403\n",
            "Epoch: [0]  [1760/3605]  eta: 0:34:34  lr: 0.005000  loss: 1.4597 (2.0690)  loss_classifier: 0.9850 (1.4959)  loss_box_reg: 0.2440 (0.2854)  loss_objectness: 0.0486 (0.0926)  loss_rpn_box_reg: 0.1891 (0.1951)  time: 1.1248  data: 0.2098  max mem: 7403\n",
            "Epoch: [0]  [1770/3605]  eta: 0:34:23  lr: 0.005000  loss: 1.4072 (2.0659)  loss_classifier: 0.9598 (1.4932)  loss_box_reg: 0.2230 (0.2852)  loss_objectness: 0.0425 (0.0925)  loss_rpn_box_reg: 0.1745 (0.1950)  time: 1.0965  data: 0.1908  max mem: 7403\n",
            "Epoch: [0]  [1780/3605]  eta: 0:34:11  lr: 0.005000  loss: 1.3610 (2.0620)  loss_classifier: 0.9493 (1.4900)  loss_box_reg: 0.2014 (0.2847)  loss_objectness: 0.0388 (0.0923)  loss_rpn_box_reg: 0.1729 (0.1949)  time: 1.1015  data: 0.1866  max mem: 7403\n",
            "Epoch: [0]  [1790/3605]  eta: 0:34:00  lr: 0.005000  loss: 1.3540 (2.0578)  loss_classifier: 0.9192 (1.4867)  loss_box_reg: 0.1981 (0.2843)  loss_objectness: 0.0388 (0.0921)  loss_rpn_box_reg: 0.1660 (0.1948)  time: 1.1381  data: 0.1969  max mem: 7403\n",
            "Epoch: [0]  [1800/3605]  eta: 0:33:49  lr: 0.005000  loss: 1.3237 (2.0542)  loss_classifier: 0.9062 (1.4832)  loss_box_reg: 0.2101 (0.2839)  loss_objectness: 0.0466 (0.0923)  loss_rpn_box_reg: 0.1710 (0.1949)  time: 1.1367  data: 0.1990  max mem: 7403\n",
            "Epoch: [0]  [1810/3605]  eta: 0:33:38  lr: 0.005000  loss: 1.3807 (2.0520)  loss_classifier: 0.9062 (1.4808)  loss_box_reg: 0.2101 (0.2836)  loss_objectness: 0.0559 (0.0923)  loss_rpn_box_reg: 0.1931 (0.1952)  time: 1.1175  data: 0.1961  max mem: 7403\n",
            "Epoch: [0]  [1820/3605]  eta: 0:33:26  lr: 0.005000  loss: 1.3826 (2.0498)  loss_classifier: 0.9279 (1.4791)  loss_box_reg: 0.2033 (0.2833)  loss_objectness: 0.0609 (0.0922)  loss_rpn_box_reg: 0.1738 (0.1952)  time: 1.1092  data: 0.2057  max mem: 7403\n",
            "Epoch: [0]  [1830/3605]  eta: 0:33:15  lr: 0.005000  loss: 1.4074 (2.0463)  loss_classifier: 0.9620 (1.4763)  loss_box_reg: 0.2072 (0.2829)  loss_objectness: 0.0490 (0.0921)  loss_rpn_box_reg: 0.1599 (0.1950)  time: 1.1285  data: 0.2146  max mem: 7403\n",
            "Epoch: [0]  [1840/3605]  eta: 0:33:04  lr: 0.005000  loss: 1.4102 (2.0429)  loss_classifier: 0.9112 (1.4734)  loss_box_reg: 0.2072 (0.2826)  loss_objectness: 0.0421 (0.0919)  loss_rpn_box_reg: 0.1635 (0.1949)  time: 1.1231  data: 0.2028  max mem: 7403\n",
            "Epoch: [0]  [1850/3605]  eta: 0:32:53  lr: 0.005000  loss: 1.4102 (2.0388)  loss_classifier: 0.9112 (1.4701)  loss_box_reg: 0.2068 (0.2821)  loss_objectness: 0.0457 (0.0917)  loss_rpn_box_reg: 0.1745 (0.1948)  time: 1.1107  data: 0.1989  max mem: 7403\n",
            "Epoch: [0]  [1860/3605]  eta: 0:32:41  lr: 0.005000  loss: 1.3865 (2.0350)  loss_classifier: 0.9010 (1.4671)  loss_box_reg: 0.2069 (0.2818)  loss_objectness: 0.0442 (0.0915)  loss_rpn_box_reg: 0.1753 (0.1947)  time: 1.1009  data: 0.2064  max mem: 7403\n",
            "Epoch: [0]  [1870/3605]  eta: 0:32:29  lr: 0.005000  loss: 1.3623 (2.0322)  loss_classifier: 0.9115 (1.4649)  loss_box_reg: 0.2054 (0.2815)  loss_objectness: 0.0370 (0.0912)  loss_rpn_box_reg: 0.1726 (0.1946)  time: 1.0837  data: 0.1929  max mem: 7403\n",
            "Epoch: [0]  [1880/3605]  eta: 0:32:18  lr: 0.005000  loss: 1.3626 (2.0285)  loss_classifier: 0.9425 (1.4618)  loss_box_reg: 0.2012 (0.2811)  loss_objectness: 0.0592 (0.0911)  loss_rpn_box_reg: 0.1726 (0.1945)  time: 1.0981  data: 0.1901  max mem: 7403\n",
            "Epoch: [0]  [1890/3605]  eta: 0:32:07  lr: 0.005000  loss: 1.3101 (2.0250)  loss_classifier: 0.9251 (1.4591)  loss_box_reg: 0.1869 (0.2806)  loss_objectness: 0.0385 (0.0909)  loss_rpn_box_reg: 0.1750 (0.1944)  time: 1.1134  data: 0.2061  max mem: 7403\n",
            "Epoch: [0]  [1900/3605]  eta: 0:31:56  lr: 0.005000  loss: 1.2832 (2.0210)  loss_classifier: 0.8932 (1.4559)  loss_box_reg: 0.1869 (0.2802)  loss_objectness: 0.0413 (0.0907)  loss_rpn_box_reg: 0.1750 (0.1943)  time: 1.1444  data: 0.2154  max mem: 7403\n",
            "Epoch: [0]  [1910/3605]  eta: 0:31:44  lr: 0.005000  loss: 1.1999 (2.0174)  loss_classifier: 0.7835 (1.4530)  loss_box_reg: 0.1925 (0.2798)  loss_objectness: 0.0522 (0.0905)  loss_rpn_box_reg: 0.1740 (0.1941)  time: 1.1360  data: 0.2048  max mem: 7403\n",
            "Epoch: [0]  [1920/3605]  eta: 0:31:34  lr: 0.005000  loss: 1.1079 (2.0136)  loss_classifier: 0.7378 (1.4500)  loss_box_reg: 0.1916 (0.2794)  loss_objectness: 0.0398 (0.0902)  loss_rpn_box_reg: 0.1620 (0.1940)  time: 1.1315  data: 0.2122  max mem: 7403\n",
            "Epoch: [0]  [1930/3605]  eta: 0:31:22  lr: 0.005000  loss: 1.1927 (2.0111)  loss_classifier: 0.7896 (1.4481)  loss_box_reg: 0.1920 (0.2793)  loss_objectness: 0.0433 (0.0900)  loss_rpn_box_reg: 0.1518 (0.1938)  time: 1.1462  data: 0.2184  max mem: 7403\n",
            "Epoch: [0]  [1940/3605]  eta: 0:31:11  lr: 0.005000  loss: 1.2622 (2.0077)  loss_classifier: 0.8646 (1.4454)  loss_box_reg: 0.1920 (0.2788)  loss_objectness: 0.0387 (0.0898)  loss_rpn_box_reg: 0.1600 (0.1937)  time: 1.1286  data: 0.2137  max mem: 7403\n",
            "Epoch: [0]  [1950/3605]  eta: 0:31:00  lr: 0.005000  loss: 1.2375 (2.0044)  loss_classifier: 0.8118 (1.4424)  loss_box_reg: 0.1839 (0.2784)  loss_objectness: 0.0634 (0.0899)  loss_rpn_box_reg: 0.1651 (0.1937)  time: 1.1337  data: 0.2125  max mem: 7403\n",
            "Epoch: [0]  [1960/3605]  eta: 0:30:49  lr: 0.005000  loss: 1.2872 (2.0012)  loss_classifier: 0.8541 (1.4398)  loss_box_reg: 0.1886 (0.2780)  loss_objectness: 0.0680 (0.0898)  loss_rpn_box_reg: 0.1721 (0.1936)  time: 1.1351  data: 0.2031  max mem: 7403\n",
            "Epoch: [0]  [1970/3605]  eta: 0:30:37  lr: 0.005000  loss: 1.2467 (1.9980)  loss_classifier: 0.8210 (1.4372)  loss_box_reg: 0.1927 (0.2777)  loss_objectness: 0.0507 (0.0897)  loss_rpn_box_reg: 0.1597 (0.1933)  time: 1.1061  data: 0.2024  max mem: 7403\n",
            "Epoch: [0]  [1980/3605]  eta: 0:30:26  lr: 0.005000  loss: 1.2540 (1.9948)  loss_classifier: 0.8246 (1.4347)  loss_box_reg: 0.1953 (0.2774)  loss_objectness: 0.0384 (0.0895)  loss_rpn_box_reg: 0.1472 (0.1932)  time: 1.0966  data: 0.1966  max mem: 7403\n",
            "Epoch: [0]  [1990/3605]  eta: 0:30:14  lr: 0.005000  loss: 1.3205 (1.9913)  loss_classifier: 0.8616 (1.4320)  loss_box_reg: 0.2012 (0.2770)  loss_objectness: 0.0420 (0.0893)  loss_rpn_box_reg: 0.1554 (0.1930)  time: 1.0986  data: 0.1899  max mem: 7403\n",
            "Epoch: [0]  [2000/3605]  eta: 0:30:03  lr: 0.005000  loss: 1.3775 (1.9890)  loss_classifier: 0.9864 (1.4302)  loss_box_reg: 0.1956 (0.2769)  loss_objectness: 0.0420 (0.0891)  loss_rpn_box_reg: 0.1571 (0.1929)  time: 1.1050  data: 0.2006  max mem: 7403\n",
            "Epoch: [0]  [2010/3605]  eta: 0:29:52  lr: 0.005000  loss: 1.2207 (1.9848)  loss_classifier: 0.8238 (1.4267)  loss_box_reg: 0.1925 (0.2763)  loss_objectness: 0.0363 (0.0889)  loss_rpn_box_reg: 0.1751 (0.1929)  time: 1.1416  data: 0.2169  max mem: 7403\n",
            "Epoch: [0]  [2020/3605]  eta: 0:29:41  lr: 0.005000  loss: 1.1758 (1.9813)  loss_classifier: 0.7156 (1.4240)  loss_box_reg: 0.1654 (0.2760)  loss_objectness: 0.0363 (0.0886)  loss_rpn_box_reg: 0.1623 (0.1927)  time: 1.1309  data: 0.2079  max mem: 7403\n",
            "Epoch: [0]  [2030/3605]  eta: 0:29:30  lr: 0.005000  loss: 1.2896 (1.9786)  loss_classifier: 0.8383 (1.4219)  loss_box_reg: 0.1808 (0.2757)  loss_objectness: 0.0337 (0.0884)  loss_rpn_box_reg: 0.1707 (0.1927)  time: 1.1181  data: 0.2018  max mem: 7403\n",
            "Epoch: [0]  [2040/3605]  eta: 0:29:18  lr: 0.005000  loss: 1.3466 (1.9752)  loss_classifier: 0.8442 (1.4191)  loss_box_reg: 0.1811 (0.2754)  loss_objectness: 0.0320 (0.0881)  loss_rpn_box_reg: 0.1787 (0.1926)  time: 1.1223  data: 0.1965  max mem: 7403\n",
            "Epoch: [0]  [2050/3605]  eta: 0:29:07  lr: 0.005000  loss: 1.1705 (1.9714)  loss_classifier: 0.7782 (1.4160)  loss_box_reg: 0.1697 (0.2749)  loss_objectness: 0.0271 (0.0879)  loss_rpn_box_reg: 0.1685 (0.1926)  time: 1.1270  data: 0.1906  max mem: 7403\n",
            "Epoch: [0]  [2060/3605]  eta: 0:28:55  lr: 0.005000  loss: 1.1107 (1.9680)  loss_classifier: 0.7417 (1.4134)  loss_box_reg: 0.1683 (0.2746)  loss_objectness: 0.0309 (0.0876)  loss_rpn_box_reg: 0.1583 (0.1924)  time: 1.1030  data: 0.1853  max mem: 7403\n",
            "Epoch: [0]  [2070/3605]  eta: 0:28:44  lr: 0.005000  loss: 1.1577 (1.9648)  loss_classifier: 0.7954 (1.4108)  loss_box_reg: 0.1781 (0.2741)  loss_objectness: 0.0386 (0.0875)  loss_rpn_box_reg: 0.1798 (0.1924)  time: 1.1118  data: 0.2048  max mem: 7403\n",
            "Epoch: [0]  [2080/3605]  eta: 0:28:34  lr: 0.005000  loss: 1.2971 (1.9620)  loss_classifier: 0.8581 (1.4087)  loss_box_reg: 0.1830 (0.2737)  loss_objectness: 0.0395 (0.0873)  loss_rpn_box_reg: 0.1798 (0.1923)  time: 1.1662  data: 0.2364  max mem: 7403\n",
            "Epoch: [0]  [2090/3605]  eta: 0:28:23  lr: 0.005000  loss: 1.3154 (1.9590)  loss_classifier: 0.8798 (1.4062)  loss_box_reg: 0.1925 (0.2734)  loss_objectness: 0.0435 (0.0871)  loss_rpn_box_reg: 0.1742 (0.1923)  time: 1.1919  data: 0.2564  max mem: 7403\n",
            "Epoch: [0]  [2100/3605]  eta: 0:28:12  lr: 0.005000  loss: 1.2837 (1.9553)  loss_classifier: 0.8653 (1.4034)  loss_box_reg: 0.1834 (0.2730)  loss_objectness: 0.0383 (0.0869)  loss_rpn_box_reg: 0.1557 (0.1921)  time: 1.1599  data: 0.2318  max mem: 7403\n",
            "Epoch: [0]  [2110/3605]  eta: 0:28:00  lr: 0.005000  loss: 1.2167 (1.9533)  loss_classifier: 0.8613 (1.4016)  loss_box_reg: 0.1755 (0.2728)  loss_objectness: 0.0284 (0.0869)  loss_rpn_box_reg: 0.1426 (0.1920)  time: 1.1167  data: 0.2050  max mem: 7403\n",
            "Epoch: [0]  [2120/3605]  eta: 0:27:49  lr: 0.005000  loss: 1.3112 (1.9499)  loss_classifier: 0.8301 (1.3988)  loss_box_reg: 0.1849 (0.2724)  loss_objectness: 0.0418 (0.0868)  loss_rpn_box_reg: 0.1535 (0.1919)  time: 1.1241  data: 0.2195  max mem: 7403\n",
            "Epoch: [0]  [2130/3605]  eta: 0:27:38  lr: 0.005000  loss: 1.2040 (1.9470)  loss_classifier: 0.7947 (1.3966)  loss_box_reg: 0.1849 (0.2721)  loss_objectness: 0.0418 (0.0866)  loss_rpn_box_reg: 0.1427 (0.1917)  time: 1.1160  data: 0.2010  max mem: 7403\n",
            "Epoch: [0]  [2140/3605]  eta: 0:27:27  lr: 0.005000  loss: 1.2839 (1.9437)  loss_classifier: 0.7862 (1.3940)  loss_box_reg: 0.1853 (0.2718)  loss_objectness: 0.0372 (0.0864)  loss_rpn_box_reg: 0.1435 (0.1915)  time: 1.1410  data: 0.1968  max mem: 7403\n",
            "Epoch: [0]  [2150/3605]  eta: 0:27:16  lr: 0.005000  loss: 1.3486 (1.9410)  loss_classifier: 0.8561 (1.3917)  loss_box_reg: 0.2005 (0.2714)  loss_objectness: 0.0305 (0.0863)  loss_rpn_box_reg: 0.1631 (0.1916)  time: 1.1583  data: 0.2223  max mem: 7403\n",
            "Epoch: [0]  [2160/3605]  eta: 0:27:05  lr: 0.005000  loss: 1.2762 (1.9380)  loss_classifier: 0.8611 (1.3892)  loss_box_reg: 0.1910 (0.2710)  loss_objectness: 0.0475 (0.0862)  loss_rpn_box_reg: 0.1870 (0.1916)  time: 1.1370  data: 0.2165  max mem: 7403\n",
            "Epoch: [0]  [2170/3605]  eta: 0:26:53  lr: 0.005000  loss: 1.3052 (1.9357)  loss_classifier: 0.9030 (1.3873)  loss_box_reg: 0.1876 (0.2707)  loss_objectness: 0.0432 (0.0861)  loss_rpn_box_reg: 0.1646 (0.1915)  time: 1.1127  data: 0.1942  max mem: 7403\n",
            "Epoch: [0]  [2180/3605]  eta: 0:26:42  lr: 0.005000  loss: 1.1847 (1.9322)  loss_classifier: 0.8188 (1.3846)  loss_box_reg: 0.1848 (0.2703)  loss_objectness: 0.0431 (0.0859)  loss_rpn_box_reg: 0.1388 (0.1913)  time: 1.0998  data: 0.1866  max mem: 7403\n",
            "Epoch: [0]  [2190/3605]  eta: 0:26:31  lr: 0.005000  loss: 1.1567 (1.9289)  loss_classifier: 0.7743 (1.3819)  loss_box_reg: 0.1774 (0.2699)  loss_objectness: 0.0431 (0.0857)  loss_rpn_box_reg: 0.1709 (0.1913)  time: 1.1207  data: 0.1975  max mem: 7403\n",
            "Epoch: [0]  [2200/3605]  eta: 0:26:19  lr: 0.005000  loss: 1.1899 (1.9265)  loss_classifier: 0.7718 (1.3801)  loss_box_reg: 0.1783 (0.2696)  loss_objectness: 0.0351 (0.0855)  loss_rpn_box_reg: 0.1784 (0.1912)  time: 1.1262  data: 0.2055  max mem: 7403\n",
            "Epoch: [0]  [2210/3605]  eta: 0:26:08  lr: 0.005000  loss: 1.3447 (1.9238)  loss_classifier: 0.8945 (1.3779)  loss_box_reg: 0.1909 (0.2694)  loss_objectness: 0.0294 (0.0853)  loss_rpn_box_reg: 0.1766 (0.1912)  time: 1.1168  data: 0.2076  max mem: 7403\n",
            "Epoch: [0]  [2220/3605]  eta: 0:25:57  lr: 0.005000  loss: 1.3352 (1.9213)  loss_classifier: 0.8874 (1.3760)  loss_box_reg: 0.2003 (0.2692)  loss_objectness: 0.0448 (0.0851)  loss_rpn_box_reg: 0.1618 (0.1910)  time: 1.1308  data: 0.2159  max mem: 7403\n",
            "Epoch: [0]  [2230/3605]  eta: 0:25:45  lr: 0.005000  loss: 1.3089 (1.9195)  loss_classifier: 0.8504 (1.3743)  loss_box_reg: 0.2065 (0.2691)  loss_objectness: 0.0394 (0.0850)  loss_rpn_box_reg: 0.1642 (0.1911)  time: 1.1237  data: 0.2100  max mem: 7403\n",
            "Epoch: [0]  [2240/3605]  eta: 0:25:34  lr: 0.005000  loss: 1.2702 (1.9165)  loss_classifier: 0.8393 (1.3719)  loss_box_reg: 0.2023 (0.2688)  loss_objectness: 0.0388 (0.0849)  loss_rpn_box_reg: 0.1716 (0.1910)  time: 1.1099  data: 0.1897  max mem: 7403\n",
            "Epoch: [0]  [2250/3605]  eta: 0:25:23  lr: 0.005000  loss: 1.2702 (1.9134)  loss_classifier: 0.7578 (1.3692)  loss_box_reg: 0.1941 (0.2684)  loss_objectness: 0.0407 (0.0848)  loss_rpn_box_reg: 0.1716 (0.1909)  time: 1.0986  data: 0.1900  max mem: 7403\n",
            "Epoch: [0]  [2260/3605]  eta: 0:25:11  lr: 0.005000  loss: 1.2158 (1.9107)  loss_classifier: 0.7344 (1.3670)  loss_box_reg: 0.1968 (0.2682)  loss_objectness: 0.0407 (0.0846)  loss_rpn_box_reg: 0.1827 (0.1909)  time: 1.0926  data: 0.2057  max mem: 7403\n",
            "Epoch: [0]  [2270/3605]  eta: 0:25:00  lr: 0.005000  loss: 1.2158 (1.9078)  loss_classifier: 0.7379 (1.3645)  loss_box_reg: 0.1915 (0.2679)  loss_objectness: 0.0518 (0.0845)  loss_rpn_box_reg: 0.1826 (0.1909)  time: 1.1318  data: 0.2233  max mem: 7403\n",
            "Epoch: [0]  [2280/3605]  eta: 0:24:49  lr: 0.005000  loss: 1.1913 (1.9051)  loss_classifier: 0.6989 (1.3621)  loss_box_reg: 0.1828 (0.2676)  loss_objectness: 0.0588 (0.0846)  loss_rpn_box_reg: 0.1681 (0.1908)  time: 1.1294  data: 0.2141  max mem: 7403\n",
            "Epoch: [0]  [2290/3605]  eta: 0:24:37  lr: 0.005000  loss: 1.2690 (1.9034)  loss_classifier: 0.8808 (1.3608)  loss_box_reg: 0.1886 (0.2675)  loss_objectness: 0.0575 (0.0845)  loss_rpn_box_reg: 0.1527 (0.1906)  time: 1.0917  data: 0.1826  max mem: 7403\n",
            "Epoch: [0]  [2300/3605]  eta: 0:24:26  lr: 0.005000  loss: 1.2795 (1.9011)  loss_classifier: 0.8472 (1.3587)  loss_box_reg: 0.1966 (0.2673)  loss_objectness: 0.0528 (0.0844)  loss_rpn_box_reg: 0.1766 (0.1908)  time: 1.1213  data: 0.2033  max mem: 7403\n",
            "Epoch: [0]  [2310/3605]  eta: 0:24:15  lr: 0.005000  loss: 1.2795 (1.8983)  loss_classifier: 0.7902 (1.3563)  loss_box_reg: 0.1863 (0.2670)  loss_objectness: 0.0496 (0.0842)  loss_rpn_box_reg: 0.1950 (0.1907)  time: 1.1413  data: 0.2220  max mem: 7403\n",
            "Epoch: [0]  [2320/3605]  eta: 0:24:04  lr: 0.005000  loss: 1.2600 (1.8962)  loss_classifier: 0.8667 (1.3546)  loss_box_reg: 0.1840 (0.2667)  loss_objectness: 0.0504 (0.0841)  loss_rpn_box_reg: 0.1766 (0.1907)  time: 1.1361  data: 0.2201  max mem: 7403\n",
            "Epoch: [0]  [2330/3605]  eta: 0:23:53  lr: 0.005000  loss: 1.2494 (1.8933)  loss_classifier: 0.7429 (1.3522)  loss_box_reg: 0.1803 (0.2663)  loss_objectness: 0.0557 (0.0840)  loss_rpn_box_reg: 0.1743 (0.1907)  time: 1.1692  data: 0.2316  max mem: 7403\n",
            "Epoch: [0]  [2340/3605]  eta: 0:23:42  lr: 0.005000  loss: 1.2967 (1.8916)  loss_classifier: 0.8527 (1.3508)  loss_box_reg: 0.1840 (0.2661)  loss_objectness: 0.0552 (0.0839)  loss_rpn_box_reg: 0.1863 (0.1907)  time: 1.1682  data: 0.2308  max mem: 7403\n",
            "Epoch: [0]  [2350/3605]  eta: 0:23:31  lr: 0.005000  loss: 1.3636 (1.8888)  loss_classifier: 0.8743 (1.3485)  loss_box_reg: 0.1875 (0.2658)  loss_objectness: 0.0522 (0.0838)  loss_rpn_box_reg: 0.1863 (0.1908)  time: 1.1314  data: 0.2109  max mem: 7403\n",
            "Epoch: [0]  [2360/3605]  eta: 0:23:20  lr: 0.005000  loss: 1.1996 (1.8865)  loss_classifier: 0.7673 (1.3467)  loss_box_reg: 0.1823 (0.2655)  loss_objectness: 0.0378 (0.0836)  loss_rpn_box_reg: 0.1633 (0.1907)  time: 1.1527  data: 0.2228  max mem: 7403\n",
            "Epoch: [0]  [2370/3605]  eta: 0:23:09  lr: 0.005000  loss: 1.2006 (1.8833)  loss_classifier: 0.6753 (1.3440)  loss_box_reg: 0.1823 (0.2652)  loss_objectness: 0.0338 (0.0834)  loss_rpn_box_reg: 0.1630 (0.1906)  time: 1.1512  data: 0.2140  max mem: 7403\n",
            "Epoch: [0]  [2380/3605]  eta: 0:22:57  lr: 0.005000  loss: 1.2262 (1.8808)  loss_classifier: 0.8148 (1.3421)  loss_box_reg: 0.1704 (0.2649)  loss_objectness: 0.0334 (0.0833)  loss_rpn_box_reg: 0.1736 (0.1905)  time: 1.1268  data: 0.1952  max mem: 7403\n",
            "Epoch: [0]  [2390/3605]  eta: 0:22:46  lr: 0.005000  loss: 1.2893 (1.8786)  loss_classifier: 0.8288 (1.3402)  loss_box_reg: 0.1829 (0.2646)  loss_objectness: 0.0275 (0.0832)  loss_rpn_box_reg: 0.1589 (0.1906)  time: 1.1462  data: 0.2124  max mem: 7403\n",
            "Epoch: [0]  [2400/3605]  eta: 0:22:35  lr: 0.005000  loss: 1.2257 (1.8759)  loss_classifier: 0.8141 (1.3379)  loss_box_reg: 0.1863 (0.2643)  loss_objectness: 0.0410 (0.0831)  loss_rpn_box_reg: 0.1998 (0.1906)  time: 1.1510  data: 0.2193  max mem: 7403\n",
            "Epoch: [0]  [2410/3605]  eta: 0:22:24  lr: 0.005000  loss: 1.1989 (1.8737)  loss_classifier: 0.7222 (1.3360)  loss_box_reg: 0.1878 (0.2640)  loss_objectness: 0.0580 (0.0830)  loss_rpn_box_reg: 0.1825 (0.1906)  time: 1.1782  data: 0.2334  max mem: 7403\n",
            "Epoch: [0]  [2420/3605]  eta: 0:22:13  lr: 0.005000  loss: 1.2136 (1.8715)  loss_classifier: 0.7889 (1.3342)  loss_box_reg: 0.1970 (0.2638)  loss_objectness: 0.0556 (0.0829)  loss_rpn_box_reg: 0.1773 (0.1906)  time: 1.1620  data: 0.2225  max mem: 7403\n",
            "Epoch: [0]  [2430/3605]  eta: 0:22:02  lr: 0.005000  loss: 1.2441 (1.8688)  loss_classifier: 0.7787 (1.3322)  loss_box_reg: 0.1916 (0.2635)  loss_objectness: 0.0342 (0.0827)  loss_rpn_box_reg: 0.1520 (0.1904)  time: 1.1233  data: 0.2145  max mem: 7403\n",
            "Epoch: [0]  [2440/3605]  eta: 0:21:51  lr: 0.005000  loss: 1.1630 (1.8661)  loss_classifier: 0.7287 (1.3300)  loss_box_reg: 0.1876 (0.2633)  loss_objectness: 0.0300 (0.0825)  loss_rpn_box_reg: 0.1462 (0.1903)  time: 1.1291  data: 0.2126  max mem: 7403\n",
            "Epoch: [0]  [2450/3605]  eta: 0:21:39  lr: 0.005000  loss: 1.2527 (1.8643)  loss_classifier: 0.8369 (1.3286)  loss_box_reg: 0.1876 (0.2630)  loss_objectness: 0.0356 (0.0824)  loss_rpn_box_reg: 0.1508 (0.1903)  time: 1.1254  data: 0.1892  max mem: 7403\n",
            "Epoch: [0]  [2460/3605]  eta: 0:21:28  lr: 0.005000  loss: 1.2527 (1.8620)  loss_classifier: 0.8433 (1.3267)  loss_box_reg: 0.1810 (0.2627)  loss_objectness: 0.0421 (0.0823)  loss_rpn_box_reg: 0.1717 (0.1903)  time: 1.1268  data: 0.1956  max mem: 7403\n",
            "Epoch: [0]  [2470/3605]  eta: 0:21:17  lr: 0.005000  loss: 1.1669 (1.8592)  loss_classifier: 0.7904 (1.3245)  loss_box_reg: 0.1722 (0.2624)  loss_objectness: 0.0342 (0.0821)  loss_rpn_box_reg: 0.1771 (0.1902)  time: 1.1240  data: 0.1987  max mem: 7403\n",
            "Epoch: [0]  [2480/3605]  eta: 0:21:05  lr: 0.005000  loss: 1.1188 (1.8564)  loss_classifier: 0.7109 (1.3221)  loss_box_reg: 0.1636 (0.2621)  loss_objectness: 0.0328 (0.0819)  loss_rpn_box_reg: 0.1747 (0.1903)  time: 1.0930  data: 0.1830  max mem: 7403\n",
            "Epoch: [0]  [2490/3605]  eta: 0:20:54  lr: 0.005000  loss: 1.1556 (1.8547)  loss_classifier: 0.7628 (1.3207)  loss_box_reg: 0.1883 (0.2619)  loss_objectness: 0.0376 (0.0818)  loss_rpn_box_reg: 0.1636 (0.1903)  time: 1.0819  data: 0.1916  max mem: 7403\n",
            "Epoch: [0]  [2500/3605]  eta: 0:20:42  lr: 0.005000  loss: 1.1556 (1.8520)  loss_classifier: 0.7803 (1.3186)  loss_box_reg: 0.1756 (0.2616)  loss_objectness: 0.0364 (0.0817)  loss_rpn_box_reg: 0.1475 (0.1901)  time: 1.0925  data: 0.1916  max mem: 7403\n",
            "Epoch: [0]  [2510/3605]  eta: 0:20:31  lr: 0.005000  loss: 1.0749 (1.8493)  loss_classifier: 0.7371 (1.3164)  loss_box_reg: 0.1650 (0.2612)  loss_objectness: 0.0362 (0.0815)  loss_rpn_box_reg: 0.1405 (0.1901)  time: 1.0984  data: 0.1778  max mem: 7403\n",
            "Epoch: [0]  [2520/3605]  eta: 0:20:20  lr: 0.005000  loss: 1.0598 (1.8463)  loss_classifier: 0.7142 (1.3141)  loss_box_reg: 0.1647 (0.2609)  loss_objectness: 0.0362 (0.0814)  loss_rpn_box_reg: 0.1486 (0.1899)  time: 1.1082  data: 0.1812  max mem: 7403\n",
            "Epoch: [0]  [2530/3605]  eta: 0:20:09  lr: 0.005000  loss: 1.0592 (1.8436)  loss_classifier: 0.7343 (1.3120)  loss_box_reg: 0.1754 (0.2606)  loss_objectness: 0.0266 (0.0812)  loss_rpn_box_reg: 0.1537 (0.1898)  time: 1.1266  data: 0.2133  max mem: 7403\n",
            "Epoch: [0]  [2540/3605]  eta: 0:19:58  lr: 0.005000  loss: 1.1684 (1.8413)  loss_classifier: 0.7633 (1.3103)  loss_box_reg: 0.1900 (0.2603)  loss_objectness: 0.0329 (0.0810)  loss_rpn_box_reg: 0.1555 (0.1897)  time: 1.1563  data: 0.2385  max mem: 7403\n",
            "Epoch: [0]  [2550/3605]  eta: 0:19:46  lr: 0.005000  loss: 1.2237 (1.8391)  loss_classifier: 0.7875 (1.3085)  loss_box_reg: 0.1968 (0.2601)  loss_objectness: 0.0349 (0.0809)  loss_rpn_box_reg: 0.1552 (0.1896)  time: 1.1528  data: 0.2159  max mem: 7403\n",
            "Epoch: [0]  [2560/3605]  eta: 0:19:35  lr: 0.005000  loss: 1.1289 (1.8361)  loss_classifier: 0.7875 (1.3062)  loss_box_reg: 0.1833 (0.2598)  loss_objectness: 0.0317 (0.0807)  loss_rpn_box_reg: 0.1370 (0.1894)  time: 1.1466  data: 0.2150  max mem: 7403\n",
            "Epoch: [0]  [2570/3605]  eta: 0:19:24  lr: 0.005000  loss: 1.1281 (1.8336)  loss_classifier: 0.7374 (1.3042)  loss_box_reg: 0.1700 (0.2595)  loss_objectness: 0.0330 (0.0805)  loss_rpn_box_reg: 0.1370 (0.1893)  time: 1.1217  data: 0.2117  max mem: 7403\n",
            "Epoch: [0]  [2580/3605]  eta: 0:19:13  lr: 0.005000  loss: 1.1647 (1.8313)  loss_classifier: 0.7706 (1.3023)  loss_box_reg: 0.1817 (0.2593)  loss_objectness: 0.0382 (0.0804)  loss_rpn_box_reg: 0.1861 (0.1893)  time: 1.1040  data: 0.1910  max mem: 7403\n",
            "Epoch: [0]  [2590/3605]  eta: 0:19:02  lr: 0.005000  loss: 1.2001 (1.8287)  loss_classifier: 0.7865 (1.3002)  loss_box_reg: 0.1983 (0.2590)  loss_objectness: 0.0375 (0.0802)  loss_rpn_box_reg: 0.1640 (0.1892)  time: 1.1447  data: 0.2111  max mem: 7403\n",
            "Epoch: [0]  [2600/3605]  eta: 0:18:50  lr: 0.005000  loss: 1.1240 (1.8258)  loss_classifier: 0.7174 (1.2979)  loss_box_reg: 0.1728 (0.2587)  loss_objectness: 0.0352 (0.0801)  loss_rpn_box_reg: 0.1431 (0.1891)  time: 1.1518  data: 0.2186  max mem: 7403\n",
            "Epoch: [0]  [2610/3605]  eta: 0:18:39  lr: 0.005000  loss: 1.0862 (1.8233)  loss_classifier: 0.7174 (1.2959)  loss_box_reg: 0.1726 (0.2584)  loss_objectness: 0.0385 (0.0799)  loss_rpn_box_reg: 0.1584 (0.1890)  time: 1.1463  data: 0.2161  max mem: 7403\n",
            "Epoch: [0]  [2620/3605]  eta: 0:18:28  lr: 0.005000  loss: 1.1693 (1.8208)  loss_classifier: 0.7368 (1.2939)  loss_box_reg: 0.1821 (0.2581)  loss_objectness: 0.0328 (0.0797)  loss_rpn_box_reg: 0.1589 (0.1890)  time: 1.1450  data: 0.2071  max mem: 7403\n",
            "Epoch: [0]  [2630/3605]  eta: 0:18:17  lr: 0.005000  loss: 1.1715 (1.8182)  loss_classifier: 0.7257 (1.2918)  loss_box_reg: 0.1821 (0.2578)  loss_objectness: 0.0251 (0.0796)  loss_rpn_box_reg: 0.1762 (0.1890)  time: 1.1210  data: 0.1916  max mem: 7403\n",
            "Epoch: [0]  [2640/3605]  eta: 0:18:05  lr: 0.005000  loss: 1.2116 (1.8162)  loss_classifier: 0.7671 (1.2901)  loss_box_reg: 0.1865 (0.2576)  loss_objectness: 0.0333 (0.0795)  loss_rpn_box_reg: 0.1857 (0.1890)  time: 1.1154  data: 0.1873  max mem: 7403\n",
            "Epoch: [0]  [2650/3605]  eta: 0:17:54  lr: 0.005000  loss: 1.3809 (1.8153)  loss_classifier: 0.9319 (1.2895)  loss_box_reg: 0.2076 (0.2576)  loss_objectness: 0.0383 (0.0793)  loss_rpn_box_reg: 0.1864 (0.1889)  time: 1.1350  data: 0.2255  max mem: 7403\n",
            "Epoch: [0]  [2660/3605]  eta: 0:17:43  lr: 0.005000  loss: 1.3105 (1.8128)  loss_classifier: 0.9299 (1.2876)  loss_box_reg: 0.1963 (0.2573)  loss_objectness: 0.0264 (0.0792)  loss_rpn_box_reg: 0.1477 (0.1888)  time: 1.1137  data: 0.2150  max mem: 7403\n",
            "Epoch: [0]  [2670/3605]  eta: 0:17:32  lr: 0.005000  loss: 1.2967 (1.8116)  loss_classifier: 0.7729 (1.2862)  loss_box_reg: 0.1698 (0.2571)  loss_objectness: 0.0456 (0.0795)  loss_rpn_box_reg: 0.1569 (0.1888)  time: 1.1126  data: 0.1930  max mem: 7403\n",
            "Epoch: [0]  [2680/3605]  eta: 0:17:20  lr: 0.005000  loss: 1.3049 (1.8101)  loss_classifier: 0.8047 (1.2848)  loss_box_reg: 0.1756 (0.2570)  loss_objectness: 0.0688 (0.0795)  loss_rpn_box_reg: 0.1757 (0.1888)  time: 1.1295  data: 0.2198  max mem: 7403\n",
            "Epoch: [0]  [2690/3605]  eta: 0:17:09  lr: 0.005000  loss: 1.3049 (1.8083)  loss_classifier: 0.8047 (1.2833)  loss_box_reg: 0.1880 (0.2568)  loss_objectness: 0.0517 (0.0794)  loss_rpn_box_reg: 0.1741 (0.1888)  time: 1.1366  data: 0.2202  max mem: 7403\n",
            "Epoch: [0]  [2700/3605]  eta: 0:16:58  lr: 0.005000  loss: 1.3075 (1.8062)  loss_classifier: 0.8702 (1.2816)  loss_box_reg: 0.1917 (0.2566)  loss_objectness: 0.0446 (0.0793)  loss_rpn_box_reg: 0.1622 (0.1887)  time: 1.1363  data: 0.2145  max mem: 7403\n",
            "Epoch: [0]  [2710/3605]  eta: 0:16:47  lr: 0.005000  loss: 1.2026 (1.8040)  loss_classifier: 0.8233 (1.2798)  loss_box_reg: 0.1894 (0.2563)  loss_objectness: 0.0315 (0.0791)  loss_rpn_box_reg: 0.1581 (0.1887)  time: 1.1023  data: 0.1873  max mem: 7403\n",
            "Epoch: [0]  [2720/3605]  eta: 0:16:35  lr: 0.005000  loss: 1.2052 (1.8021)  loss_classifier: 0.8413 (1.2784)  loss_box_reg: 0.1832 (0.2561)  loss_objectness: 0.0268 (0.0790)  loss_rpn_box_reg: 0.1581 (0.1886)  time: 1.0929  data: 0.1913  max mem: 7403\n",
            "Epoch: [0]  [2730/3605]  eta: 0:16:24  lr: 0.005000  loss: 1.1090 (1.7994)  loss_classifier: 0.7949 (1.2762)  loss_box_reg: 0.1860 (0.2557)  loss_objectness: 0.0369 (0.0790)  loss_rpn_box_reg: 0.1487 (0.1885)  time: 1.0880  data: 0.1894  max mem: 7403\n",
            "Epoch: [0]  [2740/3605]  eta: 0:16:12  lr: 0.005000  loss: 1.1073 (1.7984)  loss_classifier: 0.7458 (1.2755)  loss_box_reg: 0.1860 (0.2556)  loss_objectness: 0.0418 (0.0789)  loss_rpn_box_reg: 0.1603 (0.1885)  time: 1.0991  data: 0.1881  max mem: 7403\n",
            "Epoch: [0]  [2750/3605]  eta: 0:16:01  lr: 0.005000  loss: 1.1332 (1.7959)  loss_classifier: 0.7938 (1.2736)  loss_box_reg: 0.1858 (0.2553)  loss_objectness: 0.0307 (0.0787)  loss_rpn_box_reg: 0.1543 (0.1884)  time: 1.1225  data: 0.2002  max mem: 7403\n",
            "Epoch: [0]  [2760/3605]  eta: 0:15:50  lr: 0.005000  loss: 1.1097 (1.7937)  loss_classifier: 0.7103 (1.2717)  loss_box_reg: 0.1713 (0.2551)  loss_objectness: 0.0398 (0.0786)  loss_rpn_box_reg: 0.1543 (0.1883)  time: 1.1254  data: 0.1971  max mem: 7403\n",
            "Epoch: [0]  [2770/3605]  eta: 0:15:39  lr: 0.005000  loss: 1.1097 (1.7912)  loss_classifier: 0.7661 (1.2697)  loss_box_reg: 0.1670 (0.2547)  loss_objectness: 0.0400 (0.0785)  loss_rpn_box_reg: 0.1584 (0.1883)  time: 1.1594  data: 0.2234  max mem: 7403\n",
            "Epoch: [0]  [2780/3605]  eta: 0:15:28  lr: 0.005000  loss: 1.1376 (1.7887)  loss_classifier: 0.7661 (1.2677)  loss_box_reg: 0.1641 (0.2544)  loss_objectness: 0.0330 (0.0784)  loss_rpn_box_reg: 0.1615 (0.1882)  time: 1.1776  data: 0.2369  max mem: 7403\n",
            "Epoch: [0]  [2790/3605]  eta: 0:15:17  lr: 0.005000  loss: 1.0920 (1.7863)  loss_classifier: 0.6804 (1.2659)  loss_box_reg: 0.1636 (0.2541)  loss_objectness: 0.0328 (0.0782)  loss_rpn_box_reg: 0.1486 (0.1881)  time: 1.1370  data: 0.2193  max mem: 7403\n",
            "Epoch: [0]  [2800/3605]  eta: 0:15:05  lr: 0.005000  loss: 1.0613 (1.7843)  loss_classifier: 0.6984 (1.2643)  loss_box_reg: 0.1543 (0.2538)  loss_objectness: 0.0268 (0.0781)  loss_rpn_box_reg: 0.1713 (0.1881)  time: 1.1237  data: 0.2098  max mem: 7403\n",
            "Epoch: [0]  [2810/3605]  eta: 0:14:54  lr: 0.005000  loss: 1.1505 (1.7825)  loss_classifier: 0.7632 (1.2629)  loss_box_reg: 0.1744 (0.2537)  loss_objectness: 0.0345 (0.0780)  loss_rpn_box_reg: 0.1750 (0.1880)  time: 1.1362  data: 0.2244  max mem: 7403\n",
            "Epoch: [0]  [2820/3605]  eta: 0:14:43  lr: 0.005000  loss: 1.2249 (1.7806)  loss_classifier: 0.7837 (1.2613)  loss_box_reg: 0.1765 (0.2534)  loss_objectness: 0.0447 (0.0779)  loss_rpn_box_reg: 0.1778 (0.1879)  time: 1.1105  data: 0.2102  max mem: 7403\n",
            "Epoch: [0]  [2830/3605]  eta: 0:14:31  lr: 0.005000  loss: 1.2104 (1.7786)  loss_classifier: 0.7692 (1.2597)  loss_box_reg: 0.1759 (0.2532)  loss_objectness: 0.0325 (0.0778)  loss_rpn_box_reg: 0.1652 (0.1878)  time: 1.0871  data: 0.1737  max mem: 7403\n",
            "Epoch: [0]  [2840/3605]  eta: 0:14:20  lr: 0.005000  loss: 1.3829 (1.7771)  loss_classifier: 0.9347 (1.2585)  loss_box_reg: 0.1946 (0.2531)  loss_objectness: 0.0308 (0.0777)  loss_rpn_box_reg: 0.1724 (0.1878)  time: 1.1037  data: 0.1766  max mem: 7403\n",
            "Epoch: [0]  [2850/3605]  eta: 0:14:09  lr: 0.005000  loss: 1.1289 (1.7745)  loss_classifier: 0.7417 (1.2566)  loss_box_reg: 0.1804 (0.2529)  loss_objectness: 0.0208 (0.0775)  loss_rpn_box_reg: 0.1465 (0.1876)  time: 1.0783  data: 0.1807  max mem: 7403\n",
            "Epoch: [0]  [2860/3605]  eta: 0:13:57  lr: 0.005000  loss: 0.9331 (1.7719)  loss_classifier: 0.6245 (1.2545)  loss_box_reg: 0.1721 (0.2526)  loss_objectness: 0.0188 (0.0773)  loss_rpn_box_reg: 0.1388 (0.1875)  time: 1.0565  data: 0.1687  max mem: 7403\n",
            "Epoch: [0]  [2870/3605]  eta: 0:13:46  lr: 0.005000  loss: 1.0970 (1.7702)  loss_classifier: 0.7165 (1.2533)  loss_box_reg: 0.1721 (0.2525)  loss_objectness: 0.0188 (0.0771)  loss_rpn_box_reg: 0.1388 (0.1873)  time: 1.0638  data: 0.1655  max mem: 7403\n",
            "Epoch: [0]  [2880/3605]  eta: 0:13:35  lr: 0.005000  loss: 1.1047 (1.7684)  loss_classifier: 0.7618 (1.2518)  loss_box_reg: 0.1649 (0.2524)  loss_objectness: 0.0283 (0.0770)  loss_rpn_box_reg: 0.1551 (0.1873)  time: 1.1057  data: 0.1988  max mem: 7403\n",
            "Epoch: [0]  [2890/3605]  eta: 0:13:23  lr: 0.005000  loss: 1.1045 (1.7664)  loss_classifier: 0.6995 (1.2502)  loss_box_reg: 0.1946 (0.2522)  loss_objectness: 0.0330 (0.0769)  loss_rpn_box_reg: 0.1551 (0.1872)  time: 1.1026  data: 0.1960  max mem: 7403\n",
            "Epoch: [0]  [2900/3605]  eta: 0:13:12  lr: 0.005000  loss: 1.0468 (1.7641)  loss_classifier: 0.6995 (1.2484)  loss_box_reg: 0.1915 (0.2519)  loss_objectness: 0.0225 (0.0767)  loss_rpn_box_reg: 0.1535 (0.1871)  time: 1.0827  data: 0.1790  max mem: 7403\n",
            "Epoch: [0]  [2910/3605]  eta: 0:13:01  lr: 0.005000  loss: 1.0503 (1.7620)  loss_classifier: 0.7199 (1.2467)  loss_box_reg: 0.1730 (0.2517)  loss_objectness: 0.0199 (0.0766)  loss_rpn_box_reg: 0.1625 (0.1870)  time: 1.1299  data: 0.2075  max mem: 7403\n",
            "Epoch: [0]  [2920/3605]  eta: 0:12:50  lr: 0.005000  loss: 1.1875 (1.7605)  loss_classifier: 0.7435 (1.2454)  loss_box_reg: 0.1693 (0.2515)  loss_objectness: 0.0199 (0.0765)  loss_rpn_box_reg: 0.1753 (0.1871)  time: 1.1420  data: 0.2166  max mem: 7403\n",
            "Epoch: [0]  [2930/3605]  eta: 0:12:38  lr: 0.005000  loss: 1.2813 (1.7587)  loss_classifier: 0.8057 (1.2438)  loss_box_reg: 0.1717 (0.2513)  loss_objectness: 0.0410 (0.0764)  loss_rpn_box_reg: 0.1920 (0.1872)  time: 1.1426  data: 0.2286  max mem: 7403\n",
            "Epoch: [0]  [2940/3605]  eta: 0:12:27  lr: 0.005000  loss: 1.2813 (1.7569)  loss_classifier: 0.8057 (1.2424)  loss_box_reg: 0.1778 (0.2511)  loss_objectness: 0.0403 (0.0763)  loss_rpn_box_reg: 0.1764 (0.1871)  time: 1.1491  data: 0.2199  max mem: 7403\n",
            "Epoch: [0]  [2950/3605]  eta: 0:12:16  lr: 0.005000  loss: 1.2042 (1.7551)  loss_classifier: 0.7979 (1.2409)  loss_box_reg: 0.1837 (0.2508)  loss_objectness: 0.0403 (0.0762)  loss_rpn_box_reg: 0.1679 (0.1871)  time: 1.1621  data: 0.2239  max mem: 7403\n",
            "Epoch: [0]  [2960/3605]  eta: 0:12:05  lr: 0.005000  loss: 1.1770 (1.7532)  loss_classifier: 0.7952 (1.2395)  loss_box_reg: 0.1934 (0.2507)  loss_objectness: 0.0194 (0.0760)  loss_rpn_box_reg: 0.1748 (0.1871)  time: 1.1463  data: 0.2333  max mem: 7403\n",
            "Epoch: [0]  [2970/3605]  eta: 0:11:54  lr: 0.005000  loss: 1.1746 (1.7512)  loss_classifier: 0.7626 (1.2379)  loss_box_reg: 0.1898 (0.2505)  loss_objectness: 0.0193 (0.0758)  loss_rpn_box_reg: 0.1748 (0.1870)  time: 1.1163  data: 0.2041  max mem: 7403\n",
            "Epoch: [0]  [2980/3605]  eta: 0:11:42  lr: 0.005000  loss: 0.9985 (1.7488)  loss_classifier: 0.6953 (1.2360)  loss_box_reg: 0.1728 (0.2502)  loss_objectness: 0.0244 (0.0757)  loss_rpn_box_reg: 0.1660 (0.1869)  time: 1.1226  data: 0.1969  max mem: 7403\n",
            "Epoch: [0]  [2990/3605]  eta: 0:11:31  lr: 0.005000  loss: 0.9755 (1.7465)  loss_classifier: 0.6498 (1.2342)  loss_box_reg: 0.1563 (0.2499)  loss_objectness: 0.0244 (0.0756)  loss_rpn_box_reg: 0.1443 (0.1868)  time: 1.1432  data: 0.2127  max mem: 7403\n",
            "Epoch: [0]  [3000/3605]  eta: 0:11:20  lr: 0.005000  loss: 1.0068 (1.7446)  loss_classifier: 0.6538 (1.2327)  loss_box_reg: 0.1641 (0.2497)  loss_objectness: 0.0266 (0.0754)  loss_rpn_box_reg: 0.1474 (0.1868)  time: 1.1270  data: 0.2054  max mem: 7403\n",
            "Epoch: [0]  [3010/3605]  eta: 0:11:09  lr: 0.005000  loss: 1.0068 (1.7424)  loss_classifier: 0.6585 (1.2311)  loss_box_reg: 0.1669 (0.2495)  loss_objectness: 0.0248 (0.0752)  loss_rpn_box_reg: 0.1602 (0.1867)  time: 1.1126  data: 0.1998  max mem: 7403\n",
            "Epoch: [0]  [3020/3605]  eta: 0:10:57  lr: 0.005000  loss: 1.1904 (1.7419)  loss_classifier: 0.8350 (1.2307)  loss_box_reg: 0.1830 (0.2494)  loss_objectness: 0.0320 (0.0752)  loss_rpn_box_reg: 0.1591 (0.1866)  time: 1.1161  data: 0.2026  max mem: 7403\n",
            "Epoch: [0]  [3030/3605]  eta: 0:10:46  lr: 0.005000  loss: 1.3423 (1.7404)  loss_classifier: 0.9760 (1.2294)  loss_box_reg: 0.1830 (0.2492)  loss_objectness: 0.0602 (0.0752)  loss_rpn_box_reg: 0.1652 (0.1867)  time: 1.1511  data: 0.2262  max mem: 7403\n",
            "Epoch: [0]  [3040/3605]  eta: 0:10:35  lr: 0.005000  loss: 1.1714 (1.7384)  loss_classifier: 0.7857 (1.2278)  loss_box_reg: 0.1688 (0.2489)  loss_objectness: 0.0362 (0.0751)  loss_rpn_box_reg: 0.1620 (0.1865)  time: 1.1370  data: 0.2134  max mem: 7403\n",
            "Epoch: [0]  [3050/3605]  eta: 0:10:24  lr: 0.005000  loss: 1.0406 (1.7365)  loss_classifier: 0.6662 (1.2261)  loss_box_reg: 0.1688 (0.2487)  loss_objectness: 0.0359 (0.0751)  loss_rpn_box_reg: 0.1665 (0.1866)  time: 1.0922  data: 0.1860  max mem: 7403\n",
            "Epoch: [0]  [3060/3605]  eta: 0:10:12  lr: 0.005000  loss: 1.1276 (1.7346)  loss_classifier: 0.7071 (1.2245)  loss_box_reg: 0.1718 (0.2484)  loss_objectness: 0.0464 (0.0750)  loss_rpn_box_reg: 0.1886 (0.1866)  time: 1.1405  data: 0.2194  max mem: 7403\n",
            "Epoch: [0]  [3070/3605]  eta: 0:10:01  lr: 0.005000  loss: 1.1180 (1.7328)  loss_classifier: 0.7220 (1.2231)  loss_box_reg: 0.1731 (0.2483)  loss_objectness: 0.0427 (0.0749)  loss_rpn_box_reg: 0.1616 (0.1865)  time: 1.1265  data: 0.2142  max mem: 7403\n",
            "Epoch: [0]  [3080/3605]  eta: 0:09:50  lr: 0.005000  loss: 1.0192 (1.7305)  loss_classifier: 0.6804 (1.2212)  loss_box_reg: 0.1701 (0.2480)  loss_objectness: 0.0357 (0.0748)  loss_rpn_box_reg: 0.1595 (0.1865)  time: 1.0973  data: 0.1895  max mem: 7403\n",
            "Epoch: [0]  [3090/3605]  eta: 0:09:39  lr: 0.005000  loss: 1.0083 (1.7285)  loss_classifier: 0.6349 (1.2196)  loss_box_reg: 0.1572 (0.2477)  loss_objectness: 0.0336 (0.0747)  loss_rpn_box_reg: 0.1741 (0.1864)  time: 1.1217  data: 0.1884  max mem: 7403\n",
            "Epoch: [0]  [3100/3605]  eta: 0:09:27  lr: 0.005000  loss: 1.0640 (1.7268)  loss_classifier: 0.6762 (1.2183)  loss_box_reg: 0.1614 (0.2476)  loss_objectness: 0.0383 (0.0746)  loss_rpn_box_reg: 0.1504 (0.1863)  time: 1.1243  data: 0.1875  max mem: 7403\n",
            "Epoch: [0]  [3110/3605]  eta: 0:09:16  lr: 0.005000  loss: 1.0762 (1.7249)  loss_classifier: 0.7558 (1.2167)  loss_box_reg: 0.1694 (0.2473)  loss_objectness: 0.0367 (0.0745)  loss_rpn_box_reg: 0.1421 (0.1863)  time: 1.1127  data: 0.1815  max mem: 7403\n",
            "Epoch: [0]  [3120/3605]  eta: 0:09:05  lr: 0.005000  loss: 0.9541 (1.7223)  loss_classifier: 0.6232 (1.2147)  loss_box_reg: 0.1443 (0.2470)  loss_objectness: 0.0350 (0.0744)  loss_rpn_box_reg: 0.1527 (0.1862)  time: 1.1296  data: 0.1950  max mem: 7403\n",
            "Epoch: [0]  [3130/3605]  eta: 0:08:54  lr: 0.005000  loss: 0.9447 (1.7200)  loss_classifier: 0.6036 (1.2130)  loss_box_reg: 0.1447 (0.2467)  loss_objectness: 0.0231 (0.0742)  loss_rpn_box_reg: 0.1458 (0.1860)  time: 1.1502  data: 0.2107  max mem: 7403\n",
            "Epoch: [0]  [3140/3605]  eta: 0:08:42  lr: 0.005000  loss: 1.0352 (1.7181)  loss_classifier: 0.6846 (1.2115)  loss_box_reg: 0.1565 (0.2465)  loss_objectness: 0.0231 (0.0741)  loss_rpn_box_reg: 0.1458 (0.1859)  time: 1.1291  data: 0.2004  max mem: 7403\n",
            "Epoch: [0]  [3150/3605]  eta: 0:08:31  lr: 0.005000  loss: 1.1062 (1.7165)  loss_classifier: 0.7194 (1.2101)  loss_box_reg: 0.1652 (0.2463)  loss_objectness: 0.0371 (0.0740)  loss_rpn_box_reg: 0.1616 (0.1860)  time: 1.1071  data: 0.1882  max mem: 7403\n",
            "Epoch: [0]  [3160/3605]  eta: 0:08:20  lr: 0.005000  loss: 1.1062 (1.7144)  loss_classifier: 0.7273 (1.2084)  loss_box_reg: 0.1756 (0.2461)  loss_objectness: 0.0325 (0.0739)  loss_rpn_box_reg: 0.1626 (0.1860)  time: 1.0965  data: 0.1929  max mem: 7403\n",
            "Epoch: [0]  [3170/3605]  eta: 0:08:09  lr: 0.005000  loss: 1.0158 (1.7122)  loss_classifier: 0.6809 (1.2068)  loss_box_reg: 0.1596 (0.2458)  loss_objectness: 0.0201 (0.0738)  loss_rpn_box_reg: 0.1423 (0.1858)  time: 1.1027  data: 0.1900  max mem: 7403\n",
            "Epoch: [0]  [3180/3605]  eta: 0:07:57  lr: 0.005000  loss: 1.0158 (1.7100)  loss_classifier: 0.6809 (1.2051)  loss_box_reg: 0.1596 (0.2456)  loss_objectness: 0.0201 (0.0736)  loss_rpn_box_reg: 0.1310 (0.1857)  time: 1.1096  data: 0.1872  max mem: 7403\n",
            "Epoch: [0]  [3190/3605]  eta: 0:07:46  lr: 0.005000  loss: 1.0073 (1.7085)  loss_classifier: 0.6668 (1.2039)  loss_box_reg: 0.1664 (0.2454)  loss_objectness: 0.0239 (0.0735)  loss_rpn_box_reg: 0.1492 (0.1857)  time: 1.0822  data: 0.1751  max mem: 7403\n",
            "Epoch: [0]  [3200/3605]  eta: 0:07:35  lr: 0.005000  loss: 1.0818 (1.7068)  loss_classifier: 0.7334 (1.2026)  loss_box_reg: 0.1790 (0.2453)  loss_objectness: 0.0263 (0.0734)  loss_rpn_box_reg: 0.1492 (0.1855)  time: 1.0849  data: 0.1827  max mem: 7403\n",
            "Epoch: [0]  [3210/3605]  eta: 0:07:24  lr: 0.005000  loss: 1.0949 (1.7049)  loss_classifier: 0.7048 (1.2010)  loss_box_reg: 0.1652 (0.2450)  loss_objectness: 0.0399 (0.0734)  loss_rpn_box_reg: 0.1569 (0.1856)  time: 1.1339  data: 0.2084  max mem: 7403\n",
            "Epoch: [0]  [3220/3605]  eta: 0:07:12  lr: 0.005000  loss: 1.1418 (1.7037)  loss_classifier: 0.7639 (1.2001)  loss_box_reg: 0.1816 (0.2450)  loss_objectness: 0.0399 (0.0732)  loss_rpn_box_reg: 0.1478 (0.1854)  time: 1.1443  data: 0.2196  max mem: 7403\n",
            "Epoch: [0]  [3230/3605]  eta: 0:07:01  lr: 0.005000  loss: 1.1855 (1.7021)  loss_classifier: 0.8109 (1.1988)  loss_box_reg: 0.1869 (0.2448)  loss_objectness: 0.0243 (0.0731)  loss_rpn_box_reg: 0.1358 (0.1854)  time: 1.1184  data: 0.2091  max mem: 7403\n",
            "Epoch: [0]  [3240/3605]  eta: 0:06:50  lr: 0.005000  loss: 1.1405 (1.7004)  loss_classifier: 0.7336 (1.1974)  loss_box_reg: 0.1711 (0.2446)  loss_objectness: 0.0302 (0.0730)  loss_rpn_box_reg: 0.1821 (0.1854)  time: 1.1050  data: 0.1912  max mem: 7403\n",
            "Epoch: [0]  [3250/3605]  eta: 0:06:38  lr: 0.005000  loss: 0.9496 (1.6984)  loss_classifier: 0.6742 (1.1957)  loss_box_reg: 0.1651 (0.2444)  loss_objectness: 0.0336 (0.0729)  loss_rpn_box_reg: 0.1815 (0.1853)  time: 1.0983  data: 0.1998  max mem: 7403\n",
            "Epoch: [0]  [3260/3605]  eta: 0:06:27  lr: 0.005000  loss: 1.1274 (1.6970)  loss_classifier: 0.7257 (1.1946)  loss_box_reg: 0.1734 (0.2443)  loss_objectness: 0.0410 (0.0728)  loss_rpn_box_reg: 0.1679 (0.1853)  time: 1.1075  data: 0.1970  max mem: 7403\n",
            "Epoch: [0]  [3270/3605]  eta: 0:06:16  lr: 0.005000  loss: 1.1868 (1.6954)  loss_classifier: 0.7652 (1.1933)  loss_box_reg: 0.1793 (0.2441)  loss_objectness: 0.0295 (0.0727)  loss_rpn_box_reg: 0.1774 (0.1852)  time: 1.0976  data: 0.1830  max mem: 7403\n",
            "Epoch: [0]  [3280/3605]  eta: 0:06:05  lr: 0.005000  loss: 1.0463 (1.6933)  loss_classifier: 0.6776 (1.1916)  loss_box_reg: 0.1640 (0.2439)  loss_objectness: 0.0201 (0.0726)  loss_rpn_box_reg: 0.1708 (0.1852)  time: 1.1004  data: 0.2088  max mem: 7403\n",
            "Epoch: [0]  [3290/3605]  eta: 0:05:54  lr: 0.005000  loss: 1.0546 (1.6917)  loss_classifier: 0.6958 (1.1906)  loss_box_reg: 0.1541 (0.2436)  loss_objectness: 0.0242 (0.0725)  loss_rpn_box_reg: 0.1551 (0.1851)  time: 1.1352  data: 0.2284  max mem: 7403\n",
            "Epoch: [0]  [3300/3605]  eta: 0:05:42  lr: 0.005000  loss: 1.1150 (1.6905)  loss_classifier: 0.7838 (1.1896)  loss_box_reg: 0.1516 (0.2434)  loss_objectness: 0.0343 (0.0724)  loss_rpn_box_reg: 0.1551 (0.1851)  time: 1.1252  data: 0.2103  max mem: 7403\n",
            "Epoch: [0]  [3310/3605]  eta: 0:05:31  lr: 0.005000  loss: 1.1091 (1.6886)  loss_classifier: 0.7395 (1.1881)  loss_box_reg: 0.1629 (0.2432)  loss_objectness: 0.0314 (0.0723)  loss_rpn_box_reg: 0.1549 (0.1850)  time: 1.1159  data: 0.1994  max mem: 7403\n",
            "Epoch: [0]  [3320/3605]  eta: 0:05:20  lr: 0.005000  loss: 1.0523 (1.6867)  loss_classifier: 0.6877 (1.1866)  loss_box_reg: 0.1660 (0.2430)  loss_objectness: 0.0281 (0.0722)  loss_rpn_box_reg: 0.1407 (0.1849)  time: 1.1305  data: 0.1992  max mem: 7403\n",
            "Epoch: [0]  [3330/3605]  eta: 0:05:09  lr: 0.005000  loss: 0.9912 (1.6849)  loss_classifier: 0.6708 (1.1853)  loss_box_reg: 0.1640 (0.2428)  loss_objectness: 0.0299 (0.0720)  loss_rpn_box_reg: 0.1315 (0.1848)  time: 1.1413  data: 0.2182  max mem: 7403\n",
            "Epoch: [0]  [3340/3605]  eta: 0:04:57  lr: 0.005000  loss: 0.9912 (1.6833)  loss_classifier: 0.6442 (1.1841)  loss_box_reg: 0.1608 (0.2426)  loss_objectness: 0.0299 (0.0719)  loss_rpn_box_reg: 0.1411 (0.1847)  time: 1.1450  data: 0.2258  max mem: 7403\n",
            "Epoch: [0]  [3350/3605]  eta: 0:04:46  lr: 0.005000  loss: 1.0603 (1.6819)  loss_classifier: 0.7146 (1.1830)  loss_box_reg: 0.1523 (0.2424)  loss_objectness: 0.0259 (0.0718)  loss_rpn_box_reg: 0.1481 (0.1847)  time: 1.1731  data: 0.2081  max mem: 7999\n",
            "Epoch: [0]  [3360/3605]  eta: 0:04:35  lr: 0.005000  loss: 1.0603 (1.6804)  loss_classifier: 0.7146 (1.1818)  loss_box_reg: 0.1493 (0.2422)  loss_objectness: 0.0288 (0.0718)  loss_rpn_box_reg: 0.1714 (0.1847)  time: 1.1599  data: 0.1932  max mem: 7999\n",
            "Epoch: [0]  [3370/3605]  eta: 0:04:24  lr: 0.005000  loss: 0.9761 (1.6781)  loss_classifier: 0.5955 (1.1799)  loss_box_reg: 0.1621 (0.2419)  loss_objectness: 0.0285 (0.0716)  loss_rpn_box_reg: 0.1696 (0.1846)  time: 1.0949  data: 0.1808  max mem: 7999\n",
            "Epoch: [0]  [3380/3605]  eta: 0:04:12  lr: 0.005000  loss: 0.9720 (1.6761)  loss_classifier: 0.5893 (1.1784)  loss_box_reg: 0.1511 (0.2417)  loss_objectness: 0.0242 (0.0715)  loss_rpn_box_reg: 0.1591 (0.1845)  time: 1.0968  data: 0.1732  max mem: 7999\n",
            "Epoch: [0]  [3390/3605]  eta: 0:04:01  lr: 0.005000  loss: 0.8877 (1.6737)  loss_classifier: 0.6437 (1.1766)  loss_box_reg: 0.1594 (0.2414)  loss_objectness: 0.0159 (0.0714)  loss_rpn_box_reg: 0.1292 (0.1843)  time: 1.1256  data: 0.1913  max mem: 7999\n",
            "Epoch: [0]  [3400/3605]  eta: 0:03:50  lr: 0.005000  loss: 0.8877 (1.6718)  loss_classifier: 0.6107 (1.1751)  loss_box_reg: 0.1494 (0.2411)  loss_objectness: 0.0148 (0.0713)  loss_rpn_box_reg: 0.1306 (0.1842)  time: 1.1275  data: 0.2052  max mem: 7999\n",
            "Epoch: [0]  [3410/3605]  eta: 0:03:39  lr: 0.005000  loss: 0.9996 (1.6698)  loss_classifier: 0.6576 (1.1735)  loss_box_reg: 0.1504 (0.2409)  loss_objectness: 0.0318 (0.0712)  loss_rpn_box_reg: 0.1529 (0.1842)  time: 1.1191  data: 0.2062  max mem: 7999\n",
            "Epoch: [0]  [3420/3605]  eta: 0:03:27  lr: 0.005000  loss: 1.0478 (1.6684)  loss_classifier: 0.6774 (1.1725)  loss_box_reg: 0.1716 (0.2408)  loss_objectness: 0.0317 (0.0711)  loss_rpn_box_reg: 0.1529 (0.1841)  time: 1.1065  data: 0.1947  max mem: 7999\n",
            "Epoch: [0]  [3430/3605]  eta: 0:03:16  lr: 0.005000  loss: 1.0937 (1.6668)  loss_classifier: 0.6978 (1.1711)  loss_box_reg: 0.1698 (0.2406)  loss_objectness: 0.0236 (0.0710)  loss_rpn_box_reg: 0.1611 (0.1841)  time: 1.1282  data: 0.1959  max mem: 7999\n",
            "Epoch: [0]  [3440/3605]  eta: 0:03:05  lr: 0.005000  loss: 1.0379 (1.6647)  loss_classifier: 0.6422 (1.1695)  loss_box_reg: 0.1537 (0.2404)  loss_objectness: 0.0269 (0.0709)  loss_rpn_box_reg: 0.1641 (0.1840)  time: 1.1577  data: 0.2121  max mem: 7999\n",
            "Epoch: [0]  [3450/3605]  eta: 0:02:54  lr: 0.005000  loss: 0.9888 (1.6629)  loss_classifier: 0.6422 (1.1682)  loss_box_reg: 0.1489 (0.2401)  loss_objectness: 0.0243 (0.0707)  loss_rpn_box_reg: 0.1557 (0.1840)  time: 1.1441  data: 0.2163  max mem: 7999\n",
            "Epoch: [0]  [3460/3605]  eta: 0:02:43  lr: 0.005000  loss: 0.9766 (1.6612)  loss_classifier: 0.6655 (1.1668)  loss_box_reg: 0.1516 (0.2400)  loss_objectness: 0.0195 (0.0707)  loss_rpn_box_reg: 0.1508 (0.1838)  time: 1.1298  data: 0.2124  max mem: 7999\n",
            "Epoch: [0]  [3470/3605]  eta: 0:02:31  lr: 0.005000  loss: 0.9385 (1.6592)  loss_classifier: 0.6126 (1.1652)  loss_box_reg: 0.1529 (0.2397)  loss_objectness: 0.0195 (0.0705)  loss_rpn_box_reg: 0.1520 (0.1838)  time: 1.1659  data: 0.2368  max mem: 7999\n",
            "Epoch: [0]  [3480/3605]  eta: 0:02:20  lr: 0.005000  loss: 0.9385 (1.6573)  loss_classifier: 0.6082 (1.1636)  loss_box_reg: 0.1516 (0.2395)  loss_objectness: 0.0272 (0.0704)  loss_rpn_box_reg: 0.1616 (0.1837)  time: 1.1637  data: 0.2334  max mem: 7999\n",
            "Epoch: [0]  [3490/3605]  eta: 0:02:09  lr: 0.005000  loss: 0.8984 (1.6557)  loss_classifier: 0.6082 (1.1623)  loss_box_reg: 0.1550 (0.2393)  loss_objectness: 0.0272 (0.0703)  loss_rpn_box_reg: 0.1662 (0.1837)  time: 1.1432  data: 0.2102  max mem: 7999\n",
            "Epoch: [0]  [3500/3605]  eta: 0:01:58  lr: 0.005000  loss: 0.8907 (1.6534)  loss_classifier: 0.5697 (1.1606)  loss_box_reg: 0.1545 (0.2390)  loss_objectness: 0.0304 (0.0702)  loss_rpn_box_reg: 0.1345 (0.1836)  time: 1.1267  data: 0.1939  max mem: 7999\n",
            "Epoch: [0]  [3510/3605]  eta: 0:01:46  lr: 0.005000  loss: 0.8991 (1.6516)  loss_classifier: 0.5697 (1.1591)  loss_box_reg: 0.1545 (0.2388)  loss_objectness: 0.0327 (0.0702)  loss_rpn_box_reg: 0.1305 (0.1836)  time: 1.1250  data: 0.2007  max mem: 7999\n",
            "Epoch: [0]  [3520/3605]  eta: 0:01:35  lr: 0.005000  loss: 1.0704 (1.6502)  loss_classifier: 0.6919 (1.1579)  loss_box_reg: 0.1634 (0.2386)  loss_objectness: 0.0510 (0.0701)  loss_rpn_box_reg: 0.1647 (0.1836)  time: 1.1581  data: 0.2238  max mem: 7999\n",
            "Epoch: [0]  [3530/3605]  eta: 0:01:24  lr: 0.005000  loss: 1.0753 (1.6483)  loss_classifier: 0.6880 (1.1564)  loss_box_reg: 0.1567 (0.2383)  loss_objectness: 0.0427 (0.0700)  loss_rpn_box_reg: 0.1577 (0.1835)  time: 1.1558  data: 0.2064  max mem: 7999\n",
            "Epoch: [0]  [3540/3605]  eta: 0:01:13  lr: 0.005000  loss: 1.0321 (1.6473)  loss_classifier: 0.6868 (1.1556)  loss_box_reg: 0.1660 (0.2382)  loss_objectness: 0.0366 (0.0700)  loss_rpn_box_reg: 0.1518 (0.1834)  time: 1.1021  data: 0.1884  max mem: 7999\n",
            "Epoch: [0]  [3550/3605]  eta: 0:01:01  lr: 0.005000  loss: 1.1245 (1.6456)  loss_classifier: 0.6868 (1.1542)  loss_box_reg: 0.1664 (0.2380)  loss_objectness: 0.0490 (0.0700)  loss_rpn_box_reg: 0.1599 (0.1834)  time: 1.0917  data: 0.1969  max mem: 7999\n",
            "Epoch: [0]  [3560/3605]  eta: 0:00:50  lr: 0.005000  loss: 1.0501 (1.6442)  loss_classifier: 0.6805 (1.1530)  loss_box_reg: 0.1624 (0.2379)  loss_objectness: 0.0501 (0.0700)  loss_rpn_box_reg: 0.1589 (0.1833)  time: 1.1393  data: 0.2118  max mem: 7999\n",
            "Epoch: [0]  [3570/3605]  eta: 0:00:39  lr: 0.005000  loss: 1.0558 (1.6430)  loss_classifier: 0.7055 (1.1521)  loss_box_reg: 0.1624 (0.2377)  loss_objectness: 0.0359 (0.0699)  loss_rpn_box_reg: 0.1501 (0.1832)  time: 1.1279  data: 0.2100  max mem: 7999\n",
            "Epoch: [0]  [3580/3605]  eta: 0:00:28  lr: 0.005000  loss: 1.1584 (1.6415)  loss_classifier: 0.7444 (1.1510)  loss_box_reg: 0.1639 (0.2375)  loss_objectness: 0.0370 (0.0699)  loss_rpn_box_reg: 0.1500 (0.1831)  time: 1.1186  data: 0.2144  max mem: 7999\n",
            "Epoch: [0]  [3590/3605]  eta: 0:00:16  lr: 0.005000  loss: 1.0511 (1.6402)  loss_classifier: 0.7444 (1.1501)  loss_box_reg: 0.1637 (0.2373)  loss_objectness: 0.0280 (0.0698)  loss_rpn_box_reg: 0.1438 (0.1830)  time: 1.1292  data: 0.2106  max mem: 7999\n",
            "Epoch: [0]  [3600/3605]  eta: 0:00:05  lr: 0.005000  loss: 0.9541 (1.6382)  loss_classifier: 0.6311 (1.1486)  loss_box_reg: 0.1499 (0.2370)  loss_objectness: 0.0193 (0.0697)  loss_rpn_box_reg: 0.1315 (0.1829)  time: 1.0938  data: 0.1878  max mem: 7999\n",
            "Epoch: [0]  [3604/3605]  eta: 0:00:01  lr: 0.005000  loss: 0.9046 (1.6373)  loss_classifier: 0.6189 (1.1479)  loss_box_reg: 0.1486 (0.2369)  loss_objectness: 0.0186 (0.0696)  loss_rpn_box_reg: 0.1289 (0.1829)  time: 1.0727  data: 0.1743  max mem: 7999\n",
            "Epoch: [0] Total time: 1:07:33 (1.1244 s / it)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-JtKezdzCmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import utils\n",
        "import math\n",
        "import sys\n",
        "\n",
        "def train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq):\n",
        "    model.train()\n",
        "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
        "    metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value:.6f}'))\n",
        "    header = 'Epoch: [{}]'.format(epoch)\n",
        "\n",
        "    lr_scheduler = None\n",
        "    if epoch == 0:\n",
        "        warmup_factor = 1. / 1000\n",
        "        warmup_iters = min(1000, len(data_loader) - 1)\n",
        "\n",
        "        lr_scheduler = utils.warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor)\n",
        "\n",
        "    for images, targets in metric_logger.log_every(data_loader, print_freq, header):\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        loss_dict = model(images, targets)\n",
        "\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        # reduce losses over all GPUs for logging purposes\n",
        "        loss_dict_reduced = utils.reduce_dict(loss_dict)\n",
        "        losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
        "\n",
        "        loss_value = losses_reduced.item()\n",
        "\n",
        "        if not math.isfinite(loss_value):\n",
        "            print(\"Loss is {}, stopping training\".format(loss_value))\n",
        "            print(loss_dict_reduced)\n",
        "            sys.exit(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if lr_scheduler is not None:\n",
        "            lr_scheduler.step()\n",
        "\n",
        "        metric_logger.update(loss=losses_reduced, **loss_dict_reduced)\n",
        "        metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VGrNf110y8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch = 1\n",
        "print('Epoch: [{}]'.format(epoch))\n",
        "train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gt6uB_oVQAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test dataset:\n",
        "# Defining the dataset:\n",
        "'''\n",
        "https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html\n",
        "'''\n",
        "import os\n",
        "import numpy as np\n",
        "import torch.utils.data\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "\n",
        "class KuzushijiTDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, df, root, mode='train', transforms=None):\n",
        "    self.records = df.to_records(index=False)\n",
        "    self.root = root\n",
        "    self.mode = mode\n",
        "    self.transforms = transforms\n",
        "    self.len = df.shape[0]    \n",
        "    \n",
        "  def __getitem__(self, index):\n",
        "    imgs = self.records[index].image_id\n",
        "    img = Image.open(os.path.join(root, imgs)).convert(\"RGB\")\n",
        "    \n",
        "    img_id = torch.tensor([index])\n",
        "    \n",
        "    if self.transforms is not None:\n",
        "      img = self.transforms(img)\n",
        "      \n",
        "    return img, img_id\n",
        "    \n",
        "  def __len__(self):\n",
        "    return self.len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfOdEmSnloPh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "bc50d33c-8dfa-4549-a191-fa1b2cff71c3"
      },
      "source": [
        "import pandas as pd\n",
        "submission = pd.read_csv('sample_submission.csv')\n",
        "print(submission.shape, submission.head())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4150, 2)         image_id                 labels\n",
            "0  test_00145af3  U+003F 1 1 U+FF2F 2 2\n",
            "1  test_001c37e2  U+003F 1 1 U+FF2F 2 2\n",
            "2  test_003aa33a  U+003F 1 1 U+FF2F 2 2\n",
            "3  test_00665e33  U+003F 1 1 U+FF2F 2 2\n",
            "4  test_006964dc  U+003F 1 1 U+FF2F 2 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04Fd_ZZAlqZZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f59a7468-6cb9-4c1f-9c17-421294ec4284"
      },
      "source": [
        "submission['image_id'] = submission.image_id + '.jpg'\n",
        "submission.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test_00145af3.jpg</td>\n",
              "      <td>U+003F 1 1 U+FF2F 2 2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test_001c37e2.jpg</td>\n",
              "      <td>U+003F 1 1 U+FF2F 2 2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test_003aa33a.jpg</td>\n",
              "      <td>U+003F 1 1 U+FF2F 2 2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test_00665e33.jpg</td>\n",
              "      <td>U+003F 1 1 U+FF2F 2 2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test_006964dc.jpg</td>\n",
              "      <td>U+003F 1 1 U+FF2F 2 2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            image_id                 labels\n",
              "0  test_00145af3.jpg  U+003F 1 1 U+FF2F 2 2\n",
              "1  test_001c37e2.jpg  U+003F 1 1 U+FF2F 2 2\n",
              "2  test_003aa33a.jpg  U+003F 1 1 U+FF2F 2 2\n",
              "3  test_00665e33.jpg  U+003F 1 1 U+FF2F 2 2\n",
              "4  test_006964dc.jpg  U+003F 1 1 U+FF2F 2 2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1D_4dxGzP7_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b51ff34f-9f4a-4daf-8b89-65a47f5f3aa5"
      },
      "source": [
        "submission.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4150, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUGqSxO5lr4k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "490147ec-f0f0-4beb-9754-03d20b11f7d8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "root = 'test_images'\n",
        "\n",
        "Tdataset = KuzushijiTDataset(submission, root, transforms=T.ToTensor())\n",
        "\n",
        "for i in range(len(dataset)):\n",
        "  img, lbl = Tdataset[i]\n",
        "  \n",
        "  print(i, img.shape, lbl.shape)\n",
        "  \n",
        "  if i == 2:\n",
        "    break"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 torch.Size([3, 3394, 2210]) torch.Size([1])\n",
            "1 torch.Size([3, 3134, 2046]) torch.Size([1])\n",
            "2 torch.Size([3, 3122, 1990]) torch.Size([1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMWkvDOolszd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "c7165513-fc87-4c9f-a45b-4e312c5a3d51"
      },
      "source": [
        "Tdataset[0]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.5882, 0.5961, 0.6039,  ..., 0.6980, 0.7020, 0.7020],\n",
              "          [0.5882, 0.5922, 0.6039,  ..., 0.6941, 0.7020, 0.7020],\n",
              "          [0.5843, 0.5882, 0.6000,  ..., 0.6941, 0.6980, 0.6980],\n",
              "          ...,\n",
              "          [0.5843, 0.5961, 0.6000,  ..., 0.6824, 0.6824, 0.6824],\n",
              "          [0.5804, 0.5922, 0.6039,  ..., 0.6863, 0.6902, 0.6902],\n",
              "          [0.5882, 0.6039, 0.6118,  ..., 0.6863, 0.6902, 0.6902]],\n",
              " \n",
              "         [[0.5686, 0.5765, 0.5843,  ..., 0.6980, 0.7020, 0.7020],\n",
              "          [0.5686, 0.5725, 0.5843,  ..., 0.6941, 0.7020, 0.7020],\n",
              "          [0.5647, 0.5686, 0.5804,  ..., 0.6941, 0.6980, 0.6980],\n",
              "          ...,\n",
              "          [0.5647, 0.5765, 0.5804,  ..., 0.6784, 0.6784, 0.6784],\n",
              "          [0.5608, 0.5725, 0.5843,  ..., 0.6824, 0.6863, 0.6863],\n",
              "          [0.5686, 0.5843, 0.5922,  ..., 0.6824, 0.6863, 0.6863]],\n",
              " \n",
              "         [[0.5451, 0.5529, 0.5608,  ..., 0.6667, 0.6706, 0.6706],\n",
              "          [0.5451, 0.5490, 0.5608,  ..., 0.6627, 0.6706, 0.6706],\n",
              "          [0.5412, 0.5451, 0.5569,  ..., 0.6627, 0.6667, 0.6667],\n",
              "          ...,\n",
              "          [0.5412, 0.5529, 0.5569,  ..., 0.6627, 0.6627, 0.6627],\n",
              "          [0.5373, 0.5490, 0.5608,  ..., 0.6667, 0.6706, 0.6706],\n",
              "          [0.5451, 0.5608, 0.5686,  ..., 0.6667, 0.6706, 0.6706]]]),\n",
              " tensor([0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrmt15PEluuk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import utils\n",
        "\n",
        "Tdata_loader = torch.utils.data.DataLoader(Tdataset,\n",
        "                                          batch_size=1,\n",
        "                                          shuffle=False,\n",
        "                                          #num_workers=4,\n",
        "                                          collate_fn=utils.collate_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "790g6Aoul1RP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for images, labels in Tdata_loader:\n",
        "  print(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XVJQKWxmGwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = []\n",
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  for images, labels in Tdata_loader:\n",
        "    images = list(image.to(device) for image in images)\n",
        "    output = model(images)\n",
        "    res = {labels: output}\n",
        "    #labels = [{k: v.to(device) for k, v in t.items()} for t in labels]\n",
        "   # output = model(images, labels)\n",
        "    #res = {label[\"image_id\"].item(): outputs for label, outputs in zip(labels, output)}\n",
        "    pred.append(res)\n",
        "    del images, output, res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jk4UmD0yx15",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f62aac2-2803-4750-e8d7-f29ad9966633"
      },
      "source": [
        "len(pred)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4150"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvog7QV-UlmU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "617ac903-fa69-482e-fc86-136dc007284f"
      },
      "source": [
        "a = pred[0]\n",
        "for k, v in a.items():\n",
        "  print(int(k[0].cpu().numpy()))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umEnIjxnVDjd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca8781c9-b7ad-47e1-86ea-866ea4afaf3a"
      },
      "source": [
        "a = pred[0]\n",
        "for k, v in a.items():\n",
        "  b = v[0]\n",
        "  c = b['boxes'].cpu().numpy()\n",
        "  print(c.shape)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g-_wdFMMcShh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9c71c14-4d50-44cd-c6ce-3d0978d0a7bb"
      },
      "source": [
        "records = submission.to_records(index=False)\n",
        "records[0]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('test_00145af3.jpg', 'U+003F 1 1 U+FF2F 2 2')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VRLgFDXmv17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels2unicode = {v: k for k, v in unicode2labels.items()}\n",
        "labels2unicode"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C63OOoUTmwgi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "comps = []\n",
        "img_id = []\n",
        "for elm in pred:\n",
        "  for k, v in elm.items():\n",
        "    \n",
        "    img_id.append(records[int(k[0].cpu().numpy())].image_id)\n",
        "    b = v[0]\n",
        "    box = b['boxes'].cpu().numpy()\n",
        "    lb = b['labels'].cpu().numpy()\n",
        "    \n",
        "    ulb = []\n",
        "    \n",
        "    for em in lb:\n",
        "      uelm = labels2unicode[em]\n",
        "      ulb.append(uelm)\n",
        "      \n",
        "    comp = []\n",
        "    \n",
        "    for i in range(lb.shape[0]):\n",
        "      sng = [ulb[i], box[i]]\n",
        "      comp.append(sng)\n",
        "      #comp.append(ulb[i])\n",
        "      #comp.append(box[i])\n",
        "    \n",
        "    comps.append(comp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5bnU4OGGeh6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1da6e58c-302e-4106-9da2-132a1ba97e89"
      },
      "source": [
        "len(comps[0])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHf6oYORcoWa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b9f5d4f5-78ff-4e5d-960f-472497d29af3"
      },
      "source": [
        "comps[0]"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['U+3075',\n",
              "  array([ 998.8686, 1548.1893, 1121.5999, 1639.9849], dtype=float32)],\n",
              " ['U+3084',\n",
              "  array([ 662.05084, 2510.2322 ,  782.7215 , 2587.9036 ], dtype=float32)],\n",
              " ['U+3075',\n",
              "  array([ 498.54675, 2867.594  ,  607.64044, 2974.871  ], dtype=float32)],\n",
              " ['U+3084',\n",
              "  array([1668.7532,  953.1088, 1781.6333, 1045.1973], dtype=float32)],\n",
              " ['U+3066',\n",
              "  array([ 532.74506, 1693.211  ,  615.25037, 1789.0995 ], dtype=float32)],\n",
              " ['U+306E',\n",
              "  array([1337.6643, 1930.4438, 1425.0494, 2023.9517], dtype=float32)],\n",
              " ['U+3066',\n",
              "  array([1369.6523,  824.2311, 1446.9543,  929.3372], dtype=float32)],\n",
              " ['U+3084',\n",
              "  array([ 824.80505, 2301.4597 ,  947.4589 , 2379.9485 ], dtype=float32)],\n",
              " ['U+3066',\n",
              "  array([1500.4342, 2362.0554, 1576.6232, 2455.369 ], dtype=float32)],\n",
              " ['U+3044',\n",
              "  array([1016.46344, 1480.9626 , 1107.9977 , 1544.611  ], dtype=float32)],\n",
              " ['U+306E',\n",
              "  array([ 207.61516, 1418.5038 ,  309.52695, 1506.055  ], dtype=float32)],\n",
              " ['U+3075',\n",
              "  array([ 505.91068, 1896.2976 ,  615.3127 , 1982.6539 ], dtype=float32)],\n",
              " ['U+3066',\n",
              "  array([714.6158 , 673.29236, 793.88086, 762.4994 ], dtype=float32)],\n",
              " ['U+3075',\n",
              "  array([1794.13  , 1553.7358, 1912.5775, 1643.3317], dtype=float32)],\n",
              " ['U+3046',\n",
              "  array([ 866.09015, 2385.1086 ,  906.4138 , 2518.9358 ], dtype=float32)],\n",
              " ['U+3066',\n",
              "  array([1207.5676,  860.7496, 1267.2292,  977.9886], dtype=float32)],\n",
              " ['U+3066',\n",
              "  array([ 183.1611 , 2513.185  ,  259.20007, 2618.353  ], dtype=float32)],\n",
              " ['U+308C',\n",
              "  array([532.7096 , 653.16174, 660.036  , 754.134  ], dtype=float32)],\n",
              " ['U+3075',\n",
              "  array([ 174.65022, 2087.5693 ,  287.60474, 2186.0652 ], dtype=float32)],\n",
              " ['U+3064',\n",
              "  array([541.78345, 571.1156 , 634.16406, 646.9525 ], dtype=float32)],\n",
              " ['U+3044',\n",
              "  array([ 195.75807, 1833.9296 ,  297.5735 , 1902.9583 ], dtype=float32)],\n",
              " ['U+304B',\n",
              "  array([1155.3492, 2490.9626, 1254.9022, 2546.017 ], dtype=float32)],\n",
              " ['U+3066',\n",
              "  array([1697.6478, 1325.119 , 1741.2604, 1457.7084], dtype=float32)],\n",
              " ['U+306B',\n",
              "  array([1512.0695, 1267.5731, 1610.6174, 1365.9855], dtype=float32)],\n",
              " ['U+3042',\n",
              "  array([1803.8083, 2702.948 , 1893.8041, 2801.5525], dtype=float32)],\n",
              " ['U+3092',\n",
              "  array([1031.5472 ,  894.6992 , 1145.8535 , 1011.74554], dtype=float32)],\n",
              " ['U+3068',\n",
              "  array([  56.957394, 2551.113   ,   84.72764 , 2666.5935  ], dtype=float32)],\n",
              " ['U+306B',\n",
              "  array([  80.91894, 1134.2836 ,  125.53047, 1230.3057 ], dtype=float32)],\n",
              " ['U+3046',\n",
              "  array([ 878.5613, 1867.3077,  918.4474, 2001.0819], dtype=float32)],\n",
              " ['U+308C',\n",
              "  array([1821.4359,  969.6216, 1937.5088, 1075.469 ], dtype=float32)],\n",
              " ['U+3046',\n",
              "  array([ 571.06866,  924.00433,  607.8193 , 1038.5793 ], dtype=float32)],\n",
              " ['U+304D',\n",
              "  array([ 729.73267, 1165.0605 ,  783.2406 , 1283.1884 ], dtype=float32)],\n",
              " ['U+3068',\n",
              "  array([ 422.15207, 1008.0534 ,  453.91342, 1112.3308 ], dtype=float32)],\n",
              " ['U+3068',\n",
              "  array([1060.0079, 1339.4905, 1091.9509, 1458.823 ], dtype=float32)],\n",
              " ['U+3068',\n",
              "  array([1700.9896, 1573.3226, 1730.6737, 1686.1902], dtype=float32)],\n",
              " ['U+3075',\n",
              "  array([ 987.81433, 2202.4036 , 1098.8221 , 2303.7788 ], dtype=float32)],\n",
              " ['U+3066',\n",
              "  array([1212.4752, 1909.194 , 1254.1262, 2057.119 ], dtype=float32)],\n",
              " ['U+3066',\n",
              "  array([1852.1995, 1075.1213, 1921.1221, 1159.9661], dtype=float32)],\n",
              " ['U+3068',\n",
              "  array([ 100.28242, 1547.5769 ,  129.92505, 1663.9657 ], dtype=float32)],\n",
              " ['U+306E',\n",
              "  array([1340.233 , 1171.642 , 1464.1355, 1268.8542], dtype=float32)],\n",
              " ['U+3066',\n",
              "  array([ 218.81134, 1262.7417 ,  292.67502, 1347.4628 ], dtype=float32)],\n",
              " ['U+304F',\n",
              "  array([ 530.1622 , 2480.408  ,  571.33203, 2611.4153 ], dtype=float32)],\n",
              " ['U+3078',\n",
              "  array([ 846.293 , 1007.3909,  981.0758, 1068.8584], dtype=float32)],\n",
              " ['U+306B',\n",
              "  array([ 711.01807, 1860.2361 ,  759.2541 , 1959.4945 ], dtype=float32)],\n",
              " ['U+308C',\n",
              "  array([ 151.88884, 2975.3413 ,  299.3399 , 3085.0557 ], dtype=float32)],\n",
              " ['U+3042',\n",
              "  array([885.771  , 576.00415, 975.91547, 689.6696 ], dtype=float32)],\n",
              " ['U+3072',\n",
              "  array([ 851.9434 , 1500.8044 ,  956.34296, 1603.148  ], dtype=float32)],\n",
              " ['U+307E',\n",
              "  array([1184.3534, 2237.9397, 1225.1976, 2343.0498], dtype=float32)],\n",
              " ['U+306F',\n",
              "  array([ 325.2853 , 2667.2434 ,  433.12076, 2726.303  ], dtype=float32)],\n",
              " ['U+304B',\n",
              "  array([1023.967 , 2606.1868, 1071.5225, 2675.3203], dtype=float32)],\n",
              " ['U+3093',\n",
              "  array([1342.3931, 1584.0955, 1436.2948, 1675.2538], dtype=float32)],\n",
              " ['U+3093',\n",
              "  array([ 676.2241, 2664.0713,  761.3745, 2755.7678], dtype=float32)],\n",
              " ['U+3066',\n",
              "  array([ 366.56372, 1762.3525 ,  446.35132, 1857.4764 ], dtype=float32)],\n",
              " ['U+307E',\n",
              "  array([1832.2949, 2360.653 , 1870.4769, 2465.734 ], dtype=float32)],\n",
              " ['U+3072',\n",
              "  array([ 189.00752, 2277.876  ,  280.28088, 2394.258  ], dtype=float32)],\n",
              " ['U+306A',\n",
              "  array([ 700.16785, 1509.0397 ,  798.5044 , 1610.6898 ], dtype=float32)],\n",
              " ['U+306B', array([ 78.4879, 828.4661, 133.8093, 922.0119], dtype=float32)],\n",
              " ['U+308A',\n",
              "  array([559.2818 , 813.441  , 637.8696 , 930.68115], dtype=float32)],\n",
              " ['U+7533',\n",
              "  array([ 852.0651, 2626.5579,  908.6783, 2784.3354], dtype=float32)],\n",
              " ['U+306F',\n",
              "  array([714.6444 , 778.59625, 815.12714, 832.02527], dtype=float32)],\n",
              " ['U+304D',\n",
              "  array([ 694.759  , 2363.3772 ,  763.05194, 2490.6628 ], dtype=float32)],\n",
              " ['U+3031',\n",
              "  array([ 535.7177, 2593.871 ,  608.2541, 2761.601 ], dtype=float32)],\n",
              " ['U+3068',\n",
              "  array([ 865.7269, 2524.0928,  900.3897, 2613.9626], dtype=float32)],\n",
              " ['U+306A',\n",
              "  array([ 689.33307, 2202.9365 ,  773.9341 , 2349.202  ], dtype=float32)],\n",
              " ['U+3067',\n",
              "  array([ 714.77216,  912.39386,  809.15814, 1026.4264 ], dtype=float32)],\n",
              " ['U+3031',\n",
              "  array([1371.9669, 2055.128 , 1429.1705, 2199.2112], dtype=float32)],\n",
              " ['U+305B',\n",
              "  array([1359.8259 ,  734.26385, 1453.0137 ,  817.67694], dtype=float32)],\n",
              " ['U+3072',\n",
              "  array([1001.8861, 1982.8489, 1104.1548, 2089.5305], dtype=float32)],\n",
              " ['U+516D',\n",
              "  array([  62.38176,  937.9822 ,  151.35316, 1005.9477 ], dtype=float32)],\n",
              " ['U+308A',\n",
              "  array([ 866.6574, 1765.1211,  943.4114, 1873.4644], dtype=float32)],\n",
              " ['U+3060',\n",
              "  array([1175.1359, 2363.1265, 1267.1381, 2472.5093], dtype=float32)],\n",
              " ['U+3092',\n",
              "  array([1183.5597, 1715.6156, 1287.7762, 1828.9794], dtype=float32)],\n",
              " ['U+3068',\n",
              "  array([ 93.83398, 656.2584 , 124.41737, 753.2602 ], dtype=float32)],\n",
              " ['U+308B',\n",
              "  array([1534.3187, 1823.8121, 1586.0496, 1911.881 ], dtype=float32)],\n",
              " ['U+3068',\n",
              "  array([ 709.05865, 2760.5566 ,  738.22327, 2845.375  ], dtype=float32)],\n",
              " ['U+305D',\n",
              "  array([  70.02297, 1760.6359 ,  128.37085, 1876.7169 ], dtype=float32)],\n",
              " ['U+4E16',\n",
              "  array([ 473.1432, 2312.7458,  626.1905, 2400.7283], dtype=float32)],\n",
              " ['U+4E00',\n",
              "  array([ 984.22003, 2780.3733 , 1081.0369 , 2818.531  ], dtype=float32)],\n",
              " ['U+304B',\n",
              "  array([1371.1577, 1682.8474, 1409.277 , 1755.9259], dtype=float32)],\n",
              " ['U+307F',\n",
              "  array([242.86552, 812.50574, 283.22205, 906.91583], dtype=float32)],\n",
              " ['U+307E',\n",
              "  array([ 195.81834, 2623.095  ,  243.20258, 2725.875  ], dtype=float32)],\n",
              " ['U+3072',\n",
              "  array([ 649.984  , 2958.8103 ,  759.37415, 3074.2822 ], dtype=float32)],\n",
              " ['U+304F',\n",
              "  array([1078.4427, 1209.0503, 1120.8469, 1337.5844], dtype=float32)],\n",
              " ['U+3046',\n",
              "  array([ 883.21295, 2098.0522 ,  914.99536, 2201.1917 ], dtype=float32)],\n",
              " ['U+308B',\n",
              "  array([1679.0668, 2815.0493, 1725.7749, 2893.7827], dtype=float32)],\n",
              " ['U+306F',\n",
              "  array([409.654  , 568.1971 , 458.80225, 679.7025 ], dtype=float32)],\n",
              " ['U+3072',\n",
              "  array([ 992.7147, 2395.1733, 1098.7156, 2496.863 ], dtype=float32)],\n",
              " ['U+3031',\n",
              "  array([ 356.2607, 2901.2493,  422.4489, 3043.2979], dtype=float32)],\n",
              " ['U+3053',\n",
              "  array([ 533.3116, 2776.3904,  591.5289, 2849.9111], dtype=float32)],\n",
              " ['U+3068',\n",
              "  array([1054.4657, 1740.8372, 1085.3799, 1872.6913], dtype=float32)],\n",
              " ['U+3082',\n",
              "  array([1222.983  ,  667.3608 , 1271.3948 ,  764.57355], dtype=float32)],\n",
              " ['U+306A',\n",
              "  array([1340.082 , 2640.2803, 1411.6451, 2726.7878], dtype=float32)],\n",
              " ['U+3089',\n",
              "  array([ 542.5564, 2960.0051,  588.6379, 3056.619 ], dtype=float32)],\n",
              " ['U+304B',\n",
              "  array([1685.9268,  780.9855, 1777.2606,  846.1112], dtype=float32)],\n",
              " ['U+3081',\n",
              "  array([721.6465 , 827.29736, 791.636  , 912.02   ], dtype=float32)],\n",
              " ['U+7533',\n",
              "  array([ 409.78186, 1120.8271 ,  462.38528, 1279.759  ], dtype=float32)],\n",
              " ['U+3089',\n",
              "  array([1871.3788 ,  774.44495, 1914.1929 ,  888.0196 ], dtype=float32)],\n",
              " ['U+3081',\n",
              "  array([ 360.9536, 2190.78  ,  443.6187, 2275.8293], dtype=float32)],\n",
              " ['U+305F',\n",
              "  array([1170.8479, 1361.2179, 1266.8679, 1469.3907], dtype=float32)],\n",
              " ['U+3066',\n",
              "  array([  72.43834, 1785.5078 ,  129.50291, 1880.1749 ], dtype=float32)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qzRJh-oQLUM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = []\n",
        "for item in comps:\n",
        "  c = [] \n",
        "  for i in item:\n",
        "    a = i[1]\n",
        "    x, y, z, w = int(a[0]), int(a[1]), int(a[2]) - int(a[0]), int(a[3]) - int(a[1])\n",
        "    #b = [i[0], x, y, z, w]\n",
        "    c.append(i[0])\n",
        "    c.append(x)\n",
        "    c.append(y)\n",
        "    c.append(z)\n",
        "    c.append(w)\n",
        "  d.append(np.asarray(c))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51pW_z45c5tk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "07299c6c-4e9b-4c43-f264-b3db2e474c3b"
      },
      "source": [
        "d[0].shape"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEErEFpsdRAP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "365ef31b-e3ca-411f-8f43-20c20d73f3fa"
      },
      "source": [
        "e[0].shape"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf6ArP7GSIgG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ed293dff-c3fa-44e5-b7f1-5f4ef8f52469"
      },
      "source": [
        "e = np.array([np.array(xi) for xi in d])\n",
        "e"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([array(['U+3075', '998', '1548', '123', '91', 'U+3084', '662', '2510',\n",
              "       '120', '77', 'U+3075', '498', '2867', '109', '107', 'U+3084',\n",
              "       '1668', '953', '113', '92', 'U+3066', '532', '1693', '83', '96',\n",
              "       'U+306E', '1337', '1930', '88', '93', 'U+3066', '1369', '824',\n",
              "       '77', '105', 'U+3084', '824', '2301', '123', '78', 'U+3066',\n",
              "       '1500', '2362', '76', '93', 'U+3044', '1016', '1480', '91', '64',\n",
              "       'U+306E', '207', '1418', '102', '88', 'U+3075', '505', '1896',\n",
              "       '110', '86', 'U+3066', '714', '673', '79', '89', 'U+3075', '1794',\n",
              "       '1553', '118', '90', 'U+3046', '866', '2385', '40', '133',\n",
              "       'U+3066', '1207', '860', '60', '117', 'U+3066', '183', '2513',\n",
              "       '76', '105', 'U+308C', '532', '653', '128', '101', 'U+3075', '174',\n",
              "       '2087', '113', '99', 'U+3064', '541', '571', '93', '75', 'U+3044',\n",
              "       '195', '1833', '102', '69', 'U+304B', '1155', '2490', '99', '56',\n",
              "       'U+3066', '1697', '1325', '44', '132', 'U+306B', '1512', '1267',\n",
              "       '98', '98', 'U+3042', '1803', '2702', '90', '99', 'U+3092', '1031',\n",
              "       '894', '114', '117', 'U+3068', '56', '2551', '28', '115', 'U+306B',\n",
              "       '80', '1134', '45', '96', 'U+3046', '878', '1867', '40', '134',\n",
              "       'U+308C', '1821', '969', '116', '106', 'U+3046', '571', '924',\n",
              "       '36', '114', 'U+304D', '729', '1165', '54', '118', 'U+3068', '422',\n",
              "       '1008', '31', '104', 'U+3068', '1060', '1339', '31', '119',\n",
              "       'U+3068', '1700', '1573', '30', '113', 'U+3075', '987', '2202',\n",
              "       '111', '101', 'U+3066', '1212', '1909', '42', '148', 'U+3066',\n",
              "       '1852', '1075', '69', '84', 'U+3068', '100', '1547', '29', '116',\n",
              "       'U+306E', '1340', '1171', '124', '97', 'U+3066', '218', '1262',\n",
              "       '74', '85', 'U+304F', '530', '2480', '41', '131', 'U+3078', '846',\n",
              "       '1007', '135', '61', 'U+306B', '711', '1860', '48', '99', 'U+308C',\n",
              "       '151', '2975', '148', '110', 'U+3042', '885', '576', '90', '113',\n",
              "       'U+3072', '851', '1500', '105', '103', 'U+307E', '1184', '2237',\n",
              "       '41', '106', 'U+306F', '325', '2667', '108', '59', 'U+304B',\n",
              "       '1023', '2606', '48', '69', 'U+3093', '1342', '1584', '94', '91',\n",
              "       'U+3093', '676', '2664', '85', '91', 'U+3066', '366', '1762', '80',\n",
              "       '95', 'U+307E', '1832', '2360', '38', '105', 'U+3072', '189',\n",
              "       '2277', '91', '117', 'U+306A', '700', '1509', '98', '101',\n",
              "       'U+306B', '78', '828', '55', '94', 'U+308A', '559', '813', '78',\n",
              "       '117', 'U+7533', '852', '2626', '56', '158', 'U+306F', '714',\n",
              "       '778', '101', '54', 'U+304D', '694', '2363', '69', '127', 'U+3031',\n",
              "       '535', '2593', '73', '168', 'U+3068', '865', '2524', '35', '89',\n",
              "       'U+306A', '689', '2202', '84', '147', 'U+3067', '714', '912', '95',\n",
              "       '114', 'U+3031', '1371', '2055', '58', '144', 'U+305B', '1359',\n",
              "       '734', '94', '83', 'U+3072', '1001', '1982', '103', '107',\n",
              "       'U+516D', '62', '937', '89', '68', 'U+308A', '866', '1765', '77',\n",
              "       '108', 'U+3060', '1175', '2363', '92', '109', 'U+3092', '1183',\n",
              "       '1715', '104', '113', 'U+3068', '93', '656', '31', '97', 'U+308B',\n",
              "       '1534', '1823', '52', '88', 'U+3068', '709', '2760', '29', '85',\n",
              "       'U+305D', '70', '1760', '58', '116', 'U+4E16', '473', '2312',\n",
              "       '153', '88', 'U+4E00', '984', '2780', '97', '38', 'U+304B', '1371',\n",
              "       '1682', '38', '73', 'U+307F', '242', '812', '41', '94', 'U+307E',\n",
              "       '195', '2623', '48', '102', 'U+3072', '649', '2958', '110', '116',\n",
              "       'U+304F', '1078', '1209', '42', '128', 'U+3046', '883', '2098',\n",
              "       '31', '103', 'U+308B', '1679', '2815', '46', '78', 'U+306F', '409',\n",
              "       '568', '49', '111', 'U+3072', '992', '2395', '106', '101',\n",
              "       'U+3031', '356', '2901', '66', '142', 'U+3053', '533', '2776',\n",
              "       '58', '73', 'U+3068', '1054', '1740', '31', '132', 'U+3082',\n",
              "       '1222', '667', '49', '97', 'U+306A', '1340', '2640', '71', '86',\n",
              "       'U+3089', '542', '2960', '46', '96', 'U+304B', '1685', '780', '92',\n",
              "       '66', 'U+3081', '721', '827', '70', '85', 'U+7533', '409', '1120',\n",
              "       '53', '159', 'U+3089', '1871', '774', '43', '114', 'U+3081', '360',\n",
              "       '2190', '83', '85', 'U+305F', '1170', '1361', '96', '108',\n",
              "       'U+3066', '72', '1785', '57', '95'], dtype='<U6'),\n",
              "       array(['U+3057', '1290', '1824', '86', '99', 'U+306E', '1143', '1404',\n",
              "       '67', '71', 'U+306E', '501', '746', '60', '61', 'U+3057', '1167',\n",
              "       '2120', '26', '128', 'U+306E', '500', '2589', '62', '55', 'U+3068',\n",
              "       '992', '2312', '34', '94', 'U+3084', '669', '2012', '72', '70',\n",
              "       'U+306E', '661', '1538', '64', '75', 'U+306E', '339', '2129', '71',\n",
              "       '52', 'U+3066', '330', '1865', '49', '83', 'U+306E', '1612',\n",
              "       '1421', '66', '72', 'U+4EBA', '960', '1661', '112', '115',\n",
              "       'U+3078', '1129', '2785', '77', '65', 'U+308A', '824', '2022',\n",
              "       '52', '110', 'U+306E', '1296', '2249', '71', '69', 'U+3057',\n",
              "       '1328', '1923', '22', '154', 'U+308A', '352', '1146', '48', '105',\n",
              "       'U+306B', '1456', '1254', '72', '69', 'U+308D', '819', '1827',\n",
              "       '67', '79', 'U+304D', '655', '2284', '70', '122', 'U+3075', '1132',\n",
              "       '1956', '76', '87', 'U+3084', '499', '2768', '70', '74', 'U+305F',\n",
              "       '823', '2291', '42', '108', 'U+306B', '813', '986', '79', '71',\n",
              "       'U+3082', '656', '1916', '53', '87', 'U+3082', '1463', '2739',\n",
              "       '67', '110', 'U+308D', '497', '1147', '67', '92', 'U+304F', '994',\n",
              "       '2179', '39', '136', 'U+3089', '1490', '1725', '26', '106',\n",
              "       'U+3053', '519', '1046', '33', '85', 'U+307E', '657', '2114', '74',\n",
              "       '95', 'U+304F', '977', '2403', '70', '70', 'U+304F', '194', '1075',\n",
              "       '28', '113', 'U+306C', '1291', '1739', '84', '88', 'U+6B64', '498',\n",
              "       '2119', '80', '74', 'U+4EBA', '1446', '1430', '96', '100',\n",
              "       'U+6B64', '1295', '2086', '72', '93', 'U+306F', '508', '2353',\n",
              "       '54', '30', 'U+7269', '800', '2569', '92', '80', 'U+306B', '985',\n",
              "       '939', '68', '63', 'U+3068', '674', '1200', '27', '98', 'U+304F',\n",
              "       '513', '936', '37', '110', 'U+3068', '357', '740', '27', '93',\n",
              "       'U+3082', '337', '1962', '56', '91', 'U+307E', '671', '1394', '35',\n",
              "       '86', 'U+3070', '180', '1852', '55', '108', 'U+7269', '648',\n",
              "       '1317', '88', '73', 'U+3082', '1157', '916', '33', '98', 'U+5927',\n",
              "       '813', '2142', '75', '92', 'U+3066', '1163', '2252', '35', '115',\n",
              "       'U+4E00', '982', '742', '62', '22', 'U+308A', '665', '1763', '51',\n",
              "       '104', 'U+662F', '346', '1389', '70', '149', 'U+308C', '793',\n",
              "       '2385', '102', '103', 'U+3068', '192', '2746', '29', '102',\n",
              "       'U+306E', '480', '1879', '81', '90', 'U+306A', '828', '1916', '44',\n",
              "       '110', 'U+308B', '1313', '1087', '34', '83', 'U+305D', '177',\n",
              "       '2537', '56', '94', 'U+3055', '1315', '1094', '31', '71', 'U+6642',\n",
              "       '1127', '1463', '91', '111', 'U+3089', '676', '856', '28', '125',\n",
              "       'U+3082', '511', '1245', '39', '106', 'U+304F', '1163', '2259',\n",
              "       '32', '105', 'U+3092', '1466', '2050', '57', '104', 'U+3053',\n",
              "       '834', '734', '34', '79', 'U+65E5', '1472', '1089', '43', '68',\n",
              "       'U+306A', '353', '1030', '48', '111', 'U+4E8B', '977', '2716',\n",
              "       '68', '137', 'U+306C', '808', '1588', '87', '75', 'U+3053', '196',\n",
              "       '2303', '33', '73', 'U+3092', '812', '2779', '74', '77', 'U+305A',\n",
              "       '343', '2751', '83', '99', 'U+304B', '1316', '1357', '31', '78',\n",
              "       'U+516D', '664', '2696', '66', '63', 'U+3072', '661', '993', '60',\n",
              "       '82', 'U+6240', '333', '951', '72', '83', 'U+3072', '1142', '1314',\n",
              "       '68', '92', 'U+8EAB', '495', '2374', '73', '129', 'U+305D', '366',\n",
              "       '2476', '38', '74', 'U+306B', '336', '881', '90', '73', 'U+308A',\n",
              "       '1315', '1595', '40', '123', 'U+306B', '342', '1551', '70', '61',\n",
              "       'U+305D', '509', '814', '43', '86', 'U+305B', '805', '1528', '82',\n",
              "       '66', 'U+3068', '832', '1666', '37', '69', 'U+5207', '1450',\n",
              "       '1165', '89', '70', 'U+308D', '1287', '2696', '52', '67', 'U+304F',\n",
              "       '1479', '2227', '35', '113', 'U+898B', '174', '2634', '64', '114',\n",
              "       'U+308B', '1149', '1206', '42', '82', 'U+304F', '494', '2656',\n",
              "       '65', '86', 'U+3093', '1450', '1434', '98', '110', 'U+4EBA', '322',\n",
              "       '2050', '100', '96', 'U+3051', '663', '2103', '72', '112',\n",
              "       'U+9905', '1599', '1512', '89', '115', 'U+3046', '838', '911',\n",
              "       '27', '84', 'U+3078', '324', '2073', '104', '81', 'U+6C41', '503',\n",
              "       '2184', '69', '174', 'U+4E4B', '350', '2201', '52', '111'],\n",
              "      dtype='<U6'),\n",
              "       array(['U+306E', '1276', '1601', '61', '65', 'U+306E', '1283', '2367',\n",
              "       '60', '63', 'U+306E', '960', '1262', '66', '58', 'U+3057', '659',\n",
              "       '1456', '21', '103', 'U+306E', '639', '1668', '72', '73', 'U+3078',\n",
              "       '956', '1867', '102', '58', 'U+304D', '483', '879', '58', '116',\n",
              "       'U+3079', '621', '1421', '88', '49', 'U+306A', '971', '1325', '48',\n",
              "       '83', 'U+3093', '803', '2183', '84', '86', 'U+306B', '810', '2572',\n",
              "       '70', '74', 'U+306E', '647', '2764', '69', '75', 'U+306E', '625',\n",
              "       '1086', '61', '77', 'U+306E', '1447', '2382', '49', '61', 'U+3046',\n",
              "       '978', '806', '29', '104', 'U+306A', '1143', '2362', '43', '73',\n",
              "       'U+307E', '165', '1476', '40', '83', 'U+308A', '1291', '938', '38',\n",
              "       '97', 'U+306B', '970', '1925', '73', '57', 'U+306B', '501', '1929',\n",
              "       '69', '65', 'U+308C', '976', '2094', '48', '112', 'U+306E', '808',\n",
              "       '2035', '61', '68', 'U+3078', '170', '2452', '75', '67', 'U+3051',\n",
              "       '1454', '2005', '46', '79', 'U+3057', '197', '2677', '26', '150',\n",
              "       'U+3068', '664', '849', '24', '81', 'U+306B', '795', '1129', '82',\n",
              "       '80', 'U+306A', '644', '1265', '43', '77', 'U+4EBA', '143', '1387',\n",
              "       '106', '111', 'U+308A', '824', '1614', '38', '96', 'U+306A', '180',\n",
              "       '2216', '52', '100', 'U+308A', '815', '1804', '48', '102',\n",
              "       'U+3082', '344', '1702', '55', '89', 'U+3068', '1153', '2572',\n",
              "       '31', '70', 'U+4EBA', '324', '1908', '103', '100', 'U+306F', '341',\n",
              "       '2321', '62', '38', 'U+304D', '1303', '2733', '31', '97', 'U+308A',\n",
              "       '651', '1824', '51', '112', 'U+306B', '168', '1897', '61', '70',\n",
              "       'U+306B', '161', '881', '70', '66', 'U+306F', '974', '1585', '54',\n",
              "       '32', 'U+3078', '1585', '1274', '95', '47', 'U+306B', '335',\n",
              "       '1629', '75', '76', 'U+306E', '1604', '1324', '52', '51', 'U+3082',\n",
              "       '177', '1672', '45', '102', 'U+306F', '354', '1995', '34', '89',\n",
              "       'U+3046', '665', '1736', '27', '97', 'U+306F', '642', '935', '51',\n",
              "       '48', 'U+306F', '652', '2227', '50', '35', 'U+308B', '815', '906',\n",
              "       '36', '91', 'U+3076', '480', '1475', '85', '73', 'U+3082', '1141',\n",
              "       '2193', '36', '96', 'U+6C17', '168', '2075', '79', '120', 'U+304B',\n",
              "       '159', '953', '65', '53', 'U+308B', '1147', '2108', '35', '81',\n",
              "       'U+4E8B', '639', '1163', '43', '110', 'U+305A', '151', '1167',\n",
              "       '87', '105', 'U+3066', '979', '2214', '34', '131', 'U+4E00', '791',\n",
              "       '1272', '78', '26', 'U+3089', '175', '1082', '21', '112', 'U+304F',\n",
              "       '979', '2247', '32', '95', 'U+306F', '1135', '1443', '57', '33',\n",
              "       'U+3070', '1126', '1135', '59', '98', 'U+304C', '1293', '2614',\n",
              "       '77', '70', 'U+308B', '516', '2374', '42', '76', 'U+3046', '1145',\n",
              "       '1895', '29', '100', 'U+3075', '473', '1861', '94', '55', 'U+308B',\n",
              "       '351', '2194', '32', '74', 'U+304F', '969', '894', '38', '93',\n",
              "       'U+51FA', '1447', '2526', '67', '60', 'U+898B', '1114', '927',\n",
              "       '73', '98', 'U+6238', '1446', '1527', '37', '104', 'U+308B',\n",
              "       '1297', '1688', '35', '79', 'U+304F', '1461', '2269', '39', '108',\n",
              "       'U+4E8C', '315', '1286', '70', '62', 'U+4E00', '332', '880', '50',\n",
              "       '18', 'U+308B', '983', '2660', '37', '90', 'U+3061', '510', '2298',\n",
              "       '44', '89', 'U+3072', '1448', '1736', '56', '76', 'U+304F', '1145',\n",
              "       '1805', '31', '86', 'U+308B', '1147', '2428', '34', '86', 'U+304F',\n",
              "       '498', '1639', '43', '114', 'U+3046', '346', '738', '38', '110',\n",
              "       'U+308A', '508', '2391', '52', '112', 'U+4EBA', '1418', '1392',\n",
              "       '100', '88', 'U+51FA', '488', '1391', '72', '73', 'U+4ECA', '472',\n",
              "       '1988', '115', '115', 'U+306C', '957', '1505', '76', '80',\n",
              "       'U+3078', '147', '1405', '106', '90', 'U+5176', '1449', '2086',\n",
              "       '41', '108', 'U+306A', '1144', '2008', '48', '107', 'U+3078',\n",
              "       '793', '1445', '72', '49', 'U+3051', '1597', '1378', '64', '75',\n",
              "       'U+3053', '1136', '724', '43', '73', 'U+3092', '326', '1018', '60',\n",
              "       '87', 'U+3068', '978', '2558', '31', '66', 'U+3086', '172', '2383',\n",
              "       '62', '67', 'U+304F', '1462', '2738', '28', '85', 'U+3048', '961',\n",
              "       '1200', '69', '62', 'U+307E', '505', '2759', '66', '73'],\n",
              "      dtype='<U6'),\n",
              "       ...,\n",
              "       array(['U+3084', '224', '3393', '165', '113', 'U+3066', '265', '993',\n",
              "       '89', '171', 'U+3064', '868', '1584', '159', '133', 'U+3064',\n",
              "       '240', '1827', '137', '123', 'U+306E', '674', '3471', '120', '118',\n",
              "       'U+305F', '1095', '1658', '106', '129', 'U+305B', '1748', '1194',\n",
              "       '114', '124', 'U+3066', '251', '2736', '111', '120', 'U+3092',\n",
              "       '481', '930', '123', '193', 'U+306E', '1316', '2078', '125', '130',\n",
              "       'U+3066', '1538', '2579', '96', '165', 'U+3075', '876', '1796',\n",
              "       '161', '160', 'U+306F', '1972', '1288', '105', '70', 'U+3092',\n",
              "       '1768', '2680', '117', '117', 'U+308C', '1522', '1356', '152',\n",
              "       '166', 'U+308A', '931', '2778', '64', '173', 'U+3057', '905',\n",
              "       '1439', '116', '145', 'U+304B', '715', '3589', '54', '96',\n",
              "       'U+3057', '2419', '1808', '113', '120', 'U+3055', '485', '2783',\n",
              "       '64', '97', 'U+308B', '292', '3578', '70', '130', 'U+4EBA', '861',\n",
              "       '3428', '206', '177', 'U+3068', '2449', '1637', '44', '147',\n",
              "       'U+308A', '2469', '912', '60', '173', 'U+3057', '964', '906', '45',\n",
              "       '173', 'U+306B', '1323', '3550', '76', '124', 'U+304C', '1126',\n",
              "       '2002', '117', '135', 'U+4E8B', '684', '1978', '98', '236',\n",
              "       'U+306B', '1539', '2237', '81', '155', 'U+3057', '731', '1763',\n",
              "       '45', '179', 'U+304F', '726', '742', '54', '183', 'U+3044', '2188',\n",
              "       '1686', '137', '94', 'U+306E', '1722', '2310', '149', '166',\n",
              "       'U+3064', '2415', '757', '127', '149', 'U+3092', '2193', '3130',\n",
              "       '120', '163', 'U+306F', '2210', '2040', '101', '63', 'U+308A',\n",
              "       '1333', '2526', '78', '203', 'U+3057', '1327', '3149', '108',\n",
              "       '118', 'U+898B', '265', '2098', '100', '169', 'U+4ECA', '1502',\n",
              "       '1677', '197', '202', 'U+3057', '2443', '2043', '47', '185',\n",
              "       'U+3070', '1560', '1501', '99', '164', 'U+3061', '1334', '2223',\n",
              "       '112', '147', 'U+3042', '2197', '2270', '101', '139', 'U+304B',\n",
              "       '1796', '743', '46', '101', 'U+308A', '2007', '1700', '66', '157',\n",
              "       'U+3088', '2237', '738', '50', '143', 'U+3052', '480', '1920',\n",
              "       '152', '148', 'U+308A', '1132', '1804', '67', '187', 'U+304F',\n",
              "       '2405', '2222', '63', '179', 'U+305F', '2432', '1920', '83', '153',\n",
              "       'U+308A', '718', '2526', '62', '172', 'U+3075', '904', '1938',\n",
              "       '121', '124', 'U+3057', '288', '765', '44', '215', 'U+304B',\n",
              "       '1569', '1090', '49', '94', 'U+3057', '1561', '2384', '52', '188',\n",
              "       'U+3076', '228', '3264', '191', '133', 'U+304F', '293', '1497',\n",
              "       '57', '210', 'U+3079', '1294', '1821', '166', '86', 'U+3057',\n",
              "       '714', '3650', '51', '182', 'U+304B', '290', '3494', '50', '113',\n",
              "       'U+3075', '2392', '2576', '117', '138', 'U+3082', '1761', '3698',\n",
              "       '93', '144', 'U+8EAB', '1499', '2013', '133', '226', 'U+3057',\n",
              "       '1995', '918', '71', '201', 'U+305A', '2199', '2487', '130', '180',\n",
              "       'U+3064', '699', '1662', '103', '98', 'U+3064', '655', '2236',\n",
              "       '144', '149', 'U+304F', '1574', '3711', '63', '144', 'U+305D',\n",
              "       '1559', '758', '74', '138', 'U+306E', '1289', '2988', '181', '182',\n",
              "       'U+308A', '2431', '2926', '71', '182', 'U+308A', '523', '1588',\n",
              "       '59', '185', 'U+3068', '2012', '1864', '47', '150', 'U+304B',\n",
              "       '2421', '3119', '65', '105', 'U+304F', '1161', '3536', '54', '131',\n",
              "       'U+3064', '2190', '1790', '118', '85', 'U+3068', '1804', '2785',\n",
              "       '41', '155', 'U+3044', '251', '1740', '119', '93', 'U+3057', '295',\n",
              "       '2515', '59', '196', 'U+304B', '952', '1701', '38', '101',\n",
              "       'U+3031', '290', '2457', '83', '271', 'U+306B', '1320', '747',\n",
              "       '136', '141', 'U+305E', '279', '1949', '125', '140', 'U+3064',\n",
              "       '1518', '1904', '132', '145', 'U+306A', '1338', '1538', '115',\n",
              "       '143', 'U+3080', '1537', '905', '128', '182', 'U+3055', '1555',\n",
              "       '1201', '69', '124', 'U+308B', '2200', '1879', '124', '155',\n",
              "       'U+3068', '1996', '1140', '46', '127', 'U+3057', '2451', '1407',\n",
              "       '46', '225', 'U+307E', '703', '2359', '70', '143', 'U+4EBA',\n",
              "       '2153', '1338', '167', '197', 'U+3064', '449', '3557', '158',\n",
              "       '112', 'U+3066', '483', '2055', '61', '206', 'U+3066', '1769',\n",
              "       '3091', '54', '208', 'U+304D', '461', '2883', '144', '148',\n",
              "       'U+3075', '903', '773', '120', '140', 'U+308B', '2410', '3260',\n",
              "       '121', '168', 'U+3072', '1289', '3405', '136', '136'], dtype='<U6'),\n",
              "       array(['U+3064', '1139', '2695', '90', '62', 'U+3084', '668', '2960',\n",
              "       '95', '97', 'U+3042', '979', '2515', '81', '97', 'U+306E', '636',\n",
              "       '1616', '127', '91', 'U+3042', '809', '1178', '81', '96', 'U+308C',\n",
              "       '185', '1673', '66', '127', 'U+306E', '1433', '2059', '153', '111',\n",
              "       'U+3082', '1004', '2702', '37', '90', 'U+3042', '1141', '1221',\n",
              "       '84', '103', 'U+3075', '1745', '1036', '116', '76', 'U+306E',\n",
              "       '1624', '2735', '119', '83', 'U+3064', '975', '2623', '98', '76',\n",
              "       'U+3046', '688', '1015', '32', '110', 'U+3066', '173', '1824',\n",
              "       '68', '101', 'U+306E', '1099', '699', '136', '92', 'U+306E', '783',\n",
              "       '683', '107', '83', 'U+306E', '814', '2982', '94', '79', 'U+306E',\n",
              "       '1916', '2005', '135', '91', 'U+306E', '149', '2279', '126', '91',\n",
              "       'U+306B', '159', '1142', '96', '90', 'U+306E', '1119', '1497',\n",
              "       '116', '89', 'U+3046', '192', '1215', '31', '105', 'U+306E', '650',\n",
              "       '2717', '128', '92', 'U+306E', '140', '811', '125', '83', 'U+306F',\n",
              "       '495', '2982', '100', '60', 'U+306B', '1964', '2961', '43', '71',\n",
              "       'U+308A', '485', '569', '69', '122', 'U+306E', '949', '791', '111',\n",
              "       '68', 'U+305B', '1927', '1833', '97', '89', 'U+306E', '1264',\n",
              "       '2276', '137', '96', 'U+3068', '1009', '2052', '42', '114',\n",
              "       'U+306E', '1434', '1244', '111', '92', 'U+306E', '1897', '903',\n",
              "       '130', '98', 'U+3059', '1938', '1211', '76', '137', 'U+306F',\n",
              "       '498', '1241', '70', '39', 'U+3065', '158', '2038', '128', '87',\n",
              "       'U+305F', '1647', '1944', '52', '90', 'U+306E', '1605', '1630',\n",
              "       '114', '81', 'U+306F', '994', '3009', '87', '43', 'U+306F', '327',\n",
              "       '1249', '94', '49', 'U+304D', '1304', '1023', '56', '109',\n",
              "       'U+3080', '1453', '2690', '99', '101', 'U+3068', '1304', '715',\n",
              "       '32', '84', 'U+304B', '1324', '2349', '37', '75', 'U+306F', '818',\n",
              "       '1707', '81', '49', 'U+306E', '1746', '743', '107', '92', 'U+306F',\n",
              "       '339', '1931', '83', '44', 'U+3064', '1424', '561', '95', '108',\n",
              "       'U+3082', '1332', '2510', '33', '73', 'U+306E', '947', '1875',\n",
              "       '134', '94', 'U+4E09', '1905', '684', '83', '78', 'U+3093', '1946',\n",
              "       '1908', '87', '90', 'U+307F', '1923', '2309', '112', '108',\n",
              "       'U+308A', '977', '1762', '73', '112', 'U+306E', '640', '938', '99',\n",
              "       '89', 'U+308A', '1330', '1762', '41', '81', 'U+304D', '1621',\n",
              "       '746', '56', '112', 'U+3051', '1925', '1344', '95', '105',\n",
              "       'U+308A', '1000', '1148', '37', '108', 'U+3082', '199', '1403',\n",
              "       '38', '84', 'U+3055', '185', '1584', '48', '82', 'U+3064', '965',\n",
              "       '1479', '96', '92', 'U+307E', '1461', '775', '43', '103', 'U+304B',\n",
              "       '368', '2168', '35', '54', 'U+4EBA', '927', '695', '126', '104',\n",
              "       'U+3055', '183', '1041', '45', '83', 'U+306B', '1805', '2736',\n",
              "       '50', '73', 'U+306E', '1276', '1476', '122', '101', 'U+540C',\n",
              "       '1613', '534', '87', '124', 'U+3093', '491', '1705', '83', '87',\n",
              "       'U+4E09', '336', '2075', '96', '86', 'U+3072', '483', '1801', '96',\n",
              "       '87', 'U+3064', '312', '774', '101', '104', 'U+308A', '977',\n",
              "       '1344', '68', '104', 'U+3057', '1937', '1619', '87', '101',\n",
              "       'U+304C', '370', '2387', '51', '79', 'U+3058', '1645', '632', '44',\n",
              "       '102', 'U+3076', '477', '935', '114', '82', 'U+304B', '1493',\n",
              "       '2142', '44', '71', 'U+308A', '1498', '2560', '42', '98', 'U+306E',\n",
              "       '1745', '950', '103', '85', 'U+304B', '1168', '1570', '33', '74',\n",
              "       'U+662F', '347', '1776', '88', '139', 'U+3082', '992', '1679',\n",
              "       '36', '78', 'U+4EBA', '294', '679', '121', '97', 'U+5B50', '980',\n",
              "       '2176', '85', '115', 'U+308F', '1161', '2209', '40', '98',\n",
              "       'U+307F', '1783', '878', '46', '68', 'U+4E09', '1926', '2096',\n",
              "       '92', '76', 'U+304D', '825', '1283', '53', '101', 'U+5927', '959',\n",
              "       '867', '81', '87', 'U+4EBA', '1917', '2880', '135', '107',\n",
              "       'U+3064', '159', '901', '84', '64', 'U+3056', '1799', '2078', '60',\n",
              "       '72', 'U+516D', '492', '2946', '109', '91', 'U+307F', '1485',\n",
              "       '1389', '42', '79', 'U+304D', '1796', '2598', '55', '98', 'U+3082',\n",
              "       '996', '1254', '32', '78', 'U+306A', '1144', '1997', '78', '95',\n",
              "       'U+308A', '667', '1513', '75', '111'], dtype='<U6'),\n",
              "       array(['U+306E', '362', '1798', '74', '66', 'U+306E', '231', '2190', '74',\n",
              "       '66', 'U+306E', '869', '2142', '79', '74', 'U+306E', '533', '1617',\n",
              "       '82', '75', 'U+3057', '407', '2343', '24', '175', 'U+4E00', '1000',\n",
              "       '1025', '108', '26', 'U+3066', '1025', '1601', '74', '104',\n",
              "       'U+3057', '787', '1786', '24', '109', 'U+306F', '864', '2001',\n",
              "       '71', '37', 'U+4EBA', '735', '2206', '106', '91', 'U+308C', '521',\n",
              "       '2024', '122', '126', 'U+3057', '255', '2036', '25', '142',\n",
              "       'U+4E8C', '516', '1021', '114', '56', 'U+65E5', '1495', '1596',\n",
              "       '40', '60', 'U+4E00', '1468', '1550', '100', '36', 'U+306B', '369',\n",
              "       '1967', '74', '67', 'U+3078', '754', '1908', '72', '61', 'U+306B',\n",
              "       '762', '1965', '67', '64', 'U+3031', '896', '2319', '47', '163',\n",
              "       'U+65E5', '1499', '1444', '38', '73', 'U+3064', '1003', '1268',\n",
              "       '105', '116', 'U+3057', '392', '2118', '32', '138', 'U+306F',\n",
              "       '371', '2048', '68', '33', 'U+3044', '743', '1656', '73', '57',\n",
              "       'U+306E', '746', '2288', '77', '54', 'U+306E', '1000', '1695',\n",
              "       '148', '128', 'U+304D', '1037', '1382', '43', '106', 'U+3075',\n",
              "       '1476', '1657', '78', '73', 'U+3093', '541', '2015', '94', '126',\n",
              "       'U+304B', '390', '2075', '29', '65', 'U+3044', '760', '1743', '56',\n",
              "       '71', 'U+3051', '761', '1728', '47', '88', 'U+3068', '1039',\n",
              "       '1365', '40', '89', 'U+4E8C', '1463', '1529', '104', '54',\n",
              "       'U+8EAB', '521', '1294', '88', '129', 'U+3058', '395', '2116',\n",
              "       '39', '141', 'U+308A', '1042', '1483', '47', '104', 'U+3059',\n",
              "       '545', '1829', '38', '113', 'U+53C8', '1485', '1242', '83', '77',\n",
              "       'U+3068', '546', '1838', '31', '74', 'U+3068', '547', '1867', '34',\n",
              "       '83', 'U+6642', '1002', '1244', '109', '156', 'U+308F', '1498',\n",
              "       '1599', '43', '63', 'U+3082', '1036', '1485', '54', '107',\n",
              "       'U+90CE', '1024', '1889', '59', '194', 'U+309D', '1012', '2587',\n",
              "       '23', '37', 'U+76EE', '376', '1868', '52', '96', 'U+3075', '1472',\n",
              "       '2293', '127', '100', 'U+304F', '898', '2335', '35', '161',\n",
              "       'U+98A8', '764', '2340', '75', '81', 'U+6C41', '1015', '1925',\n",
              "       '71', '180', 'U+4E94', '1481', '2307', '121', '88', 'U+3057',\n",
              "       '1474', '2294', '124', '111', 'U+540C', '1495', '1424', '51', '85',\n",
              "       'U+5927', '1475', '1241', '91', '78', 'U+5408', '1445', '1726',\n",
              "       '139', '96', 'U+304C', '746', '2284', '92', '61', 'U+3060', '542',\n",
              "       '1943', '49', '81', 'U+4E8C', '391', '2272', '50', '54', 'U+6238',\n",
              "       '241', '1789', '39', '183', 'U+3060', '548', '1947', '53', '49',\n",
              "       'U+308C', '1010', '1708', '131', '113', 'U+5DFB', '1484', '2139',\n",
              "       '151', '147', 'U+306F', '1483', '1523', '72', '38', 'U+30FD',\n",
              "       '1014', '2590', '23', '32', 'U+7533', '239', '1803', '50', '153',\n",
              "       'U+3051', '228', '1726', '78', '84', 'U+6708', '755', '2337', '69',\n",
              "       '86', 'U+3053', '389', '2266', '52', '61', 'U+91D1', '1471',\n",
              "       '1733', '99', '111', 'U+4ECA', '1455', '1739', '125', '91',\n",
              "       'U+3057', '143', '1111', '15', '158', 'U+5F15', '1238', '1006',\n",
              "       '83', '127', 'U+8272', '1016', '1797', '119', '135', 'U+5168',\n",
              "       '1467', '1736', '97', '85', 'U+304D', '1006', '1692', '136', '131',\n",
              "       'U+6C5F', '227', '1726', '87', '79', 'U+4E00', '518', '1046',\n",
              "       '103', '36', 'U+6C41', '1007', '1250', '97', '146', 'U+3066',\n",
              "       '896', '2312', '40', '187', 'U+53E3', '232', '1735', '70', '67',\n",
              "       'U+304B', '1038', '1447', '32', '54', 'U+3082', '1042', '1372',\n",
              "       '40', '98', 'U+3051', '1044', '1494', '46', '94', 'U+516D', '1478',\n",
              "       '1526', '94', '72', 'U+3084', '1469', '1723', '108', '86',\n",
              "       'U+4E94', '1479', '1252', '96', '74', 'U+524D', '871', '1895',\n",
              "       '58', '95', 'U+30CF', '1479', '1525', '76', '35', 'U+5DDD', '762',\n",
              "       '2338', '55', '79', 'U+305F', '538', '1942', '41', '75', 'U+307E',\n",
              "       '1032', '1388', '46', '100', 'U+898B', '996', '1696', '155', '127',\n",
              "       'U+7537', '240', '1955', '56', '91', 'U+4E8B', '245', '1803', '42',\n",
              "       '150', 'U+30CF', '366', '2051', '72', '29', 'U+7B2C', '521',\n",
              "       '1286', '81', '135', 'U+9053', '504', '1478', '113', '135',\n",
              "       'U+5185', '372', '1862', '57', '97', 'U+516D', '394', '2263', '48',\n",
              "       '64'], dtype='<U6')], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZs2c_B9GGu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns = ['image_id', 'labels']\n",
        "pddf = pd.DataFrame(index = range(len(img_id)), columns = columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKe2qECcGQRH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pddf['image_id'] = img_id\n",
        "pddf['labels'] =np.array(e)#pd.Series(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPKkQutVGYCM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "97e0ea63-33a7-4797-fac8-31c36a532cf3"
      },
      "source": [
        "pddf.head()"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test_00145af3.jpg</td>\n",
              "      <td>[U+3075, 998, 1548, 123, 91, U+3084, 662, 2510...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test_001c37e2.jpg</td>\n",
              "      <td>[U+3057, 1290, 1824, 86, 99, U+306E, 1143, 140...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test_003aa33a.jpg</td>\n",
              "      <td>[U+306E, 1276, 1601, 61, 65, U+306E, 1283, 236...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test_00665e33.jpg</td>\n",
              "      <td>[U+3068, 476, 2096, 31, 98, U+306E, 584, 503, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test_006964dc.jpg</td>\n",
              "      <td>[U+3084, 1673, 2775, 127, 84, U+3084, 890, 218...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            image_id                                             labels\n",
              "0  test_00145af3.jpg  [U+3075, 998, 1548, 123, 91, U+3084, 662, 2510...\n",
              "1  test_001c37e2.jpg  [U+3057, 1290, 1824, 86, 99, U+306E, 1143, 140...\n",
              "2  test_003aa33a.jpg  [U+306E, 1276, 1601, 61, 65, U+306E, 1283, 236...\n",
              "3  test_00665e33.jpg  [U+3068, 476, 2096, 31, 98, U+306E, 584, 503, ...\n",
              "4  test_006964dc.jpg  [U+3084, 1673, 2775, 127, 84, U+3084, 890, 218..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqDHL7DZLy41",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "744cf5bd-7b32-4646-9500-fe64f8120839"
      },
      "source": [
        "pddf['image_id'] = pddf['image_id'].map(lambda x: x.rstrip('.jpg'))\n",
        "pddf.head()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test_00145af3</td>\n",
              "      <td>[U+3075, 998, 1548, 123, 91, U+3084, 662, 2510...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test_001c37e2</td>\n",
              "      <td>[U+3057, 1290, 1824, 86, 99, U+306E, 1143, 140...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test_003aa33a</td>\n",
              "      <td>[U+306E, 1276, 1601, 61, 65, U+306E, 1283, 236...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test_00665e33</td>\n",
              "      <td>[U+3068, 476, 2096, 31, 98, U+306E, 584, 503, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test_006964dc</td>\n",
              "      <td>[U+3084, 1673, 2775, 127, 84, U+3084, 890, 218...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        image_id                                             labels\n",
              "0  test_00145af3  [U+3075, 998, 1548, 123, 91, U+3084, 662, 2510...\n",
              "1  test_001c37e2  [U+3057, 1290, 1824, 86, 99, U+306E, 1143, 140...\n",
              "2  test_003aa33a  [U+306E, 1276, 1601, 61, 65, U+306E, 1283, 236...\n",
              "3  test_00665e33  [U+3068, 476, 2096, 31, 98, U+306E, 584, 503, ...\n",
              "4  test_006964dc  [U+3084, 1673, 2775, 127, 84, U+3084, 890, 218..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mrvLxIlfzHO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c3e5ff7c-604a-482a-8732-3a0b93aedb1e"
      },
      "source": [
        "pddf['labels'] = [','.join(map(str, l)) for l in pddf['labels']]\n",
        "pddf.head()"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test_00145af3</td>\n",
              "      <td>U+3075,998,1548,123,91,U+3084,662,2510,120,77,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test_001c37e2</td>\n",
              "      <td>U+3057,1290,1824,86,99,U+306E,1143,1404,67,71,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test_003aa33a</td>\n",
              "      <td>U+306E,1276,1601,61,65,U+306E,1283,2367,60,63,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test_00665e33</td>\n",
              "      <td>U+3068,476,2096,31,98,U+306E,584,503,95,105,U+...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test_006964dc</td>\n",
              "      <td>U+3084,1673,2775,127,84,U+3084,890,2180,124,97...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        image_id                                             labels\n",
              "0  test_00145af3  U+3075,998,1548,123,91,U+3084,662,2510,120,77,...\n",
              "1  test_001c37e2  U+3057,1290,1824,86,99,U+306E,1143,1404,67,71,...\n",
              "2  test_003aa33a  U+306E,1276,1601,61,65,U+306E,1283,2367,60,63,...\n",
              "3  test_00665e33  U+3068,476,2096,31,98,U+306E,584,503,95,105,U+...\n",
              "4  test_006964dc  U+3084,1673,2775,127,84,U+3084,890,2180,124,97..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFbLPRdygS0C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6a0a39cb-bbf6-4cab-ef1e-fa5dcce21a34"
      },
      "source": [
        "pddf['labels'] = pddf['labels'].str.replace(',', ' ')\n",
        "pddf.head()"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test_00145af3</td>\n",
              "      <td>U+3075 998 1548 123 91 U+3084 662 2510 120 77 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test_001c37e2</td>\n",
              "      <td>U+3057 1290 1824 86 99 U+306E 1143 1404 67 71 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test_003aa33a</td>\n",
              "      <td>U+306E 1276 1601 61 65 U+306E 1283 2367 60 63 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test_00665e33</td>\n",
              "      <td>U+3068 476 2096 31 98 U+306E 584 503 95 105 U+...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test_006964dc</td>\n",
              "      <td>U+3084 1673 2775 127 84 U+3084 890 2180 124 97...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        image_id                                             labels\n",
              "0  test_00145af3  U+3075 998 1548 123 91 U+3084 662 2510 120 77 ...\n",
              "1  test_001c37e2  U+3057 1290 1824 86 99 U+306E 1143 1404 67 71 ...\n",
              "2  test_003aa33a  U+306E 1276 1601 61 65 U+306E 1283 2367 60 63 ...\n",
              "3  test_00665e33  U+3068 476 2096 31 98 U+306E 584 503 95 105 U+...\n",
              "4  test_006964dc  U+3084 1673 2775 127 84 U+3084 890 2180 124 97..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hPhKUo5gqEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pddf.to_csv('submission1.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISzcH2RFgtUB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bC7OZSjqf85P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5c6b58dd-fa41-466c-868d-2e2246f0a60b"
      },
      "source": [
        "pddf['labels'][0]"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'U+3075 998 1548 1121 1639 U+3084 662 2510 782 2587 U+3075 498 2867 607 2974 U+3084 1668 953 1781 1045 U+3066 532 1693 615 1789 U+306E 1337 1930 1425 2023 U+3066 1369 824 1446 929 U+3084 824 2301 947 2379 U+3066 1500 2362 1576 2455 U+3044 1016 1480 1107 1544 U+306E 207 1418 309 1506 U+3075 505 1896 615 1982 U+3066 714 673 793 762 U+3075 1794 1553 1912 1643 U+3046 866 2385 906 2518 U+3066 1207 860 1267 977 U+3066 183 2513 259 2618 U+308C 532 653 660 754 U+3075 174 2087 287 2186 U+3064 541 571 634 646 U+3044 195 1833 297 1902 U+304B 1155 2490 1254 2546 U+3066 1697 1325 1741 1457 U+306B 1512 1267 1610 1365 U+3042 1803 2702 1893 2801 U+3092 1031 894 1145 1011 U+3068 56 2551 84 2666 U+306B 80 1134 125 1230 U+3046 878 1867 918 2001 U+308C 1821 969 1937 1075 U+3046 571 924 607 1038 U+304D 729 1165 783 1283 U+3068 422 1008 453 1112 U+3068 1060 1339 1091 1458 U+3068 1700 1573 1730 1686 U+3075 987 2202 1098 2303 U+3066 1212 1909 1254 2057 U+3066 1852 1075 1921 1159 U+3068 100 1547 129 1663 U+306E 1340 1171 1464 1268 U+3066 218 1262 292 1347 U+304F 530 2480 571 2611 U+3078 846 1007 981 1068 U+306B 711 1860 759 1959 U+308C 151 2975 299 3085 U+3042 885 576 975 689 U+3072 851 1500 956 1603 U+307E 1184 2237 1225 2343 U+306F 325 2667 433 2726 U+304B 1023 2606 1071 2675 U+3093 1342 1584 1436 1675 U+3093 676 2664 761 2755 U+3066 366 1762 446 1857 U+307E 1832 2360 1870 2465 U+3072 189 2277 280 2394 U+306A 700 1509 798 1610 U+306B 78 828 133 922 U+308A 559 813 637 930 U+7533 852 2626 908 2784 U+306F 714 778 815 832 U+304D 694 2363 763 2490 U+3031 535 2593 608 2761 U+3068 865 2524 900 2613 U+306A 689 2202 773 2349 U+3067 714 912 809 1026 U+3031 1371 2055 1429 2199 U+305B 1359 734 1453 817 U+3072 1001 1982 1104 2089 U+516D 62 937 151 1005 U+308A 866 1765 943 1873 U+3060 1175 2363 1267 2472 U+3092 1183 1715 1287 1828 U+3068 93 656 124 753 U+308B 1534 1823 1586 1911 U+3068 709 2760 738 2845 U+305D 70 1760 128 1876 U+4E16 473 2312 626 2400 U+4E00 984 2780 1081 2818 U+304B 1371 1682 1409 1755 U+307F 242 812 283 906 U+307E 195 2623 243 2725 U+3072 649 2958 759 3074 U+304F 1078 1209 1120 1337 U+3046 883 2098 914 2201 U+308B 1679 2815 1725 2893 U+306F 409 568 458 679 U+3072 992 2395 1098 2496 U+3031 356 2901 422 3043 U+3053 533 2776 591 2849 U+3068 1054 1740 1085 1872 U+3082 1222 667 1271 764 U+306A 1340 2640 1411 2726 U+3089 542 2960 588 3056 U+304B 1685 780 1777 846 U+3081 721 827 791 912 U+7533 409 1120 462 1279 U+3089 1871 774 1914 888 U+3081 360 2190 443 2275 U+305F 1170 1361 1266 1469 U+3066 72 1785 129 1880'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    }
  ]
}